[{"title":"Langchain系列[02]使用LCEL构建一个简单的LLM应用程序","url":"/forward/24d30ec1.html","content":"<h1 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h1><p>今天咱们介绍一下如何使用 LangChain 构建一个简单的 LLM 应用程序。</p>\n<p>这个应用程序能够将英文文本翻译成其他语言。</p>\n<p>这是一个相对简单的 LLM 应用程序 —— 它仅包含一个 LLM 调用和一些提示。</p>\n<p>今天的学习目的是初步了解下面的概念</p>\n<ul>\n<li>使用语言模型 （必须）</li>\n<li>使用 PromptTemplates 和 OutputParsers（必须）</li>\n<li>使用 LangChain 表达式语言 (LCEL) 将组件连接在一起（必须）</li>\n<li>使用 LangSmith 调试和跟踪您的应用程序 （不用也问题不大）</li>\n<li>使用 LangServe 部署您的应用程序（不用也问题不大）</li>\n</ul>\n<h2 id=\"准备阶段\"><a href=\"#准备阶段\" class=\"headerlink\" title=\"准备阶段\"></a>准备阶段</h2><p>我们全程使用windows + python, 其他的方法就不介绍了，同学们可以自己探索~</p>\n<p><strong>安装</strong></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install langchain</span><br></pre></td></tr></table></figure>\n\n<p><strong>关于 Jupyter Notebook</strong></p>\n<p>咱们用能跑python的编程工具就可以，用什么来跑不是很重要-。-</p>\n<p><strong><a href=\"https://www.langchain.com/langsmith\">LangSmith</a></strong></p>\n<p>langsmith 是一个可以跟踪runnable  的工具，可以跟踪和记录复杂流程中的大部分参数，对于复杂问题分析很有帮助。在学习初期，我们可以先不使用这个工具，到后面遇到复杂逻辑和chain的时候，我们再使用。 感兴趣的同学可以自己去注册一下，每月有免费的使用额度。</p>\n<p><strong>薅羊毛</strong> langsmith 的提示：截止2024 7.1日前，免费账户每月有5K 的使用次数</p>\n<p>New Pricing:All free accounts will be rate limited to 5k traces per month starting on July 1st. To avoid this, <a href=\"https://smith.langchain.com/settings/payments\">sign up</a> for our paid plans</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">你可以这样简单使用</span><br><span class=\"line\"># 新建一个<span class=\"variable constant_\">ID</span>号，用于记录你的<span class=\"title class_\">Log</span></span><br><span class=\"line\">unique_id = <span class=\"title function_\">uuid4</span>().<span class=\"property\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"># 写一个<span class=\"variable constant_\">TAG</span></span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = f<span class=\"string\">&quot; Agent RAG - &#123;unique_id&#125;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"># 这个表示你要使用langsmith 开始记录，不用就<span class=\"literal\">false</span></span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"># 这个是你注册langsmith 后的<span class=\"variable constant_\">KEY</span></span><br><span class=\"line\"># 你可以把你的key 放到环境中，用<span class=\"variable constant_\">MY_LANGCHAIN_API_KEY</span>来引用</span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.<span class=\"title function_\">getenv</span>(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"># 要是你觉得麻烦 你就这样</span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = <span class=\"string\">&#x27;dsad6487dfdhb...  你的key&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"使用语言模型\"><a href=\"#使用语言模型\" class=\"headerlink\" title=\"使用语言模型\"></a>使用语言模型</h2><p>官网列出一堆模型，好是好，国内能用的没几个…(不翻墙的情况)</p>\n<p>我们先用官网中的 <strong>Azure  OpenAi</strong>  以及 <strong>千帆</strong>来做演示~</p>\n<h3 id=\"创建一个-Azure-OpenAi-chatModel\"><a href=\"#创建一个-Azure-OpenAi-chatModel\" class=\"headerlink\" title=\"创建一个  Azure OpenAi chatModel\"></a><strong>创建一个  Azure OpenAi chatModel</strong></h3><figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] =<span class=\"variable constant_\">AZURE_OPENAI_API_KEY</span></span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] =<span class=\"variable constant_\">AZURE_OPENAI_ENDPOINT</span></span><br><span class=\"line\">gpt3p5_model = <span class=\"title class_\">AzureChatOpenAI</span>(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">    azure_deployment=<span class=\"variable constant_\">DEPLOYMENT_NAME_GPT3P5</span>,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p><strong>AZURE_OPENAI_API_KEY</strong>: 你的<strong>Azure OpenAI KEY,</strong> 需要在微软Azure中申请订阅</p>\n<p><strong>AZURE_OPENAI_ENDPOINT</strong>： 你的服务端endpit,一个url地址，订阅后从Azure获取</p>\n<p><strong>openai_api_version</strong>： 你使用模型的版本号，依赖你使用的模型</p>\n<p><strong>azure_deployment</strong>：你给你部署的模型起的名字，从Azure获取</p>\n<p><strong>给出提示词，并调用invoke (LCEL 的方法之一)</strong></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">messages = [</span><br><span class=\"line\">    <span class=\"title class_\">SystemMessage</span>(content=<span class=\"string\">&quot;Translate the following from English into Italian&quot;</span>),</span><br><span class=\"line\">    <span class=\"title class_\">HumanMessage</span>(content=<span class=\"string\">&quot;hi!&quot;</span>),</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\">res = gpt3p5_model.<span class=\"title function_\">invoke</span>(messages)</span><br><span class=\"line\"><span class=\"title function_\">print</span>(res.<span class=\"property\">content</span>)</span><br></pre></td></tr></table></figure>\n\n<p>messages： 消息列表，通常包含整个对话历史</p>\n<p>SystemMessage：系统提示词，在messages 中一般只出现一次，表明系统的<strong>身份</strong></p>\n<p>HumanMessage： 用户消息</p>\n<p><strong>输出</strong></p>\n<p>模型输出的内容是 一个 <strong>AIMessage</strong></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">AIMessage</span>(content=<span class=\"string\">&#x27;ciao!....</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">content=&#x27;</span><span class=\"title class_\">Ciao</span>!<span class=\"string\">&#x27; response_metadata=&#123;&#x27;</span>token_usage<span class=\"string\">&#x27;: &#123;&#x27;</span>completion_tokens<span class=\"string\">&#x27;: 3, &#x27;</span>prompt_tokens<span class=\"string\">&#x27;: 20, &#x27;</span>total_tokens<span class=\"string\">&#x27;: 23&#125;, &#x27;</span>model_name<span class=\"string\">&#x27;: &#x27;</span>gpt-<span class=\"number\">35</span>-turbo<span class=\"string\">&#x27;, &#x27;</span>system_fingerprint<span class=\"string\">&#x27;: None, &#x27;</span>prompt_filter_results<span class=\"string\">&#x27;: [&#123;&#x27;</span>prompt_index<span class=\"string\">&#x27;: 0, &#x27;</span>content_filter_results<span class=\"string\">&#x27;: &#123;&#x27;</span>hate<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;, &#x27;</span>self_harm<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;, &#x27;</span>sexual<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;, &#x27;</span>violence<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;&#125;&#125;], &#x27;</span>finish_reason<span class=\"string\">&#x27;: &#x27;</span>stop<span class=\"string\">&#x27;, &#x27;</span>logprobs<span class=\"string\">&#x27;: None, &#x27;</span>content_filter_results<span class=\"string\">&#x27;: &#123;&#x27;</span>hate<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;, &#x27;</span>self_harm<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;, &#x27;</span>sexual<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;, &#x27;</span>violence<span class=\"string\">&#x27;: &#123;&#x27;</span>filtered<span class=\"string\">&#x27;: False, &#x27;</span>severity<span class=\"string\">&#x27;: &#x27;</span>safe<span class=\"string\">&#x27;&#125;&#125;&#125; id=&#x27;</span>run-2340cccd-9b63-4b07-9dfd-3c154bbef121-<span class=\"number\">0</span><span class=\"string\">&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"创建-文心一言4-chatModel\"><a href=\"#创建-文心一言4-chatModel\" class=\"headerlink\" title=\"创建 文心一言4 chatModel\"></a>创建 文心一言4 chatModel</h3><figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 千帆的 <span class=\"variable constant_\">AK</span> 和 <span class=\"variable constant_\">SK</span>， 需要我们去百度网站申请</span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;QIANFAN_AK&quot;</span>] = <span class=\"variable constant_\">MY_QIANFAN_AK</span></span><br><span class=\"line\">os.<span class=\"property\">environ</span>[<span class=\"string\">&quot;QIANFAN_SK&quot;</span>] = <span class=\"variable constant_\">MY_QIANFAN_SK</span></span><br><span class=\"line\"></span><br><span class=\"line\"># 文心一言<span class=\"number\">4</span> 模型<span class=\"variable constant_\">ERNIE</span>-<span class=\"title class_\">Bot</span>-<span class=\"number\">4</span></span><br><span class=\"line\">wenxin4_model = <span class=\"title class_\">QianfanChatEndpoint</span>(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\">res = wenxin4_model.<span class=\"title function_\">invoke</span>(messages)</span><br><span class=\"line\"><span class=\"title function_\">print</span>(res.<span class=\"property\">content</span>)</span><br><span class=\"line\">pass</span><br></pre></td></tr></table></figure>\n\n<p>输出</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">AIMessage</span>(content=<span class=\"string\">&#x27;salve!....</span></span><br><span class=\"line\"><span class=\"string\">content=&#x27;</span>salve!<span class=\"string\">&#x27; additional_kwargs=&#123;&#x27;</span>finish_reason<span class=\"string\">&#x27;: &#x27;</span>normal<span class=\"string\">&#x27;, &#x27;</span>request_id<span class=\"string\">&#x27;: &#x27;</span><span class=\"keyword\">as</span>-hpbfyf1uqr<span class=\"string\">&#x27;, &#x27;</span>object<span class=\"string\">&#x27;: &#x27;</span>chat.<span class=\"property\">completion</span><span class=\"string\">&#x27;, &#x27;</span>search_info<span class=\"string\">&#x27;: [], &#x27;</span>function_call<span class=\"string\">&#x27;: &#123;&#125;, &#x27;</span>tool_calls<span class=\"string\">&#x27;: [&#123;&#x27;</span>type<span class=\"string\">&#x27;: &#x27;</span><span class=\"keyword\">function</span><span class=\"string\">&#x27;, &#x27;</span><span class=\"keyword\">function</span><span class=\"string\">&#x27;: &#123;&#125;&#125;]&#125; response_metadata=&#123;&#x27;</span>token_usage<span class=\"string\">&#x27;: &#123;&#x27;</span>prompt_tokens<span class=\"string\">&#x27;: 10, &#x27;</span>completion_tokens<span class=\"string\">&#x27;: 3, &#x27;</span>total_tokens<span class=\"string\">&#x27;: 13&#125;, &#x27;</span>model_name<span class=\"string\">&#x27;: &#x27;</span><span class=\"variable constant_\">ERNIE</span>-<span class=\"title class_\">Bot</span>-<span class=\"number\">4</span><span class=\"string\">&#x27;, &#x27;</span>finish_reason<span class=\"string\">&#x27;: &#x27;</span>normal<span class=\"string\">&#x27;, &#x27;</span>id<span class=\"string\">&#x27;: &#x27;</span><span class=\"keyword\">as</span>-hpbfyf1uqr<span class=\"string\">&#x27;, &#x27;</span>object<span class=\"string\">&#x27;: &#x27;</span>chat.<span class=\"property\">completion</span><span class=\"string\">&#x27;, &#x27;</span>created<span class=\"string\">&#x27;: 1718674042, &#x27;</span>result<span class=\"string\">&#x27;: &#x27;</span>salve!<span class=\"string\">&#x27;, &#x27;</span>is_truncated<span class=\"string\">&#x27;: False, &#x27;</span>need_clear_history<span class=\"string\">&#x27;: False, &#x27;</span>usage<span class=\"string\">&#x27;: &#123;&#x27;</span>prompt_tokens<span class=\"string\">&#x27;: 10, &#x27;</span>completion_tokens<span class=\"string\">&#x27;: 3, &#x27;</span>total_tokens<span class=\"string\">&#x27;: 13&#125;&#125; id=&#x27;</span>run-4f50bc84-86a6-46dd-8c6f-03d0fbafc3d5-<span class=\"number\">0</span><span class=\"string\">&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"输出解析器\"><a href=\"#输出解析器\" class=\"headerlink\" title=\"输出解析器\"></a>输出解析器</h3><figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.<span class=\"property\">output_parsers</span> <span class=\"keyword\">import</span> <span class=\"title class_\">StrOutputParser</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser = <span class=\"title class_\">StrOutputParser</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"># 大模型的输出</span><br><span class=\"line\">result = model.<span class=\"title function_\">invoke</span>(messages)</span><br><span class=\"line\"></span><br><span class=\"line\"># 解析器 解析模型的输出</span><br><span class=\"line\">parser.<span class=\"title function_\">invoke</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"># 将 <span class=\"title class_\">AIMessage</span> 解析成 字符串  （这一步要理解一下...）</span><br><span class=\"line\"><span class=\"string\">&#x27;Ciao!&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<p>为了让上面几步连贯，这也是langchain 的 精华之一</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 使用 chain</span><br><span class=\"line\">chain = model | parser</span><br></pre></td></tr></table></figure>\n\n<p>于是 文心一言4 的chain， 可以这样</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">chain = wenxin4_model | parser</span><br><span class=\"line\">res = chain.invoke(messages)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res.content)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用提示词模板\"><a href=\"#使用提示词模板\" class=\"headerlink\" title=\"使用提示词模板\"></a>使用提示词模板</h3><p>我们可以在提示词中使用<strong>变量，</strong>变量的表示方法是把变量放到{ }中</p>\n<p>系统提示词： 通过变量language， 我们可以改变目标语言的类型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">system_template = <span class=\"string\">&quot;Translate the following into &#123;language&#125;:&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>将用户输入，放入变量 text;组合成一个[]</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">prompt_template = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">    [(<span class=\"string\">&quot;system&quot;</span>, system_template), (<span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;&#123;text&#125;&quot;</span>)]</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>通过invoke 方法，指定变量的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">result = prompt_template.invoke(&#123;<span class=\"string\">&quot;language&quot;</span>: <span class=\"string\">&quot;italian&quot;</span>, <span class=\"string\">&quot;text&quot;</span>: <span class=\"string\">&quot;hi&quot;</span>&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(result.to_messages())</span><br></pre></td></tr></table></figure>\n\n<p><strong>输出</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">messages=[SystemMessage(content=<span class=\"string\">&#x27;Translate the following into italian:&#x27;</span>), HumanMessage(content=<span class=\"string\">&#x27;hi&#x27;</span>)]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"将上面的各个部分组合起来：-chain\"><a href=\"#将上面的各个部分组合起来：-chain\" class=\"headerlink\" title=\"将上面的各个部分组合起来： chain !\"></a>将上面的各个部分组合起来： chain !</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">ful_chain = prompt_template | wenxin4_model | parser</span><br><span class=\"line\">res = ful_chain.invoke(&#123;<span class=\"string\">&quot;language&quot;</span>: <span class=\"string\">&quot;italian&quot;</span>, <span class=\"string\">&quot;text&quot;</span>: <span class=\"string\">&quot;hi&quot;</span>&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"初步体验一下-Langserve\"><a href=\"#初步体验一下-Langserve\" class=\"headerlink\" title=\"初步体验一下 Langserve\"></a>初步体验一下 Langserve</h2><p>核心</p>\n<p>用 FastAPI 创建一个APP，再调用 langserve add_routes方法，将消息路由到chain 上，作为chain 的输入</p>\n<p>需要安装</p>\n<p>pip install sse_starlette</p>\n<p>pip install langserve</p>\n<p>文心4 作为模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/env python</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">List</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastapi <span class=\"keyword\">import</span> FastAPI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_openai <span class=\"keyword\">import</span> ChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langserve <span class=\"keyword\">import</span> add_routes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> llm_cfg <span class=\"keyword\">import</span> MY_QIANFAN_AK, MY_QIANFAN_SK</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. Create prompt template</span></span><br><span class=\"line\">system_template = <span class=\"string\">&quot;Translate the following into &#123;language&#125;:&quot;</span></span><br><span class=\"line\">prompt_template = ChatPromptTemplate.from_messages([</span><br><span class=\"line\">    (<span class=\"string\">&#x27;system&#x27;</span>, system_template),</span><br><span class=\"line\">    (<span class=\"string\">&#x27;user&#x27;</span>, <span class=\"string\">&#x27;&#123;text&#125;&#x27;</span>)</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. Create model</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_AK&quot;</span>] = MY_QIANFAN_AK</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SK&quot;</span>] = MY_QIANFAN_SK</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 千帆</span></span><br><span class=\"line\">model = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. Create parser</span></span><br><span class=\"line\">parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. Create chain</span></span><br><span class=\"line\">chain = prompt_template | model | parser</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. App definition</span></span><br><span class=\"line\">app = FastAPI(</span><br><span class=\"line\">  title=<span class=\"string\">&quot;LangChain Server&quot;</span>,</span><br><span class=\"line\">  version=<span class=\"string\">&quot;1.0&quot;</span>,</span><br><span class=\"line\">  description=<span class=\"string\">&quot;A simple API server using LangChain&#x27;s Runnable interfaces&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. Adding chain route</span></span><br><span class=\"line\"></span><br><span class=\"line\">add_routes(</span><br><span class=\"line\">    app,</span><br><span class=\"line\">    chain,</span><br><span class=\"line\">    path=<span class=\"string\">&quot;/chain&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> uvicorn</span><br><span class=\"line\"></span><br><span class=\"line\">    uvicorn.run(app, host=<span class=\"string\">&quot;localhost&quot;</span>, port=<span class=\"number\">8000</span>)</span><br></pre></td></tr></table></figure>\n\n<p>直接运行main 方法，看到命令行成功后，浏览器中打开 ：<a href=\"http://localhost:8000/chain/playground/\">http://localhost:8000/chain/playground/</a></p>\n<h4 id=\"客户端调用服务端\"><a href=\"#客户端调用服务端\" class=\"headerlink\" title=\"客户端调用服务端\"></a>客户端调用服务端</h4><p>有了上面的服务端，Langchain 可以支持远程chain的调用，小伙伴们可以自行尝试。</p>\n<p>在单位里，小伙伴们可以自己建立一个大模型服务，然后让单位里的小伙伴调用~~</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langserve <span class=\"keyword\">import</span> RemoteRunnable</span><br><span class=\"line\"></span><br><span class=\"line\">remote_chain = RemoteRunnable(<span class=\"string\">&quot;http://localhost:8000/chain/&quot;</span>)</span><br><span class=\"line\">remote_chain.invoke(&#123;<span class=\"string\">&quot;language&quot;</span>: <span class=\"string\">&quot;italian&quot;</span>, <span class=\"string\">&quot;text&quot;</span>: <span class=\"string\">&quot;hi&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"代码附录\"><a href=\"#代码附录\" class=\"headerlink\" title=\"代码附录\"></a>代码附录</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage, SystemMessage</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> llm_cfg <span class=\"keyword\">import</span> AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, DEPLOYMENT_NAME_GPT3P5, MY_QIANFAN_AK, MY_QIANFAN_SK</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] =AZURE_OPENAI_API_KEY</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] =AZURE_OPENAI_ENDPOINT</span><br><span class=\"line\">    gpt3p5_model = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    messages = [</span><br><span class=\"line\">        SystemMessage(content=<span class=\"string\">&quot;Translate the following from English into Italian&quot;</span>),</span><br><span class=\"line\">        HumanMessage(content=<span class=\"string\">&quot;hi!&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\">    res = gpt3p5_model.invoke(messages)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res.content)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_AK&quot;</span>] = MY_QIANFAN_AK</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SK&quot;</span>] = MY_QIANFAN_SK</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆</span></span><br><span class=\"line\">    wenxin4_model = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\">    res = wenxin4_model.invoke(messages)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res.content)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 输出解析</span></span><br><span class=\"line\">    <span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"></span><br><span class=\"line\">    parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># chain</span></span><br><span class=\"line\">    chain = wenxin4_model | parser</span><br><span class=\"line\">    res = chain.invoke(messages)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res.content)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词</span></span><br><span class=\"line\">    system_template = <span class=\"string\">&quot;Translate the following into &#123;language&#125;:&quot;</span></span><br><span class=\"line\">    prompt_template = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">        [(<span class=\"string\">&quot;system&quot;</span>, system_template), (<span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;&#123;text&#125;&quot;</span>)]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    result = prompt_template.invoke(&#123;<span class=\"string\">&quot;language&quot;</span>: <span class=\"string\">&quot;italian&quot;</span>, <span class=\"string\">&quot;text&quot;</span>: <span class=\"string\">&quot;hi&quot;</span>&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(result.to_messages())</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ful_chain = prompt_template | wenxin4_model | parser</span><br><span class=\"line\">    res = ful_chain.invoke(&#123;<span class=\"string\">&quot;language&quot;</span>: <span class=\"string\">&quot;italian&quot;</span>, <span class=\"string\">&quot;text&quot;</span>: <span class=\"string\">&quot;hi&quot;</span>&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[01]介绍","url":"/forward/efdbd4e2.html","content":"<p>大家好，这里是<strong>粥余</strong>。<br>随着大模型技术的飞速发展，**<code>langchain</code>** 的迭代也来到了<strong>2.0</strong> 时代。<br>按照Langchain 新的文档结构再结合之前的资料，我们重新来整理一下相关知识。</p>\n<hr>\n<p>先来看下官网介绍： <a href=\"https://python.langchain.com/v0.2/docs/introduction/\">传送门</a></p>\n<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p><strong>LangChain</strong> 是一个开发由大型语言模型（LLMs）驱动的应用程序的框架。</p>\n<p>LangChain 简化了 LLM 应用生命周期的每一个阶段：</p>\n<ul>\n<li><strong>开发</strong>：使用 LangChain 的开源 <a href=\"https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel\">构建块</a> 和 <a href=\"https://python.langchain.com/v0.2/docs/concepts/\">组件</a> 构建您的应用程序。利用 <a href=\"https://python.langchain.com/v0.2/docs/integrations/platforms/\">第三方集成</a> 和 <a href=\"https://python.langchain.com/v0.2/docs/templates/\">模板</a> 快速上手。</li>\n<li><strong>生产化</strong>：使用 <a href=\"https://docs.smith.langchain.com/\">LangSmith</a> 来检查、监控和评估您的链，以便您可以持续优化并自信地部署。</li>\n<li><strong>部署</strong>：使用 <a href=\"https://python.langchain.com/v0.2/docs/langserve/\">LangServe</a> 将任何链转变为 API。</li>\n</ul>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-01-%E4%BB%8B%E7%BB%8D.assets/image-20240627095511759.png\" alt=\"image-20240627095511759\"></p>\n<p>具体来说，该框架包括以下开源库：</p>\n<ul>\n<li>**<code>langchain-core</code>**：基本抽象和 LangChain 表达式语言。</li>\n<li>**<code>langchain-community</code>**：第三方集成。</li>\n<li>**<code>langchain</code>**：构成应用程序认知架构的链、代理和检索策略。</li>\n<li>**<a href=\"https://langchain-ai.github.io/langgraph\">langgraph</a>**：通过将步骤建模为图中的边和节点，使用 LLMs 构建健壮且具有状态的多参与者应用程序。</li>\n<li>**<a href=\"https://python.langchain.com/v0.2/docs/langserve/\">langserve</a>**：将 LangChain 链作为 REST API 部署。</li>\n</ul>\n<hr>\n<p>咱们先简单的概括一下：</p>\n<p><a href=\"https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel\">构建块</a></p>\n<p>就是LangChain Expression Language (LCEL)， 也就是链中的各个组件:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Input Type</th>\n<th>Output Type</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Prompt</td>\n<td>Dictionary</td>\n<td>PromptValue</td>\n<td>提示词</td>\n</tr>\n<tr>\n<td>ChatModel</td>\n<td>Single string, list of chat messages or a PromptValue</td>\n<td>ChatMessage</td>\n<td>chat 模型（支持多轮）</td>\n</tr>\n<tr>\n<td>LLM</td>\n<td>Single string, list of chat messages or a PromptValue</td>\n<td>String</td>\n<td>completion （单轮）</td>\n</tr>\n<tr>\n<td>OutputParser</td>\n<td>The output of an LLM or ChatModel</td>\n<td>Depends on the parser</td>\n<td>输出解析器</td>\n</tr>\n<tr>\n<td>Retriever</td>\n<td>Single string</td>\n<td>List of Documents</td>\n<td>检索器</td>\n</tr>\n<tr>\n<td>Tool</td>\n<td>Single string or dictionary, depending on the tool</td>\n<td>Depends on the tool</td>\n<td>工具</td>\n</tr>\n</tbody></table>\n<p><strong>提示词</strong>： 很好理解，给模型的指令，完成某个任务，比如让模型写一首诗。</p>\n<p><strong>ChatModel</strong> ：使用消息序列作为输入并返回聊天消息作为输出（而不是使用纯文本）的语言模型。聊天模型支持为对话消息分配不同的角色，帮助区分来自AI、用户以及系统消息等指令的消息。用户和AI对话，支持聊天历史，AI有记忆。</p>\n<p><strong>LLM</strong>:以字符串作为输入并返回字符串的语言模型。AI没有记忆，通常是一锤子买卖，用于完成一次性任务。比如翻译一句话。</p>\n<p>注意：</p>\n<p><strong><code>ChatModel</code></strong> 类似于 <strong>OpenAI Chat</strong></p>\n<p><strong><code>LLM</code></strong> 类似于 <strong>OpenAI Completions</strong></p>\n<p><strong>Chat vs Completions</strong></p>\n<p>OpenAI的ChatCompletion和Completion都是自然语言生成模型的接口，但它们的用途和应用场景略有不同。</p>\n<h4 id=\"Completions\"><a href=\"#Completions\" class=\"headerlink\" title=\"Completions\"></a>Completions</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">通用的自然语言生成接口，支持生成各种类型的文本，包括段落、摘要、建议、答案等等。</span><br><span class=\"line\"></span><br><span class=\"line\">Completion接口的输出更为多样化，可能会更加严谨和专业，适用于各种文本生成场景，例如文章创作、信息提取、机器翻译、自然语言问题回答等等。</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Chat\"><a href=\"#Chat\" class=\"headerlink\" title=\"Chat\"></a>Chat</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">专为生成对话和聊天场景而设计。</span><br><span class=\"line\"></span><br><span class=\"line\">ChatCompletion接口生成的文本通常会更具有人类对话的风格和语调，可以用于智能客服、聊天机器人等场景，以及在日常聊天中帮助用户自动生成回复。</span><br></pre></td></tr></table></figure>\n\n<p><strong>输出解析器</strong>：处理大模型的输出，可以将输出转化成需要的格式，比如转化成特定的JSON格式，便于后续流程处理。</p>\n<p><strong>检索器</strong>：在langchain中，检索器通常和<strong>向量数据库</strong>、<strong>嵌入模型</strong>绑定，用于语义搜索。比如可以在本地向量数据库Chroma 中使用BGE-large的中文模型，对中文数据进行相似度搜索。</p>\n<p>工具： 通常是我们自己定义的，能够实现某种功能的方法。工具可以被大模型识别，当用户的需求需要 调用工具时，大模型会自动识别，并让我们调用工具。Langchain 中的Agent 可以自己识别并调用用户定义的工具。</p>\n<hr>\n<p><a href=\"https://python.langchain.com/v0.2/docs/concepts/\">组件</a>：</p>\n<p>这里的组件，是指langchain 工具包含的各个重要的“包”。主要是下面这个几个包：</p>\n<p><strong>langchain-core</strong></p>\n<p>这个包包含了不同组件的基础抽象以及如何将它们组合在一起的方法。在这里定义了LLMs、vectorstores、retrievers等核心组件的接口。</p>\n<p><strong>langchain</strong></p>\n<p>主要的langchain包，包含了构成应用程序认知架构的链、代理和检索策略。这里的所有链、代理和检索策略都不是特定于任何一种集成，而是适用于所有集成的通用类型。</p>\n<p><strong>langchain-community</strong></p>\n<p>这个包包含了由LangChain社区维护的第三方集成。关键的合作伙伴包已经被分离出去。这个包包含了各种组件（LLMs、vectorstores、retrievers）的所有集成。为了尽可能保持包的轻量级，这个包中的所有依赖关系都是可选的。各个模型厂商、向量数据库厂商的包，都在这里。</p>\n<p><strong>LangGraph</strong></p>\n<p>langgraph是langchain的一个扩展，旨在通过将步骤建模为图中的边和节点，使用LLMs构建健壮且具有状态的多参与者应用程序。</p>\n<p>提供了创建常见类型代理的<strong>高级接口</strong>，以及用于组合自定义流程的API。</p>\n<p><strong>也是在langchain中构建复杂Agent 逻辑的基础。</strong>（Langchain 的部分现成的Agent 就是用LangGraph 实现）</p>\n<p><strong>langserve</strong></p>\n<p>一个用于将LangChain链作为REST APIs部署的包。它使得快速启动并运行一个生产就绪的API变得简单。能够让我们快速搭建AI应用的前后端。</p>\n<p><strong>LangSmith</strong></p>\n<p>一个开发者平台，可以调试、测试、评估和监控LLM应用程序。</p>\n<hr>\n<p><a href=\"https://python.langchain.com/v0.2/docs/integrations/platforms/\">第三方集成</a> ：</p>\n<p>只要不是langchain 自己开发的，包括 大语言模型、嵌入模型、向量数据库、第三方工具等等，都属于第三方集成。</p>\n<p><a href=\"https://python.langchain.com/v0.2/docs/templates/\">模板</a>：</p>\n<p>langchain 提供的一些可以开箱体验的功能，类似于脚手架，安装之后可以立即体验。</p>\n<hr>\n<p>在正式接触langchain 之前，小伙伴们可以先到国内大厂的网站注册一下，Langchain官方的代码里</p>\n<p>国内模型作为例子的情况不多，我们主要使用国内的模型给大家介绍，小伙伴们需要先去注册一下。</p>\n<p>国内比较不错的模型（性价比高，部分模型免费）：</p>\n<p><strong>百度千帆大模型平台</strong> ： <a href=\"https://qianfan.cloud.baidu.com/\">传送门</a></p>\n<ul>\n<li>ERNIE 4.0 文心一言4</li>\n<li>ERNIE 3.5 文心一言3.5</li>\n<li>ERNIE Speed <strong>免费</strong></li>\n<li>ERNIE Lite <strong>免费</strong></li>\n<li>ERNIE Tiny <strong>免费</strong></li>\n</ul>\n<p><strong>智谱AI</strong> ： <a href=\"https://open.bigmodel.cn/\">传送门</a></p>\n<ul>\n<li>GLM-4-0520</li>\n<li>GLM-4-AirX</li>\n<li>GLM-4-Air</li>\n</ul>\n<p>**通义千问 （**DashScope灵积模型服务**）**： <a href=\"https://help.aliyun.com/zh/dashscope/developer-reference/api-details\">传送门</a></p>\n<ul>\n<li>qwen-turbo</li>\n<li>qwen-plus</li>\n<li>qwen-max</li>\n</ul>\n<p><strong>字节跳动 豆包模型</strong>： <a href=\"https://www.volcengine.com/product/doubao\">传送门</a></p>\n<ul>\n<li>Doubao-lite-4k</li>\n<li>Doubao-pro-32k</li>\n</ul>\n<p><strong>Moonshot</strong>：<a href=\"https://platform.moonshot.cn/docs/intro#%E4%B8%BB%E8%A6%81%E6%A6%82%E5%BF%B5\"> 传送门</a></p>\n<ul>\n<li>moonshot-v1-128k</li>\n<li>moonshot-v1-32k</li>\n</ul>\n","tags":["langchain"]},{"title":"LLama2大模型量化部署","url":"/forward/1f77414f.html","content":"<h1 id=\"Llama模型量化模型cpp部署\"><a href=\"#Llama模型量化模型cpp部署\" class=\"headerlink\" title=\"Llama模型量化模型cpp部署\"></a>Llama模型量化模型cpp部署</h1><h2 id=\"部署步骤\"><a href=\"#部署步骤\" class=\"headerlink\" title=\"部署步骤\"></a>部署步骤</h2><p>wsl下部署没啥装个Ubuntu22.04先。</p>\n<p>然后git clone两个项目。</p>\n<p>首先是llama的git项目</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/facebookresearch/llama.git</span><br></pre></td></tr></table></figure>\n\n<p>然后是cpp</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/ggerganov/llama.cpp.git</span><br></pre></td></tr></table></figure>\n\n<p>然后进入llama的项目</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> llama</span><br></pre></td></tr></table></figure>\n\n<p>然后去官网<a href=\"https://ai.meta.com/resources/models-and-libraries/llama-downloads/\">https://ai.meta.com/resources/models-and-libraries/llama-downloads/</a></p>\n<p>申请下载到邮箱</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">./download.sh</span><br></pre></td></tr></table></figure>\n\n<p>然后就是这样子</p>\n<p><img src=\"/images/pasted-1.png\" alt=\"upload successful\"></p>\n<p>等待模型下载完毕以后，进入llama.cpp</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> llama.cpp</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>先安装gcc环境</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo apt install build-essential</span><br></pre></td></tr></table></figure>\n\n<p>编译等待编译完成</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n\n<p>安装python依赖</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3 -m pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\n\n<p>转换模型，当然还有其他参数我们可以直接打开convert.py去查看</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3 convert.py <span class=\"string\">&#x27;模型地址&#x27;</span></span><br><span class=\"line\">python3 convert.py --outfile <span class=\"string\">&#x27;输出地址&#x27;</span> <span class=\"string\">&#x27;模型地址&#x27;</span></span><br><span class=\"line\">python3 convert.py --outfile ./models/llama-2-7b-chat ../llama/llama-2-7b-chat/</span><br></pre></td></tr></table></figure>\n\n<p>那么如果遇到以下问题</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">```bash</span><br><span class=\"line\">python3 haConvert.py --outfile ./models/llama-2-7b-chat ../llama/llama-2-7b-chat/</span><br><span class=\"line\">```</span><br><span class=\"line\">```error</span><br><span class=\"line\">Writing models/llama-2-7b-chat, format 1</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 1210, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    main()</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 1205, <span class=\"keyword\">in</span> main</span><br><span class=\"line\">    OutputFile.write_all(outfile, ftype, params, model, vocab, special_vocab, concurrency = args.concurrency, endianess=endianess)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 909, <span class=\"keyword\">in</span> write_all</span><br><span class=\"line\">    check_vocab_size(params, vocab)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 796, <span class=\"keyword\">in</span> check_vocab_size</span><br><span class=\"line\">    raise Exception(msg)</span><br><span class=\"line\">Exception: Vocab size mismatch (model has -1, but ../llama/tokenizer.model has 32000).</span><br><span class=\"line\">```</span><br></pre></td></tr></table></figure>\n\n<p>不要去相信网上的added_tokens.json</p>\n<p>实际上在llama-2-7b-chat文件夹中，应该有一个.json文件（可能是params.json）。打开这个json文件，将”vocab_size”从-1改为32000。</p>\n<p><img src=\"/images/pasted-0.png\" alt=\"upload successful\"></p>\n<h2 id=\"注意\"><a href=\"#注意\" class=\"headerlink\" title=\"注意\"></a>注意</h2><p>实际上最后输出的是一个.bin文件，所以我们上面的命令是有瑕疵的。</p>\n<p>所以当我们转换成功以后。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> models</span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> 7B</span><br><span class=\"line\"><span class=\"built_in\">mv</span> llama-2-7b-chat 7B/ggml-model-f16.bin</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"量化\"><a href=\"#量化\" class=\"headerlink\" title=\"量化\"></a>量化</h2><p>我们上面改为了bin这里也变成bin，我们执行的是4bit量化, 输出到./models/7B/目录下面</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">./quantize ./models/7B/ggml-model-f16.bin ./models/7B/ggml-model-q4_0.gguf q4_0</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">./main -m ./models/7B/ggml-model-q4_0.gguf -n 256 --repeat_penalty 1.0 --color -i -r <span class=\"string\">&quot;User:&quot;</span> -f prompts/chat-with-bob.txt</span><br></pre></td></tr></table></figure>","categories":["探索"],"tags":["大模型应用"]},{"title":"Langchain系列[04]表达式语言LCEL","url":"/forward/1f042660.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">- 了解LCEL包含的组件，可以调用的方法。</span><br><span class=\"line\"></span><br><span class=\"line\">- 链式调用基本形式</span><br></pre></td></tr></table></figure>\n\n<p><strong>LangChain 表达式语言（LCEL）是一种让用户能够更容易地组合不同链条的声明式编程方式。</strong></p>\n<p><strong>之前我们介绍了chain 中的组件，这个文档来明确一下组件之间的输入和输出</strong></p>\n<p>LCEL 从一开始就是为了支持将原型直接投入生产而设计的，无需修改任何代码。这适用于从最简单的“提示+大语言模型”链条到最复杂的链条（我们已经看到有人成功在生产环境中运行包含数百个步骤的 LCEL 链条）。以下是您可能想使用 LCEL 的几个原因：</p>\n<ol>\n<li><p><strong>流支持</strong>：使用 LCEL 构建链条时，<strong>您可以从第一个令牌开始就获得最快的响应时间</strong>（即从输出开始到第一个数据块出现的时间）。对于某些链条来说，这意味着我们可以直接从大语言模型向输出解析器发送令牌流，您将以与模型提供者输出原始令牌相同的速度接收到解析后的数据块。</p>\n</li>\n<li><p><strong>异步支持</strong>：使用 LCEL 构建的任何链条都可以通过同步 API（例如，在 Jupyter  笔记本中测试原型）或异步 API（例如，在 LangServe  服务器中）调用。这使得您可以使用相同的代码进行原型设计和生产，同时还能保持出色的性能，并能在同一服务器上处理多个并发请求。</p>\n<blockquote>\n<p>同步 API：当您在 Jupyter 笔记本或其他环境中直接调用链条时，您会使用同步 API。这种方式会阻塞当前进程，直到链条执行完毕并返回结果。这适合于原型设计和开发阶段，因为它允许您立即看到每个步骤的结果。</p>\n</blockquote>\n<blockquote>\n<p>异步 API：在生产环境中，您通常希望处理多个请求而不会阻塞主进程。这时，您可以使用异步  API。当您通过异步方式调用链条时，请求会立即返回一个唯一标识符或“任务ID”，而不是阻塞并等待结果。您可以在稍后的时间点，使用这个任务ID来检查链条的状态或获取结果。这种方式允许服务器同时处理多个请求，从而提高了效率和性能。</p>\n</blockquote>\n</li>\n<li><p><strong>并行执行优化</strong>：当 LCEL 链条中有可以并行执行的步骤（例如，从多个检索器获取文档）时，系统会自动进行优化，无论是在同步还是异步接口中，都能实现最小的延迟。</p>\n</li>\n<li><p>重试和回退：您可以为 LCEL 链条的任何部分配置重试和回退策略。这是在大规模应用中提高链条可靠性的好方法。我们目前正在为重试和回退添加流支持，这样您就可以在不增加延迟的情况下获得更高的可靠性。</p>\n</li>\n<li><p><strong>访问中间结果</strong>：对于复杂的链条，通常在最终输出完成之前访问中间步骤的结果是非常有用的。这可以用来通知最终用户正在发生的事情，或者只是用来调试您的链条。您可以流式传输中间结果，并且可以在每个 LangServe 服务器上使用。</p>\n</li>\n<li><p><strong>输入和输出架构</strong>：LCEL 链条都有 Pydantic 和 JSONSchema 架构，这些架构是从链条的结构中自动推断出来的。这可以用来验证输入和输出，并且是 LangServe 不可或缺的一部分。</p>\n</li>\n<li><p>与 LangSmith 的无缝集成：随着链条变得越来越复杂，了解每个步骤的具体情况变得越来越重要。使用 LCEL，所有步骤都会自动记录到 LangSmith 中，以便进行最大程度的监控和调试。</p>\n</li>\n<li><p>与 LangServe 的无缝部署集成：使用 LCEL 创建的任何链条都可以轻松地通过 LangServe 部署。</p>\n</li>\n</ol>\n<hr>\n<h1 id=\"快速开始\"><a href=\"#快速开始\" class=\"headerlink\" title=\"快速开始\"></a>快速开始</h1><p>基础链: prompt + model + output parser</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 环境设置</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># chatModel</span></span><br><span class=\"line\">model = QianfanChatEndpoint(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 提示词</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_template(<span class=\"string\">&quot;给我讲一个关于&#123;topic&#125;的笑话&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出解析器</span></span><br><span class=\"line\">output_parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基本链</span></span><br><span class=\"line\">chain = prompt | model | output_parser</span><br><span class=\"line\"></span><br><span class=\"line\">res = chain.invoke(&#123;<span class=\"string\">&quot;topic&quot;</span>: <span class=\"string\">&quot;冰淇淋&quot;</span>&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\">----</span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">当然可以，这是一个关于冰淇淋的笑话：...</span><br><span class=\"line\">----</span><br></pre></td></tr></table></figure>\n\n<p>这里的 “|” 符号有点像 Unix  系统中的管道操作符，它把不同的部分连接起来，把一个部分的输出作为下一个部分的输入。在这个流程中，用户输入首先传给提示模板，然后提示模板的输出传给模型，模型的输出再传给输出解析器。我们来逐一看看每个部分，以便更好地理解整个流程。</p>\n<hr>\n<ol>\n<li>提示词（Prompt） 提示是一个基础的提示模板（BasePromptTemplate），这意味着它接收一个模板变量的字典，并生成一个提示值（PromptValue）。提示值是对已完成提示的包装，可以传递给大语言模型（LLM，它接受字符串作为输入）或聊天模型（ChatModel，它接受一系列的消息作为输入）。它能够与任何语言模型类型配合工作，因为它定义了生成基础消息（BaseMessages）和生成字符串的逻辑。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 提示词</span></span><br><span class=\"line\">prompt_value = prompt.invoke(&#123;<span class=\"string\">&quot;topic&quot;</span>: <span class=\"string\">&quot;冰淇淋&quot;</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">cp_value = ChatPromptValue(messages=[HumanMessage(content=<span class=\"string\">&#x27;给我讲一个关于冰淇淋的笑话&#x27;</span>)])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># prompt_value 和 cp_value 相同</span></span><br><span class=\"line\"></span><br><span class=\"line\">message = prompt_value.to_messages()</span><br><span class=\"line\"><span class=\"comment\"># 输出 [content=&#x27;给我讲一个关于冰淇淋的笑话&#x27;]</span></span><br><span class=\"line\"></span><br><span class=\"line\">pr0_str = prompt_value.to_string()</span><br><span class=\"line\"><span class=\"comment\"># 输出  &#x27;Human: 给我讲一个关于冰淇淋的笑话&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>模型（Model） 提示词接着被传递给模型。在这个例子中，我们的模型是一个聊天模型（ChatModel），这意味着它将输出一个基础消息（BaseMessage）。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">model = QianfanChatEndpoint(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\">...</span><br><span class=\"line\">message = model.invoke(prompt_value)</span><br><span class=\"line\"><span class=\"comment\"># message 是一个 AIMessage类的对象</span></span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>输出解析器（Output parser） 最后，我们将模型输出传递给输出解析器，它是一个基础的输出解析器（BaseOutputParser），这意味着它接受字符串或基础消息（BaseMessage）作为输入。StrOutputParser 特别是将任何输入简单转换为字符串。</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 解析器</span></span><br><span class=\"line\">output_parser = StrOutputParser()</span><br><span class=\"line\">res = output_parser.invoke(message)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出 ：当然可以，这是一个关于冰淇淋的笑话...</span></span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>整个流程（Entire Pipeline） 让我们一步一步地跟随这个过程：</li>\n</ol>\n<ul>\n<li>首先，我们输入用户对所需主题的输入，例如 **{“topic”: “ice cream”}**。</li>\n<li>提示组件接收用户输入，并使用该主题来构建提示，然后生成一个 <strong>PromptValue</strong>。</li>\n<li>模型组件接收生成的提示，并将其传递给 OpenAI 大语言模型进行评估。模型生成的输出是一个 <strong>ChatMessage</strong> 对象。</li>\n<li>最后，输出解析器组件接收一个 ChatMessage，并将其转换成一个 Python <strong>字符串</strong>，这个字符串从 invoke 方法中返回。</li>\n</ul>\n<p>可以这么调用么？</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># res = chain.invoke(&#123;&quot;topic&quot;: &quot;冰淇淋&quot;&#125;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 注意，由于需要指定参数，下面这样调用是不行的</span></span><br><span class=\"line\">res = chain.invoke(<span class=\"string\">&quot;冰淇淋&quot;</span>)  &lt;--------- 不行</span><br></pre></td></tr></table></figure>\n\n<p>需要指定参数传给谁 （RunnablePassthrough() 从输入接收参数，传递给topic）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;topic&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | model</span><br><span class=\"line\">        | output_parser</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chain.invoke(<span class=\"string\">&quot;冰淇淋&quot;</span>) &lt;----------可以</span><br></pre></td></tr></table></figure>\n\n<p><strong>检索流程 （了解一下，后面详解）</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 千帆嵌入模型</span></span><br><span class=\"line\">embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据库</span></span><br><span class=\"line\">vector_store = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建检索器</span></span><br><span class=\"line\">retriever = vector_store.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 提示词</span></span><br><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | model</span><br><span class=\"line\">        | output_parser</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chain.invoke(<span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompt_values <span class=\"keyword\">import</span> ChatPromptValue</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    model = QianfanChatEndpoint(</span><br><span class=\"line\">        model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_template(<span class=\"string\">&quot;给我讲一个关于&#123;topic&#125;的笑话&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    output_parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\">    chain = prompt | model | output_parser</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># res = chain.invoke(&#123;&quot;topic&quot;: &quot;冰淇淋&quot;&#125;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 注意，由于需要指定参数，下面这样调用是不行的</span></span><br><span class=\"line\">    <span class=\"comment\"># res = chain.invoke(&quot;冰淇淋&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;topic&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | model</span><br><span class=\"line\">            | output_parser</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># res = chain.invoke(&quot;冰淇淋&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># print(res)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词</span></span><br><span class=\"line\">    prompt_value = prompt.invoke(&#123;<span class=\"string\">&quot;topic&quot;</span>: <span class=\"string\">&quot;冰淇淋&quot;</span>&#125;)</span><br><span class=\"line\">    prompt_value</span><br><span class=\"line\"></span><br><span class=\"line\">    cp_value = ChatPromptValue(messages=[HumanMessage(content=<span class=\"string\">&#x27;给我讲一个关于冰淇淋的笑话&#x27;</span>)])</span><br><span class=\"line\"></span><br><span class=\"line\">    message = prompt_value.to_messages()</span><br><span class=\"line\"></span><br><span class=\"line\">    pr0_str = prompt_value.to_string()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 模型</span></span><br><span class=\"line\">    message = model.invoke(prompt_value)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(message)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析器</span></span><br><span class=\"line\">    output_parser = StrOutputParser()</span><br><span class=\"line\">    res = output_parser.invoke(message)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 检索chain</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆嵌入模型</span></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 载入本地向量数据库 Chr</span></span><br><span class=\"line\">    vector_store = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 创建检索器</span></span><br><span class=\"line\">    retriever = vector_store.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词</span></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class=\"line\"><span class=\"string\">    &#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;context&quot;</span>: retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | model</span><br><span class=\"line\">            | output_parser</span><br><span class=\"line\">    )</span><br><span class=\"line\">    res = chain.invoke(<span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[05]runnable系列函数","url":"/forward/a587df74.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>为了帮助小伙伴们更好的发挥chain 的作用以及增加chain 的灵活性，有一些函数可以参与到chain的各环节，这个文档来给大家介绍一下~</p>\n<ul>\n<li><strong>RunnableParallel</strong></li>\n<li><strong>RunnablePassthrough</strong></li>\n<li><strong>RunnableLambda</strong></li>\n<li><strong>RunnableBranch</strong></li>\n</ul>\n<hr>\n<h3 id=\"RunnableParallel\"><a href=\"#RunnableParallel\" class=\"headerlink\" title=\"RunnableParallel\"></a><strong>RunnableParallel</strong></h3><p>RunnableParallel 在将一个 Runnable 的输出调整为符合序列中下一个 Runnable 的输入格式时非常有用。在这里，提示（prompt）的输入预期是一个<strong>包含“context”和“question”键的映射（map）</strong>。用户输入仅仅是问题（question）。我们需要使用我们的检索器（retriever）获取上下文（context），并将用户输入作为“question”键下的值传递过去。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 提示词</span></span><br><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | model</span><br><span class=\"line\">        | output_parser</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chain.invoke(<span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 问题  下面这样可以么？</span></span><br><span class=\"line\">res = chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">不行，相当于：<span class=\"string\">&quot;question&quot;</span>:&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 可以是这样</span></span><br><span class=\"line\">&#123;<span class=\"string\">&quot;context&quot;</span>: retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以是这样</span></span><br><span class=\"line\">RunnableParallel(&#123;<span class=\"string\">&quot;context&quot;</span>: retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以是这样</span></span><br><span class=\"line\">RunnableParallel(context=retriever, question=RunnablePassthrough())</span><br></pre></td></tr></table></figure>\n\n<p><strong>重点： 还可以</strong>通过itemgetter 获得环境中的Key 值</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">chain = (</span><br><span class=\"line\">        <span class=\"comment\"># 原来是这样 &#123;&quot;context&quot;: retriever, &quot;question&quot;: RunnablePassthrough()&#125;</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;context&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>) | retriever, &lt;----------</span><br><span class=\"line\">            <span class=\"string\">&quot;question&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>), &lt;---------</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | model</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chain.invoke(<span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>并发执行chain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">joke_chain = ChatPromptTemplate.from_template(<span class=\"string\">&quot;告诉我一个关于 &#123;topic&#125;的笑话&quot;</span>) | model</span><br><span class=\"line\">topic_chain = (</span><br><span class=\"line\">        ChatPromptTemplate.from_template(<span class=\"string\">&quot;告诉我一个关于&#123;topic&#125;的话题&quot;</span>) | model</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">map_chain = RunnableParallel(joke=joke_chain, topic=topic_chain)</span><br><span class=\"line\"></span><br><span class=\"line\">res = map_chain.invoke(&#123;<span class=\"string\">&quot;topic&quot;</span>: <span class=\"string\">&quot;冰淇淋&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"RunnablePassthrough\"><a href=\"#RunnablePassthrough\" class=\"headerlink\" title=\"RunnablePassthrough\"></a><strong>RunnablePassthrough</strong></h3><p>RunnablePassthrough 允许您原封不动地传递输入，或者添加额外的键。这通常与 RunnableParallel 一起使用，以便在映射中为数据分配一个新的键。 当单独调用 RunnablePassthrough() 时，它只会简单地接收输入并直接传递出去。 当调用 RunnablePassthrough 的 assign 方法（RunnablePassthrough.assign(…)）时，它会接收输入，并将传递给 assign 函数的额外参数添加到输入中。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># RunnablePassthrough</span></span><br><span class=\"line\">runnable = RunnableParallel(</span><br><span class=\"line\">    passed=RunnablePassthrough(),</span><br><span class=\"line\">    extra=RunnablePassthrough.assign(mult=<span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;num&quot;</span>] * <span class=\"number\">3</span>),</span><br><span class=\"line\">    modified=<span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;num&quot;</span>] + <span class=\"number\">1</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">runnable.invoke(&#123;<span class=\"string\">&quot;num&quot;</span>: <span class=\"number\">1</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">------</span><br><span class=\"line\"><span class=\"comment\"># 结果</span></span><br><span class=\"line\">&#123;<span class=\"string\">&#x27;extra&#x27;</span>: &#123;<span class=\"string\">&#x27;mult&#x27;</span>: <span class=\"number\">3</span>, <span class=\"string\">&#x27;num&#x27;</span>: <span class=\"number\">1</span>&#125;, <span class=\"string\">&#x27;modified&#x27;</span>: <span class=\"number\">2</span>, <span class=\"string\">&#x27;passed&#x27;</span>: &#123;<span class=\"string\">&#x27;num&#x27;</span>: <span class=\"number\">1</span>&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"RunnableLambda\"><a href=\"#RunnableLambda\" class=\"headerlink\" title=\"RunnableLambda\"></a><strong>RunnableLambda</strong></h3><p>您可以在管道中使用任意函数。 请注意，所有输入到这些函数的参数需要是单个参数。如果您有一个接受多个参数的函数，您应该编写一个包装器，该包装器接受单个输入并将其解包为多个参数。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs_into_text</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">    doc_size = <span class=\"built_in\">len</span>(docs)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;收到 &#123;&#125; 个文档&#x27;</span>.<span class=\"built_in\">format</span>(doc_size))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> docs</span><br><span class=\"line\">chain = (</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;context&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>) | retriever | RunnableLambda(format_docs_into_text),</span><br><span class=\"line\">            <span class=\"string\">&quot;question&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | model</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>2个函数都能正常调用，差异在哪？</p>\n<p>函数直接返回Document 对象：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs_into_text</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">    doc_size = <span class=\"built_in\">len</span>(docs)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;收到 &#123;&#125; 个文档&#x27;</span>.<span class=\"built_in\">format</span>(doc_size))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> docs</span><br></pre></td></tr></table></figure>\n\n<p>函数直接返回字符串：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs_into_text2</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">    doc_size = <span class=\"built_in\">len</span>(docs)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;收到 &#123;&#125; 个文档&#x27;</span>.<span class=\"built_in\">format</span>(doc_size))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>生成的提示词不同</p>\n<p><strong>直接返回docs 的情况</strong></p>\n<p>[HumanMessage(content=”Answer the question based only on the following context:\\n        [<strong>Document</strong>(page_content=’LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô …</p>\n<p><strong>返回字符串的情况</strong></p>\n<p>[HumanMessage(content=’Answer the question based only on the following context:\\n        <strong>LangSmith User Guide |</strong> \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\nLangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ</p>\n<hr>\n<h3 id=\"RunnableBranch\"><a href=\"#RunnableBranch\" class=\"headerlink\" title=\"RunnableBranch\"></a><strong>RunnableBranch</strong></h3><p>1个决策chain  + 3个分支 chain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 三个分支： langchain \\ 百度 \\  缺省</span></span><br><span class=\"line\"></span><br><span class=\"line\">    langchain_chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;&quot;&quot;你是langchain 专家，回答下面的问题:</span></span><br><span class=\"line\"><span class=\"string\">                问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">                回答:&quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">    )</span><br><span class=\"line\">    baidu_chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;&quot;&quot;你是百度AI专家，回答下面的问题:</span></span><br><span class=\"line\"><span class=\"string\">                问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">                回答:&quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">    )</span><br><span class=\"line\">    general_chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">            <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            回答下面的问题：&#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">            &quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 选择分支</span></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;&quot;&quot;基于用户问题，选择这个问题是属于 `LangChain`, `百度`, or `其他`.</span></span><br><span class=\"line\"><span class=\"string\">        不要返回多余的词。</span></span><br><span class=\"line\"><span class=\"string\">        &lt;question&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;/question&gt;</span></span><br><span class=\"line\"><span class=\"string\">        分类:&quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br></pre></td></tr></table></figure>\n\n<p>选择分支</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">route</span>(<span class=\"params\">info</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&quot;百度&quot;</span> <span class=\"keyword\">in</span> info[<span class=\"string\">&quot;topic&quot;</span>].lower():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> baidu_chain</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"string\">&quot;langchain&quot;</span> <span class=\"keyword\">in</span> info[<span class=\"string\">&quot;topic&quot;</span>].lower():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> langchain_chain</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> general_chain</span><br><span class=\"line\"><span class=\"comment\"># ---------------</span></span><br><span class=\"line\"><span class=\"comment\"># 结果</span></span><br><span class=\"line\">&#123;<span class=\"string\">&#x27;question&#x27;</span>: <span class=\"string\">&#x27;我如何使用百度？&#x27;</span>, <span class=\"string\">&#x27;topic&#x27;</span>: <span class=\"string\">&#x27;百度&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>整个链路</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">full_chain = &#123;<span class=\"string\">&quot;topic&quot;</span>: chain, <span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125; | RunnableLambda(</span><br><span class=\"line\">    route</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">res = full_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;我如何使用百度？&quot;</span>&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> uuid</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompt_values <span class=\"keyword\">import</span> ChatPromptValue</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate, PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough, RunnableParallel, RunnableLambda</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> operator <span class=\"keyword\">import</span> itemgetter</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    unique_id = uuid.uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [返回docs]轨迹 - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    model = QianfanChatEndpoint(</span><br><span class=\"line\">        model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 检索chain</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆嵌入模型</span></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 载入数据库</span></span><br><span class=\"line\">    vector_store = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 创建检索器</span></span><br><span class=\"line\">    retriever = vector_store.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词</span></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class=\"line\"><span class=\"string\">        &#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">        Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            <span class=\"comment\"># 原来是这样 &#123;&quot;context&quot;: retriever, &quot;question&quot;: RunnablePassthrough()&#125;</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;context&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>) | retriever,</span><br><span class=\"line\">                <span class=\"string\">&quot;question&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | model</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># res = chain.invoke(&quot;how can langsmith help with testing?&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># print(res)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 并行执行</span></span><br><span class=\"line\">    joke_chain = ChatPromptTemplate.from_template(<span class=\"string\">&quot;告诉我一个关于 &#123;topic&#125;的笑话&quot;</span>) | model</span><br><span class=\"line\">    topic_chain = (</span><br><span class=\"line\">            ChatPromptTemplate.from_template(<span class=\"string\">&quot;告诉我一个关于&#123;topic&#125;的话题&quot;</span>) | model</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    map_chain = RunnableParallel(joke=joke_chain, topic=topic_chain)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># res = map_chain.invoke(&#123;&quot;topic&quot;: &quot;冰淇淋&quot;&#125;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># RunnablePassthrough</span></span><br><span class=\"line\">    runnable = RunnableParallel(</span><br><span class=\"line\">        passed=RunnablePassthrough(),</span><br><span class=\"line\">        extra=RunnablePassthrough.assign(mult=<span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;num&quot;</span>] * <span class=\"number\">3</span>),</span><br><span class=\"line\">        modified=<span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;num&quot;</span>] + <span class=\"number\">1</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># res = runnable.invoke(&#123;&quot;num&quot;: 1&#125;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#RunnableLambda</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">format_docs_into_text</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">        doc_size = <span class=\"built_in\">len</span>(docs)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;收到 &#123;&#125; 个文档&#x27;</span>.<span class=\"built_in\">format</span>(doc_size))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> docs</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">format_docs_into_text2</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">        doc_size = <span class=\"built_in\">len</span>(docs)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;收到 &#123;&#125; 个文档&#x27;</span>.<span class=\"built_in\">format</span>(doc_size))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;context&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>) | retriever | RunnableLambda(format_docs_into_text),</span><br><span class=\"line\">                <span class=\"string\">&quot;question&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | model</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    chain_test = (</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;context&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>) | retriever | RunnableLambda(format_docs_into_text),</span><br><span class=\"line\">                <span class=\"string\">&quot;question&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">    )</span><br><span class=\"line\">    res = chain_test.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    chain_test_2 = (</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;context&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>) | retriever | RunnableLambda(format_docs_into_text2),</span><br><span class=\"line\">                <span class=\"string\">&quot;question&quot;</span>: itemgetter(<span class=\"string\">&quot;question&quot;</span>),</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">    )</span><br><span class=\"line\">    res = chain_test_2.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    res = chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;how can langsmith help with testing?&quot;</span>&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># RunnableBranch</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 三个分支： langchain \\ 百度 \\  缺省</span></span><br><span class=\"line\"></span><br><span class=\"line\">    langchain_chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;&quot;&quot;你是langchain 专家，回答下面的问题:</span></span><br><span class=\"line\"><span class=\"string\">                问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">                回答:&quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">    )</span><br><span class=\"line\">    baidu_chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;&quot;&quot;你是百度AI专家，回答下面的问题:</span></span><br><span class=\"line\"><span class=\"string\">                问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">                回答:&quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">    )</span><br><span class=\"line\">    general_chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">            <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            回答下面的问题：&#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">            &quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 选择分支</span></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            PromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;&quot;&quot;基于用户问题，选择这个问题是属于 `LangChain`, `百度`, or `其他`.</span></span><br><span class=\"line\"><span class=\"string\">        不要返回多余的词。</span></span><br><span class=\"line\"><span class=\"string\">        &lt;question&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;/question&gt;</span></span><br><span class=\"line\"><span class=\"string\">        分类:&quot;&quot;&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\">            | model</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 情况判断</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">route</span>(<span class=\"params\">info</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&quot;百度&quot;</span> <span class=\"keyword\">in</span> info[<span class=\"string\">&quot;topic&quot;</span>].lower():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> baidu_chain</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"string\">&quot;langchain&quot;</span> <span class=\"keyword\">in</span> info[<span class=\"string\">&quot;topic&quot;</span>].lower():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> langchain_chain</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> general_chain</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    full_chain = &#123;<span class=\"string\">&quot;topic&quot;</span>: chain, <span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125; | RunnableLambda(</span><br><span class=\"line\">        route</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    res = full_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"string\">&quot;我如何使用百度？&quot;</span>&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[06]语言模型","url":"/forward/fa3d6d2f.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p><strong>模型入门</strong></p>\n<p>Langchain 2.0 都找不到下面这个图了，藏到了1.0 里面…</p>\n<p><strong>语言模型</strong>是核心，我们需要熟悉跟语言模型相关的消息：系统消息、AI消息、Human消息、工具消息…</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-06-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.assets/image-20240627100437691.png\" alt=\"image-20240627100437691\"></p>\n<p><strong>llm</strong> vs  <strong>chatModel</strong></p>\n<p><strong><code>百度千帆</code></strong></p>\n<p><strong>对话</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">chat_comp = qianfan.ChatCompletion(access_key=<span class=\"string\">&quot;...&quot;</span>, secret_key=<span class=\"string\">&quot;...&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 调用默认模型，即 ERNIE-Bot-turbo</span></span><br><span class=\"line\">resp = chat_comp.do(messages=[&#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你好&quot;</span></span><br><span class=\"line\">&#125;])</span><br></pre></td></tr></table></figure>\n\n<p><strong>完成</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">comp = qianfan.Completion()</span><br><span class=\"line\"></span><br><span class=\"line\">resp = comp.do(model=<span class=\"string\">&quot;ERNIE-Bot&quot;</span>, prompt=<span class=\"string\">&quot;你好&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 输出：你好！有什么我可以帮助你的吗？</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 续写功能同样支持流式调用</span></span><br><span class=\"line\">resp = comp.do(model=<span class=\"string\">&quot;ERNIE-Bot&quot;</span>, prompt=<span class=\"string\">&quot;你好&quot;</span>, stream=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> resp:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(r[<span class=\"string\">&#x27;result&#x27;</span>])</span><br></pre></td></tr></table></figure>\n\n<p><strong><code>Azure Openai</code></strong></p>\n<p><strong>完成</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">start_phrase = <span class=\"string\">&#x27;Write a tagline for an ice cream shop. &#x27;</span></span><br><span class=\"line\">response = openai.Completion.create(engine=deployment_name, prompt=start_phrase, max_tokens=<span class=\"number\">10</span>)</span><br><span class=\"line\">text = response[<span class=\"string\">&#x27;choices&#x27;</span>][<span class=\"number\">0</span>][<span class=\"string\">&#x27;text&#x27;</span>].replace(<span class=\"string\">&#x27;\\n&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>).replace(<span class=\"string\">&#x27; .&#x27;</span>, <span class=\"string\">&#x27;.&#x27;</span>).strip()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(start_phrase+text)</span><br></pre></td></tr></table></figure>\n\n<p><strong>对话</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">response = openai.ChatCompletion.create(</span><br><span class=\"line\">    engine=<span class=\"string\">&quot;gpt-35-turbo&quot;</span>, <span class=\"comment\"># engine = &quot;deployment_name&quot;.</span></span><br><span class=\"line\">    messages=[</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;Does Azure OpenAI support customer managed keys?&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;assistant&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;Yes, customer managed keys are supported by Azure OpenAI.&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;Do other Azure AI services support this too?&quot;</span>&#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>消息</strong> <strong>ChatModels</strong>  接收一个消息列表作为输入，并返回一个消息。消息有几种不同的类型。所有消息都有一个角色（role）和一个内容（content）属性。角色描述了是谁在说话。LangChain 为不同的角色提供了不同的消息类。内容属性描述了消息的内容。这可以是以下几种不同的东西：</p>\n<ul>\n<li>一个字符串（大多数模型都是这种方式）</li>\n<li>一个字典列表（这用于多模态输入，其中字典包含有关该输入类型和位置的信息） 此外，消息还有一个 additional_kwargs 属性。这是传递关于消息的额外信息的地方。这主要用于特定于提供商的输入参数，而不是通用的。最著名的例子是 OpenAI 的 function_call。</li>\n</ul>\n<p><code>人类消息</code>（HumanMessage） 这代表用户的消息。通常只包含内容。</p>\n<p><code>AI消息</code>（AIMessage） 这代表模型的消息。这可能有 additional_kwargs ——例如，如果使用 OpenAI 函数调用，则可能有 functional_call。</p>\n<p><code>系统消息</code>（SystemMessage） 这代表系统消息。只有一些模型支持这个。这告诉模型如何表现。这通常只包含内容。</p>\n<p><code>函数消息</code>（FunctionMessage） 这代表函数调用的结果。除了角色和内容之外，这个消息还有一个 name 参数，它传达了产生这个结果的函数的名称。</p>\n<p><code>工具消息</code>（ToolMessage） 这代表工具调用的结果。这与 FunctionMessage 是不同的，以匹配 OpenAI 的函数和工具消息类型。除了角色和内容之外，这个消息还有一个 tool_call_id 参数，它传达了产生这个结果的工具调用的 id。</p>\n<hr>\n<p>函数调用 function call</p>\n<p>定义函数： 将2个数相加</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">function = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;add_two_int&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;将输入的2个整数相加&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;int_a&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;一个整数&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">&quot;int_b&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;一个整数&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;int_a&quot;</span>, <span class=\"string\">&quot;int_b&quot;</span>]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>绑定模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">chat_with_tools = azure_chat.bind(</span><br><span class=\"line\">  function_call=&#123;<span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;add_two_int&quot;</span>&#125;, functions=[function]</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chat_with_tools.invoke(<span class=\"string\">&quot;3加18等于多少&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;<span class=\"string\">&#x27;function_call&#x27;</span>: </span><br><span class=\"line\"> &#123;<span class=\"string\">&#x27;arguments&#x27;</span>: <span class=\"string\">&#x27;&#123;\\n  &quot;int_a&quot;: &quot;3&quot;,\\n  &quot;int_b&quot;: &quot;18&quot;\\n&#125;&#x27;</span>, <span class=\"string\">&#x27;name&#x27;</span>: <span class=\"string\">&#x27;add_two_int&#x27;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>绑定运行时参数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 运行时配置参数</span></span><br><span class=\"line\">res = azure_chat.with_config(configurable=&#123;<span class=\"string\">&quot;llm_temperature&quot;</span>: <span class=\"number\">0.9</span>&#125;).invoke(<span class=\"string\">&quot;给出一个随机数&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置多个模型，运行时根据需求调用</span></span><br><span class=\"line\">llm = QianfanChatEndpoint(temperature=<span class=\"number\">0.7</span>).configurable_alternatives(</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 设置可以配置的项目</span></span><br><span class=\"line\">    ConfigurableField(<span class=\"built_in\">id</span>=<span class=\"string\">&quot;llm&quot;</span>),</span><br><span class=\"line\">    <span class=\"comment\"># 设置缺省值，默认用百度</span></span><br><span class=\"line\">    default_key=<span class=\"string\">&quot;baidu4&quot;</span>,</span><br><span class=\"line\">    <span class=\"comment\"># 可以选择 Azure OpenAI</span></span><br><span class=\"line\">    azure_openai=azure_chat,</span><br><span class=\"line\">)</span><br><span class=\"line\">chain = prompt | llm</span><br><span class=\"line\"><span class=\"comment\"># 调用百度</span></span><br><span class=\"line\">res_ = chain.with_config(configurable=&#123;<span class=\"string\">&quot;llm&quot;</span>: <span class=\"string\">&quot;baidu4&quot;</span>&#125;).invoke(&#123;<span class=\"string\">&quot;product&quot;</span>: <span class=\"string\">&quot;铅笔&quot;</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 调用 Azure Opena</span></span><br><span class=\"line\">res_ = chain.with_config(configurable=&#123;<span class=\"string\">&quot;llm&quot;</span>: <span class=\"string\">&quot;azure_openai&quot;</span>&#125;).invoke(&#123;<span class=\"string\">&quot;product&quot;</span>: <span class=\"string\">&quot;铅笔&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>聊天模型接受消息作为输入，并返回一个消息作为输出。</strong> LangChain 有一些内置的消息类型： 系统消息（SystemMessage）：用于引导 AI 行为，通常作为输入消息序列中的第一个消息传递。 人类消息（HumanMessage）：代表与聊天模型互动的人的消息。 AI消息（AIMessage）：代表聊天模型的消息。这可以是文本或调用工具的请求。 函数消息/工具消息（FunctionMessage / ToolMessage）：用于将工具调用的结果传递回模型的消息。</p>\n<p><strong>让chat 有记忆：维护一个消息列表</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">response = openai.ChatCompletion.create(</span><br><span class=\"line\">    engine=<span class=\"string\">&quot;gpt-35-turbo&quot;</span>, <span class=\"comment\"># engine = &quot;deployment_name&quot;.</span></span><br><span class=\"line\">    messages=[</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;Does Azure OpenAI support customer managed keys?&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;assistant&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;Yes, customer managed keys are supported by Azure OpenAI.&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;Do other Azure AI services support this too?&quot;</span>&#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>在提示词中保存对话内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">    [</span><br><span class=\"line\">        (<span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;你是AI助手&quot;</span>),</span><br><span class=\"line\">        MessagesPlaceholder(variable_name=<span class=\"string\">&quot;history&quot;</span>), &lt;---虚位以待</span><br><span class=\"line\">        (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;input&#125;&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">memory = ConversationBufferMemory(return_messages=<span class=\"literal\">True</span>) &lt;-- 想象成一个<span class=\"built_in\">list</span></span><br><span class=\"line\">res = memory.load_memory_variables(&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">   ------</span><br><span class=\"line\">    <span class=\"comment\"># 内容 &#123;&#x27;history&#x27;: []&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>保存对话记录</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">inputs = &#123;<span class=\"string\">&quot;input&quot;</span>: <span class=\"string\">&quot;你好！我是茉卷&quot;</span>&#125;</span><br><span class=\"line\">response = chain.invoke(inputs)</span><br><span class=\"line\"></span><br><span class=\"line\">memory.save_context(inputs, &#123;<span class=\"string\">&quot;output&quot;</span>: response.content&#125;)</span><br><span class=\"line\">res = memory.load_memory_variables(&#123;&#125;)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">    inputs = &#123;<span class=\"string\">&quot;input&quot;</span>: <span class=\"string\">&quot;我叫什么名字&quot;</span>&#125;</span><br><span class=\"line\">    response = chain.invoke(inputs)</span><br><span class=\"line\">content=<span class=\"string\">&#x27;你叫茉卷。如果你有其他疑问或者需要帮助，请随时告诉我，我会尽力为你服务。&#x27;</span> additional_kwargs=&#123;<span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;normal&#x27;</span>, <span class=\"string\">&#x27;request_id&#x27;</span>: <span class=\"string\">&#x27;as-jjdgubp1k9&#x27;</span>, <span class=\"string\">&#x27;object&#x27;</span>: <span class=\"string\">&#x27;chat.completion&#x27;</span>, <span class=\"string\">&#x27;search_info&#x27;</span>: []&#125; response_metadata=&#123;<span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;normal&#x27;</span>, <span class=\"string\">&#x27;id&#x27;</span>: <span class=\"string\">&#x27;as-jjdgubp1k9&#x27;</span>, <span class=\"string\">&#x27;object&#x27;</span>: <span class=\"string\">&#x27;chat.completion&#x27;</span>, <span class=\"string\">&#x27;created&#x27;</span>: <span class=\"number\">1711101413</span>, <span class=\"string\">&#x27;result&#x27;</span>: <span class=\"string\">&#x27;你叫茉卷。如果你有其他疑问或者需要帮助，请随时告诉我，我会尽力为你服务。&#x27;</span>, <span class=\"string\">&#x27;is_truncated&#x27;</span>: <span class=\"literal\">False</span>, <span class=\"string\">&#x27;need_clear_history&#x27;</span>: <span class=\"literal\">False</span>, <span class=\"string\">&#x27;usage&#x27;</span>: &#123;<span class=\"string\">&#x27;prompt_tokens&#x27;</span>: <span class=\"number\">37</span>, <span class=\"string\">&#x27;completion_tokens&#x27;</span>: <span class=\"number\">19</span>, <span class=\"string\">&#x27;total_tokens&#x27;</span>: <span class=\"number\">56</span>&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>本质是一个list []， 不断往里面增加</p>\n<p>{‘role’:’user’, ‘content’:’…’}</p>\n<p>{‘role’:’assistent’, ‘content’:’…’}</p>\n<p>![image.png]([Vol][6]+语言模型+f5d8e690-b777-4214-8b28-491bf3ce268c/image 2.png)</p>\n<hr>\n<p>计算token 数量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># callback ： token 计算</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.callbacks <span class=\"keyword\">import</span> get_openai_callback</span><br><span class=\"line\"><span class=\"keyword\">with</span> get_openai_callback() <span class=\"keyword\">as</span> cb:</span><br><span class=\"line\">    result = azure_chat.invoke(<span class=\"string\">&quot;Tell me a joke&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(cb)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">Tokens Used: <span class=\"number\">34</span></span><br><span class=\"line\">\tPrompt Tokens: <span class=\"number\">11</span></span><br><span class=\"line\">\tCompletion Tokens: <span class=\"number\">23</span></span><br><span class=\"line\">Successful Requests: <span class=\"number\">1</span></span><br><span class=\"line\">Total Cost (USD): $<span class=\"number\">6.25e-05</span>  ($<span class=\"number\">0.0000625</span>)</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> uuid</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.memory <span class=\"keyword\">import</span> ConversationBufferMemory</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.llms.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanLLMEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage, SystemMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser, CommaSeparatedListOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompt_values <span class=\"keyword\">import</span> ChatPromptValue</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate, PromptTemplate, MessagesPlaceholder</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough, RunnableParallel, RunnableLambda, ConfigurableField</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> operator <span class=\"keyword\">import</span> itemgetter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.pydantic_v1 <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    unique_id = uuid.uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [返回docs]轨迹 - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># chat</span></span><br><span class=\"line\">    chat_model = QianfanChatEndpoint(</span><br><span class=\"line\">        model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># llm</span></span><br><span class=\"line\">    llm = QianfanLLMEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    text = <span class=\"string\">&quot;讲一个狗熊的笑话&quot;</span></span><br><span class=\"line\">    messages = [HumanMessage(content=text)]</span><br><span class=\"line\"></span><br><span class=\"line\">    llm_res = llm.invoke(text)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># chat_res = chat_model.invoke(messages)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词  PromptTemplate</span></span><br><span class=\"line\">    prompt = PromptTemplate.from_template(<span class=\"string\">&quot;生产 &#123;product&#125; 的公司在哪里?&quot;</span>)</span><br><span class=\"line\">    prompt.<span class=\"built_in\">format</span>(product=<span class=\"string\">&quot;袜子&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#  ChatPromptTemplate</span></span><br><span class=\"line\">    template = <span class=\"string\">&quot;你是个专业的翻译，你把 &#123;input_language&#125; 翻译到 &#123;output_language&#125;.&quot;</span></span><br><span class=\"line\">    human_template = <span class=\"string\">&quot;&#123;text&#125;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    chat_prompt = ChatPromptTemplate.from_messages([</span><br><span class=\"line\">        (<span class=\"string\">&quot;system&quot;</span>, template),</span><br><span class=\"line\">        (<span class=\"string\">&quot;human&quot;</span>, human_template),</span><br><span class=\"line\">    ])</span><br><span class=\"line\"></span><br><span class=\"line\">    chat_prompt.format_messages(input_language=<span class=\"string\">&quot;English&quot;</span>, output_language=<span class=\"string\">&quot;Chinese&quot;</span>, text=<span class=\"string\">&quot;I love programming.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 消息</span></span><br><span class=\"line\">    messages = [</span><br><span class=\"line\">        SystemMessage(content=<span class=\"string\">&quot;你是一个AI助手&quot;</span>),</span><br><span class=\"line\">        HumanMessage(content=<span class=\"string\">&quot;今天有什么新闻？&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># invoke</span></span><br><span class=\"line\">    res = chat_model.invoke(messages)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># stream</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> chunk <span class=\"keyword\">in</span> chat_model.stream(messages):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(chunk.content, end=<span class=\"string\">&quot;&quot;</span>, flush=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># function call</span></span><br><span class=\"line\">    <span class=\"keyword\">class</span> <span class=\"title class_\">Multiply</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot; 将2个数相加&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">        a: <span class=\"built_in\">int</span> = Field(..., description=<span class=\"string\">&quot;第一个整数&quot;</span>)</span><br><span class=\"line\">        b: <span class=\"built_in\">int</span> = Field(..., description=<span class=\"string\">&quot;第二个整数&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># langchain的百度接口不支持</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    azure_chat = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    function = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;add_two_int&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;将输入的2个整数相加&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;int_a&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;一个整数&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"string\">&quot;int_b&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;一个整数&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;int_a&quot;</span>, <span class=\"string\">&quot;int_b&quot;</span>]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 绑定运行时参数</span></span><br><span class=\"line\">    chat_with_tools = azure_chat.bind(</span><br><span class=\"line\">      function_call=&#123;<span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;add_two_int&quot;</span>&#125;, functions=[function]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># res = chat_with_tools.invoke(&quot;3加18等于多少&quot;)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    res = azure_chat.with_config(configurable=&#123;<span class=\"string\">&quot;llm_temperature&quot;</span>: <span class=\"number\">0.9</span>&#125;).invoke(<span class=\"string\">&quot;给出一个随机数&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    llm = QianfanChatEndpoint(temperature=<span class=\"number\">0.7</span>).configurable_alternatives(</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 设置可以配置的项目</span></span><br><span class=\"line\">        ConfigurableField(<span class=\"built_in\">id</span>=<span class=\"string\">&quot;llm&quot;</span>),</span><br><span class=\"line\">        <span class=\"comment\"># 设置缺省值，默认用百度</span></span><br><span class=\"line\">        default_key=<span class=\"string\">&quot;baidu4&quot;</span>,</span><br><span class=\"line\">        <span class=\"comment\"># 可以选择 Azure OpenAI</span></span><br><span class=\"line\">        azure_openai=azure_chat,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    chain = prompt | llm</span><br><span class=\"line\">    <span class=\"comment\"># res_ = chain.with_config(configurable=&#123;&quot;llm&quot;: &quot;baidu4&quot;&#125;).invoke(&#123;&quot;product&quot;: &quot;铅笔&quot;&#125;)</span></span><br><span class=\"line\">    <span class=\"comment\"># res_ = chain.with_config(configurable=&#123;&quot;llm&quot;: &quot;azure_openai&quot;&#125;).invoke(&#123;&quot;product&quot;: &quot;铅笔&quot;&#125;)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            (<span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;你是AI助手&quot;</span>),</span><br><span class=\"line\">            MessagesPlaceholder(variable_name=<span class=\"string\">&quot;history&quot;</span>),</span><br><span class=\"line\">            (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;input&#125;&quot;</span>),</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    memory = ConversationBufferMemory(return_messages=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    res = memory.load_memory_variables(&#123;&#125;)</span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            RunnablePassthrough.assign(</span><br><span class=\"line\">                history=RunnableLambda(memory.load_memory_variables) | itemgetter(<span class=\"string\">&quot;history&quot;</span>)</span><br><span class=\"line\">            )</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | chat_model</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    inputs = &#123;<span class=\"string\">&quot;input&quot;</span>: <span class=\"string\">&quot;你好！我是茉卷&quot;</span>&#125;</span><br><span class=\"line\">    response = chain.invoke(inputs)</span><br><span class=\"line\"></span><br><span class=\"line\">    memory.save_context(inputs, &#123;<span class=\"string\">&quot;output&quot;</span>: response.content&#125;)</span><br><span class=\"line\">    res = memory.load_memory_variables(&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试记忆</span></span><br><span class=\"line\">    inputs = &#123;<span class=\"string\">&quot;input&quot;</span>: <span class=\"string\">&quot;我叫什么名字&quot;</span>&#125;</span><br><span class=\"line\">    response = chain.invoke(inputs)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\">    memory.save_context(inputs, &#123;<span class=\"string\">&quot;output&quot;</span>: response.content&#125;)</span><br><span class=\"line\">    res = memory.load_memory_variables(&#123;&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># callback ： token 计算</span></span><br><span class=\"line\">    <span class=\"keyword\">from</span> langchain.callbacks <span class=\"keyword\">import</span> get_openai_callback</span><br><span class=\"line\">    <span class=\"keyword\">with</span> get_openai_callback() <span class=\"keyword\">as</span> cb:</span><br><span class=\"line\">        result = azure_chat.invoke(<span class=\"string\">&quot;Tell me a joke&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(cb)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[07] 函数 VS 工具 VS Agent","url":"/forward/14a9d288.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p><strong>了解 function 调用、工具调用 和 Agent</strong></p>\n<hr>\n<p><strong>function</strong>：别用了（OpenAI API has deprecated <code>functions</code> in favor of <code>tools</code>）</p>\n<p><strong>Tool</strong> ：能用，但是需要我们自己调用函数，并实现后续逻辑</p>\n<p><strong>Agent</strong>: 推荐，自动调用我们本地定义的函数</p>\n<p><strong>核心思想：通过llms 来识别用户意图并调用本地函数（Agent）</strong></p>\n<p><a href=\"https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent\">https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent</a></p>\n<h3 id=\"1-function-call-tools\"><a href=\"#1-function-call-tools\" class=\"headerlink\" title=\"1. function call + tools\"></a><strong>1. function call + tools</strong></h3><p><strong>大模型的函数调用功能，最早来自OpenAI.</strong></p>\n<p><strong>OpenAI 函数</strong>是 OpenAI API 中的一个功能，允许用户通过 API 调用自定义函数。这些函数可以是在 Python 中定义的任何函数，可以接受任何类型的输入，并返回任何类型的输出。这使得用户可以扩展 OpenAI 模型的功能，使其能够执行特定的任务或操作。</p>\n<p><strong>OpenAI 函数的接收方式如下</strong>：</p>\n<ul>\n<li>首先，用户需要定义一个函数，并将其作为参数传递给 OpenAI API。这个函数可以接受任何类型的输入，并返回任何类型的输出。</li>\n<li>然后，用户需要将这个函数传递给 OpenAI API 的 functions 参数。这个参数是一个字典，其中键是函数的名称，值是函数本身。</li>\n<li>当用户调用 OpenAI API 时，他们可以在请求中指定要调用的函数的名称和参数。OpenAI API 会将这个请求转发给相应的函数，并返回函数的输出。</li>\n</ul>\n<p><strong>核心思路</strong> 我们借用阿里云上一张图来说明一下~ </p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-07-%E5%87%BD%E6%95%B0-VS-%E5%B7%A5%E5%85%B7-VS-Agent.assets/image-20240627100414764.png\" alt=\"image-20240627100414764\"></p>\n<p>【1】用户描述一个函数调用（通常通过Json Schema 格式的数据构造）</p>\n<ul>\n<li>函数名称：传给大模型，告诉模型这个函数的名字</li>\n<li>函数参数：函数有哪些参数，分别是什么意思</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">function = &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                        <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                        <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                        <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p>【2】问题 + 函数描述  传递给模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义模型，通过bind 方法传递给模型</span></span><br><span class=\"line\">model = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">    azure_deployment=os.getenv(<span class=\"string\">&#x27;DEPLOYMENT_NAME_GPT3p5&#x27;</span>),</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">).bind(</span><br><span class=\"line\">    function_call=&#123;<span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>&#125;, functions=[function]</span><br><span class=\"line\">)</span><br><span class=\"line\">runnable = &#123;<span class=\"string\">&quot;equation_statement&quot;</span>: RunnablePassthrough()&#125; | prompt | model</span><br><span class=\"line\">res = runnable.invoke(<span class=\"string\">&quot;后天从北京到南极的飞机票&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>【3】大模型进行识别，告诉用户需要执行函数，并返回输入参数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">content=<span class=\"string\">&#x27;&#x27;</span> additional_kwargs=&#123;<span class=\"string\">&#x27;function_call&#x27;</span>: </span><br><span class=\"line\">  &#123;<span class=\"string\">&#x27;arguments&#x27;</span>: <span class=\"string\">&#x27;&#123;\\n  &quot;departure&quot;: &quot;北京&quot;,\\n  &quot;destination&quot;: &quot;南极&quot;,\\n  &quot;date&quot;: &quot;2022-12-10&quot;\\n&#125;&#x27;</span>, <span class=\"string\">&#x27;name&#x27;</span>: <span class=\"string\">&#x27;get_flight_number&#x27;</span>&#125;&#125; </span><br><span class=\"line\">response_metadata=&#123;<span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;stop&#x27;</span>, <span class=\"string\">&#x27;logprobs&#x27;</span>: <span class=\"literal\">None</span>, <span class=\"string\">&#x27;content_filter_results&#x27;</span>: &#123;&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>【4】用户执行函数，并将结果返回给大模型</p>\n<p><strong>需要我们自己在代码里处理 如何调用 get_flight_number， 并继续</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 函数名</span></span><br><span class=\"line\">res.additional_kwargs[<span class=\"string\">&#x27;function_call&#x27;</span>][<span class=\"string\">&#x27;name&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#函数参数</span></span><br><span class=\"line\">res.additional_kwargs[<span class=\"string\">&#x27;function_call&#x27;</span>][<span class=\"string\">&#x27;arguments&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">get_flight_number(xxx,xxx,xxx)</span><br></pre></td></tr></table></figure>\n\n<p>【5】大模型给出最后回答</p>\n<p><strong>需要我们自己在代码里处理 ，如何继续处理get_flight_number 结果</strong></p>\n<hr>\n<p><strong>问题来了</strong></p>\n<p><strong>无论是 Function call 还是 Tool， 用户都要自己调用本地函数处理（硬编码在代码里）。</strong></p>\n<p>智谱AI举例 function call 举例</p>\n<p>定义一个函数：<strong>获得航班号</strong>，参数：<strong>出发地</strong>，<strong>目的地</strong>，<strong>日期</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;,</span><br></pre></td></tr></table></figure>\n\n<p>实现这个函数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_flight_number</span>(<span class=\"params\">date:<span class=\"built_in\">str</span> , departure:<span class=\"built_in\">str</span> , destination:<span class=\"built_in\">str</span></span>):</span><br><span class=\"line\">    flight_number = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;北京&quot;</span>:&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;上海&quot;</span> : <span class=\"string\">&quot;1234&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;广州&quot;</span> : <span class=\"string\">&quot;8321&quot;</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">&quot;上海&quot;</span>:&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;北京&quot;</span> : <span class=\"string\">&quot;1233&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;广州&quot;</span> : <span class=\"string\">&quot;8123&quot;</span>,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123; <span class=\"string\">&quot;flight_number&quot;</span>:flight_number[departure][destination] &#125;</span><br></pre></td></tr></table></figure>\n\n<p>将 <strong>函数</strong> + <strong>用户输入</strong> 传给模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">messages = []</span><br><span class=\"line\">messages.append(&#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;帮我查询从2024年1月20日，从北京出发前往上海的航班&quot;</span>&#125;)</span><br><span class=\"line\">response = client.chat.completions.create(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">    messages=messages,</span><br><span class=\"line\">    tools=tools,</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message)</span><br><span class=\"line\">messages.append(response.choices[<span class=\"number\">0</span>].message.model_dump())</span><br></pre></td></tr></table></figure>\n\n<p>模型返回</p>\n<p>Function(arguments=’{“date”:”2024-01-20”,”departure”:”北京”,”destination”:”上海”}’, name=’get_flight_number’)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">content=<span class=\"literal\">None</span> role=<span class=\"string\">&#x27;assistant&#x27;</span> tool_calls=[CompletionMessageToolCall(<span class=\"built_in\">id</span>=<span class=\"string\">&#x27;call_8513536572832694738&#x27;</span>, function=Function(arguments=<span class=\"string\">&#x27;&#123;&quot;date&quot;:&quot;2024-01-20&quot;,&quot;departure&quot;:&quot;北京&quot;,&quot;destination&quot;:&quot;上海&quot;&#125;&#x27;</span>, name=<span class=\"string\">&#x27;get_flight_number&#x27;</span>), <span class=\"built_in\">type</span>=<span class=\"string\">&#x27;function&#x27;</span>)]</span><br></pre></td></tr></table></figure>\n\n<p>写一个函数，分析这个返回，如果需要执行函数，就执行</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_function_call</span>(<span class=\"params\">model_response,messages</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 处理函数调用结果，根据模型返回参数，调用对应的函数。</span></span><br><span class=\"line\">    <span class=\"comment\"># 调用函数返回结果后构造tool message，再次调用模型，将函数结果输入模型</span></span><br><span class=\"line\">    <span class=\"comment\"># 模型会将函数调用结果以自然语言格式返回给用户。</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> model_response.choices[<span class=\"number\">0</span>].message.tool_calls:</span><br><span class=\"line\">        tool_call = model_response.choices[<span class=\"number\">0</span>].message.tool_calls[<span class=\"number\">0</span>]</span><br><span class=\"line\">        args = tool_call.function.arguments</span><br><span class=\"line\">        function_result = &#123;&#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> tool_call.function.name == <span class=\"string\">&quot;get_flight_number&quot;</span>:</span><br><span class=\"line\">            function_result = get_flight_number(**json.loads(args))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> tool_call.function.name == <span class=\"string\">&quot;get_ticket_price&quot;</span>:</span><br><span class=\"line\">            function_result = get_ticket_price(**json.loads(args))</span><br><span class=\"line\">        messages.append(&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;tool&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">f&quot;<span class=\"subst\">&#123;json.dumps(function_result)&#125;</span>&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;tool_call_id&quot;</span>:tool_call.<span class=\"built_in\">id</span></span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        response = client.chat.completions.create(</span><br><span class=\"line\">            model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">            messages=messages,</span><br><span class=\"line\">            tools=tools,</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message)</span><br><span class=\"line\">        messages.append(response.choices[<span class=\"number\">0</span>].message.model_dump())</span><br></pre></td></tr></table></figure>\n\n<p>执行完函数之后，需要把结果反馈给模型。最后，模型给出结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">content=<span class=\"string\">&#x27;根据您的查询，我已经帮您找到了2024年1月20日从北京出发前往上海的航班，航班号为1234。&#x27;</span> role=<span class=\"string\">&#x27;assistant&#x27;</span> tool_calls=<span class=\"literal\">None</span></span><br></pre></td></tr></table></figure>\n\n<p>然后我们再把结构，保存在对话列表</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">messages.append(response.choices[<span class=\"number\">0</span>].message.model_dump())</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"在Langchian中调用-function\"><a href=\"#在Langchian中调用-function\" class=\"headerlink\" title=\"在Langchian中调用 function\"></a><strong>在Langchian中调用 function</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">function = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">    [</span><br><span class=\"line\">        (</span><br><span class=\"line\">            <span class=\"string\">&quot;system&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;你是飞机票务信息提供商&quot;</span>,</span><br><span class=\"line\">        ),</span><br><span class=\"line\">        (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;equation_statement&#125;&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 函数调用</span></span><br><span class=\"line\">model = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">    azure_deployment=os.getenv(<span class=\"string\">&#x27;DEPLOYMENT_NAME_GPT3_4K_JP&#x27;</span>),</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">).bind(</span><br><span class=\"line\">    function_call=&#123;<span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>&#125;, functions=[function]</span><br><span class=\"line\">)</span><br><span class=\"line\">runnable = &#123;<span class=\"string\">&quot;equation_statement&quot;</span>: RunnablePassthrough()&#125; | prompt | model</span><br><span class=\"line\">res = runnable.invoke(<span class=\"string\">&quot;后天从北京到南极的飞机票&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>输出</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">content=<span class=\"string\">&#x27;&#x27;</span> additional_kwargs=&#123;<span class=\"string\">&#x27;function_call&#x27;</span>: &#123;<span class=\"string\">&#x27;arguments&#x27;</span>: <span class=\"string\">&#x27;&#123;\\n  &quot;departure&quot;: &quot;北京&quot;,\\n  &quot;destination&quot;: &quot;南极&quot;,\\n  &quot;date&quot;: &quot;2022-03-06&quot;\\n&#125;&#x27;</span>, <span class=\"string\">&#x27;name&#x27;</span>: <span class=\"string\">&#x27;get_flight_number&#x27;</span>&#125;&#125; response_metadata=&#123;<span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;stop&#x27;</span>, <span class=\"string\">&#x27;logprobs&#x27;</span>: <span class=\"literal\">None</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"在Langchian中调用-Tool\"><a href=\"#在Langchian中调用-Tool\" class=\"headerlink\" title=\"在Langchian中调用 Tool\"></a><strong>在Langchian中调用 Tool</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 工具调用</span></span><br><span class=\"line\">  tools = [</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">          <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">          <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">              <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">              <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">              <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">                  <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">                  <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                      <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                          <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                          <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                      &#125;,</span><br><span class=\"line\">                      <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                          <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                          <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                      &#125;,</span><br><span class=\"line\">                      <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                          <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                          <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                      &#125;</span><br><span class=\"line\">                  &#125;,</span><br><span class=\"line\">                  <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">  ]</span><br><span class=\"line\">  <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">  os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">  os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">  DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">  model = AzureChatOpenAI(</span><br><span class=\"line\">      openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">      azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">  ).bind(</span><br><span class=\"line\">      tools=tools</span><br><span class=\"line\">  )</span><br><span class=\"line\">  runnable = &#123;<span class=\"string\">&quot;equation_statement&quot;</span>: RunnablePassthrough()&#125; | prompt | model</span><br><span class=\"line\"></span><br><span class=\"line\">  res = runnable.invoke(<span class=\"string\">&quot;后天从北京到南极的飞机票&quot;</span>)</span><br><span class=\"line\">  <span class=\"comment\"># res = runnable.invoke(&quot;后天从北京到上海的火车票&quot;)</span></span><br><span class=\"line\">  <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>输出</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">content=<span class=\"string\">&#x27;&#x27;</span> additional_kwargs=&#123;<span class=\"string\">&#x27;tool_calls&#x27;</span>: [&#123;<span class=\"string\">&#x27;id&#x27;</span>: <span class=\"string\">&#x27;call_1lP2S9SFi9FDdhYZNkXVxpqt&#x27;</span>, <span class=\"string\">&#x27;function&#x27;</span>: &#123;<span class=\"string\">&#x27;arguments&#x27;</span>: <span class=\"string\">&#x27;&#123;\\n&quot;departure&quot;: &quot;北京&quot;,\\n&quot;destination&quot;: &quot;南极&quot;,\\n&quot;date&quot;: &quot;2022-11-18&quot;\\n&#125;&#x27;</span>, <span class=\"string\">&#x27;name&#x27;</span>: <span class=\"string\">&#x27;get_flight_number&#x27;</span>&#125;, <span class=\"string\">&#x27;type&#x27;</span>: <span class=\"string\">&#x27;function&#x27;</span>&#125;]&#125; response_metadata=&#123;<span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;tool_calls&#x27;</span>, <span class=\"string\">&#x27;logprobs&#x27;</span>: <span class=\"literal\">None</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>Agent （全自动）</strong></p>\n<p><strong>代理的核心思想是使用语言模型来选择要采取的一系列行动。在链式中，一系列行动是硬编码在代码中的。而在代理中，语言模型被用作推理引擎，以确定要采取哪些行动以及它们的顺序。</strong></p>\n<p><strong>函数声明：</strong> @tool</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents <span class=\"keyword\">import</span> tool, </span><br><span class=\"line\"><span class=\"meta\">  @tool</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_flight_number</span>(<span class=\"params\">departure, destination, date</span>) -&gt; <span class=\"built_in\">str</span>:</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;根据输入的出发地（departure），目的地（destination），时间（date），给出航班号&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">&quot;[茉卷航空666]&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>构建chain</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">user_template = <span class=\"string\">&#x27;&#123;input&#125;&#x27;</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">    [</span><br><span class=\"line\">        (<span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;You are a helpful assistant&quot;</span>),</span><br><span class=\"line\">        MessagesPlaceholder(<span class=\"string\">&quot;chat_history&quot;</span>, optional=<span class=\"literal\">True</span>),</span><br><span class=\"line\">        (<span class=\"string\">&quot;human&quot;</span>, user_template),</span><br><span class=\"line\">        MessagesPlaceholder(<span class=\"string\">&quot;agent_scratchpad&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\">)</span><br><span class=\"line\">model = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">    azure_deployment=os.getenv(<span class=\"string\">&#x27;DEPLOYMENT_NAME_GPT3P5&#x27;</span>),</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p><strong>调用 Agent</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">tool_list = [get_flight_number]</span><br><span class=\"line\">agent = create_openai_functions_agent(model, tool_list, prompt)</span><br><span class=\"line\">agent_executor = AgentExecutor(agent=agent, tools=tool_list, verbose=<span class=\"literal\">True</span>)</span><br><span class=\"line\">res = agent_executor.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: <span class=\"string\">&quot;后天从北京到南极的飞机票&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>\n\n<p><strong>结果</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt; Entering new AgentExecutor chain...</span><br><span class=\"line\">Invoking: `get_flight_number` <span class=\"keyword\">with</span> `&#123;<span class=\"string\">&#x27;departure&#x27;</span>: <span class=\"string\">&#x27;北京&#x27;</span>, <span class=\"string\">&#x27;destination&#x27;</span>: <span class=\"string\">&#x27;南极&#x27;</span>, <span class=\"string\">&#x27;date&#x27;</span>: <span class=\"string\">&#x27;后天&#x27;</span>&#125;`</span><br><span class=\"line\">[茉卷航空<span class=\"number\">666</span>]根据查询，后天从北京到南极的飞机票的航班号是[茉卷航空<span class=\"number\">666</span>]。</span><br><span class=\"line\">&gt; Finished chain.</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<p>zhipuai function call</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> zhipuai <span class=\"keyword\">import</span> ZhipuAI</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_flight_number</span>(<span class=\"params\">date:<span class=\"built_in\">str</span> , departure:<span class=\"built_in\">str</span> , destination:<span class=\"built_in\">str</span></span>):</span><br><span class=\"line\">    flight_number = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;北京&quot;</span>:&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;上海&quot;</span> : <span class=\"string\">&quot;1234&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;广州&quot;</span> : <span class=\"string\">&quot;8321&quot;</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">&quot;上海&quot;</span>:&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;北京&quot;</span> : <span class=\"string\">&quot;1233&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;广州&quot;</span> : <span class=\"string\">&quot;8123&quot;</span>,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123; <span class=\"string\">&quot;flight_number&quot;</span>:flight_number[departure][destination] &#125;</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_ticket_price</span>(<span class=\"params\">date:<span class=\"built_in\">str</span> , flight_number:<span class=\"built_in\">str</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;<span class=\"string\">&quot;ticket_price&quot;</span>: <span class=\"string\">&quot;1000&quot;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_function_call</span>(<span class=\"params\">model_response,messages</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 处理函数调用结果，根据模型返回参数，调用对应的函数。</span></span><br><span class=\"line\">    <span class=\"comment\"># 调用函数返回结果后构造tool message，再次调用模型，将函数结果输入模型</span></span><br><span class=\"line\">    <span class=\"comment\"># 模型会将函数调用结果以自然语言格式返回给用户。</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> model_response.choices[<span class=\"number\">0</span>].message.tool_calls:</span><br><span class=\"line\">        tool_call = model_response.choices[<span class=\"number\">0</span>].message.tool_calls[<span class=\"number\">0</span>]</span><br><span class=\"line\">        args = tool_call.function.arguments</span><br><span class=\"line\">        function_result = &#123;&#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> tool_call.function.name == <span class=\"string\">&quot;get_flight_number&quot;</span>:</span><br><span class=\"line\">            function_result = get_flight_number(**json.loads(args))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> tool_call.function.name == <span class=\"string\">&quot;get_ticket_price&quot;</span>:</span><br><span class=\"line\">            function_result = get_ticket_price(**json.loads(args))</span><br><span class=\"line\">        messages.append(&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;tool&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">f&quot;<span class=\"subst\">&#123;json.dumps(function_result)&#125;</span>&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;tool_call_id&quot;</span>:tool_call.<span class=\"built_in\">id</span></span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">        response = client.chat.completions.create(</span><br><span class=\"line\">            model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">            messages=messages,</span><br><span class=\"line\">            tools=tools,</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message)</span><br><span class=\"line\">        messages.append(response.choices[<span class=\"number\">0</span>].message.model_dump())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    client = ZhipuAI(api_key=os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>))</span><br><span class=\"line\">    messages = []</span><br><span class=\"line\">    tools = [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_ticket_price&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;查询某航班在某日的票价&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;flight_number&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;航班号&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;flight_number&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\">    messages = []</span><br><span class=\"line\">    messages.append(&#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;帮我查询从2024年1月20日，从北京出发前往上海的航班&quot;</span>&#125;)</span><br><span class=\"line\">    response = client.chat.completions.create(</span><br><span class=\"line\">        model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">        messages=messages,</span><br><span class=\"line\">        tools=tools,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message)</span><br><span class=\"line\">    messages.append(response.choices[<span class=\"number\">0</span>].message.model_dump())</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    parse_function_call(response, messages)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>langchain: function call, tool, agent</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> uuid</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents.output_parsers <span class=\"keyword\">import</span> XMLAgentOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.chains.llm <span class=\"keyword\">import</span> LLMChain</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate, ChatPromptTemplate, MessagesPlaceholder</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents <span class=\"keyword\">import</span> AgentExecutor, tool, create_openai_functions_agent</span><br><span class=\"line\"></span><br><span class=\"line\">run_uid = uuid.uuid4().<span class=\"built_in\">hex</span>[:<span class=\"number\">6</span>]</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [Agent call locat func] Tracing Walkthrough - <span class=\"subst\">&#123;run_uid&#125;</span>&quot;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    function = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            (</span><br><span class=\"line\">                <span class=\"string\">&quot;system&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;你是飞机票务信息提供商&quot;</span>,</span><br><span class=\"line\">            ),</span><br><span class=\"line\">            (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;equation_statement&#125;&quot;</span>),</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 函数调用</span></span><br><span class=\"line\">    <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    model = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    ).bind(</span><br><span class=\"line\">        function_call=&#123;<span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>&#125;, functions=[function]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    runnable = &#123;<span class=\"string\">&quot;equation_statement&quot;</span>: RunnablePassthrough()&#125; | prompt | model</span><br><span class=\"line\">    <span class=\"comment\"># res = runnable.invoke(&quot;后天从北京到南极的飞机票&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># print(res)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 工具调用</span></span><br><span class=\"line\">    tools = [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_flight_number&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的航班号&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;name&quot;</span>: <span class=\"string\">&quot;get_train_number&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;根据始发地、目的地和日期，查询对应日期的火车票&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;parameters&quot;</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;object&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;properties&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;departure&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;出发地&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;destination&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;目的地&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span></span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        <span class=\"string\">&quot;date&quot;</span>: &#123;</span><br><span class=\"line\">                            <span class=\"string\">&quot;description&quot;</span>: <span class=\"string\">&quot;日期&quot;</span>,</span><br><span class=\"line\">                            <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;string&quot;</span>,</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                    <span class=\"string\">&quot;required&quot;</span>: [<span class=\"string\">&quot;departure&quot;</span>, <span class=\"string\">&quot;destination&quot;</span>, <span class=\"string\">&quot;date&quot;</span>]</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">    <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    model = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    ).bind(</span><br><span class=\"line\">        tools=tools</span><br><span class=\"line\">    )</span><br><span class=\"line\">    runnable = &#123;<span class=\"string\">&quot;equation_statement&quot;</span>: RunnablePassthrough()&#125; | prompt | model</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># res = runnable.invoke(&quot;后天从北京到南极的飞机票&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># res = runnable.invoke(&quot;后天从北京到上海的火车票&quot;)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\">    <span class=\"comment\"># 如果需要执行函数</span></span><br><span class=\"line\">    <span class=\"comment\"># if len(res.additional_kwargs) &gt; 0:</span></span><br><span class=\"line\">    <span class=\"comment\">#</span></span><br><span class=\"line\">    <span class=\"comment\">#     func_name = res.additional_kwargs[&#x27;tool_calls&#x27;][0][&#x27;function&#x27;][&#x27;name&#x27;]</span></span><br><span class=\"line\">    <span class=\"comment\">#     if func_name == &#x27;get_flight_number&#x27;:</span></span><br><span class=\"line\">    <span class=\"comment\">#         data_str = res.additional_kwargs[&#x27;tool_calls&#x27;][0][&#x27;function&#x27;][&#x27;arguments&#x27;]</span></span><br><span class=\"line\">    <span class=\"comment\">#         # 自己加</span></span><br><span class=\"line\">    <span class=\"comment\">#         pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Agent</span></span><br><span class=\"line\"></span><br><span class=\"line\">    user_template = <span class=\"string\">&#x27;&#123;input&#125;&#x27;</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            (<span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;You are a helpful assistant&quot;</span>),</span><br><span class=\"line\">            MessagesPlaceholder(<span class=\"string\">&quot;chat_history&quot;</span>, optional=<span class=\"literal\">True</span>),</span><br><span class=\"line\">            (<span class=\"string\">&quot;human&quot;</span>, user_template),</span><br><span class=\"line\">            MessagesPlaceholder(<span class=\"string\">&quot;agent_scratchpad&quot;</span>),</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    model = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    )</span><br><span class=\"line\"><span class=\"meta\">    @tool</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_flight_number</span>(<span class=\"params\">departure, destination, date</span>) -&gt; <span class=\"built_in\">str</span>:</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;根据输入的出发地（departure），目的地（destination），时间（date），给出航班号&quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">&quot;[茉卷航空666]&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    tool_list = [get_flight_number]</span><br><span class=\"line\">    agent = create_openai_functions_agent(model, tool_list, prompt)</span><br><span class=\"line\">    agent_executor = AgentExecutor(agent=agent, tools=tool_list, verbose=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    res = agent_executor.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: <span class=\"string\">&quot;后天从北京到南极的飞机票&quot;</span>&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[08]嵌入模型 Embeddings","url":"/forward/1fbe595c.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>了解嵌入模型的概念及使用</p>\n<hr>\n<p><strong>嵌入模型为一段文本创建了一个向量表示</strong>。</p>\n<p>这很有用，因为这意味着<strong>我们可以将文本视为向量空间中的内容</strong>，并进行诸如语义搜索之类的操作，在向量空间中寻找最相似的文本片段。</p>\n<p>Embeddings类是一个设计用来与文本嵌入模型交互的类。</p>\n<p>有许多嵌入模型提供商（如OpenAI、百度、智谱等）——这个类旨在为所有这些提供商提供一个标准的接口。</p>\n<p>LangChain中的基础Embeddings类提供了两种方法：</p>\n<p>一种用于嵌入文档，另一种用于嵌入查询。</p>\n<p>前者接受多个文本作为输入，而后者接受单个文本。</p>\n<p>之所以将这两个方法分开，是因为一些嵌入提供商对于文档（搜索对象）和查询（搜索查询本身）有不同的嵌入方法。</p>\n<hr>\n<h3 id=\"bge-base-en-v1-5\"><a href=\"#bge-base-en-v1-5\" class=\"headerlink\" title=\"bge-base-en-v1.5\"></a>bge-base-en-v1.5</h3><p><a href=\"https://modelscope.cn/models/AI-ModelScope/bge-base-en-v1.5/summary\">https://modelscope.cn/models/AI-ModelScope/bge-base-en-v1.5/summary</a></p>\n<p>Rerank模型</p>\n<h3 id=\"bge-large-zh-v1-5\"><a href=\"#bge-large-zh-v1-5\" class=\"headerlink\" title=\"bge-large-zh-v1.5\"></a>bge-large-zh-v1.5</h3><p><a href=\"https://modelscope.cn/models/AI-ModelScope/bge-large-zh-v1.5/summary\">https://modelscope.cn/models/AI-ModelScope/bge-large-zh-v1.5/summary</a></p>\n<h3 id=\"嵌入模型的使用\"><a href=\"#嵌入模型的使用\" class=\"headerlink\" title=\"嵌入模型的使用\"></a>嵌入模型的使用</h3><p>本地</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">    bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\">    bge_zh_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\Bge_models\\\\bge-large-zh-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">    bge_en_emb_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">        model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">        encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用CPU</span></span><br><span class=\"line\">    bge_zh_emb_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=bge_zh_v1p5_model_path,</span><br><span class=\"line\">        model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cpu&#x27;</span>&#125;,</span><br><span class=\"line\">        encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    en_embeddings = bge_en_emb_model.embed_documents(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            <span class=\"string\">&quot;Hi there!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;Oh, hello!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;What&#x27;s your name?&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;My friends call me World&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;Hello World!&quot;</span></span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(en_embeddings), <span class=\"built_in\">len</span>(en_embeddings[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    en_embedded_query = bge_en_emb_model.embed_query(<span class=\"string\">&quot;What was the name mentioned in the conversation?&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    zh_embeddings = bge_zh_emb_model.embed_documents(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            <span class=\"string\">&quot;哈喽啊&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;干啥呢!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;你看啥&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;快去上学！&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;嗯嗯，我知道了&quot;</span></span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(en_embeddings), <span class=\"built_in\">len</span>(en_embeddings[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    zh_embedded_query = bge_zh_emb_model.embed_query(<span class=\"string\">&quot;明天怎么去上班？&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>远程模型使用</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 远程百度调用</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆 bge_large_en or bge_large_zh</span></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_zh&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_zh&quot;</span>)</span><br><span class=\"line\">    baidu_en_embeddings = embeddings_model.embed_documents(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            <span class=\"string\">&quot;哈喽啊&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;干啥呢!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;你看啥&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;快去上学！&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;嗯嗯，我知道了&quot;</span></span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(baidu_en_embeddings), <span class=\"built_in\">len</span>(baidu_en_embeddings[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>嵌入模型通过将文本转换为高维空间中的向量来表示文本的语义内容。</p>\n<p>这些向量捕获了文本的语义和上下文信息，使得语义上相似的文本在向量空间中彼此接近。</p>\n<p><strong>度量这些向量之间相似度</strong>的常见方法有以下几种：</p>\n<ol>\n<li><strong>余弦相似度（Cosine Similarity）</strong>：<ul>\n<li>余弦相似度是度量两个向量之间角度的最常用方法，它返回值介于-1（完全不同）和1（完全相同）之间。</li>\n<li>公式为：cos(θ) = (A·B) / (||A|| ||B||)，其中A和B是两个向量，·表示点积，||A||和||B||分别是向量A和B的欧几里得范数（即长度）。</li>\n<li>余弦相似度不考虑向量的长度，只考虑它们之间的角度，因此它对于度量文本的语义相似度非常有效。</li>\n</ul>\n</li>\n<li><strong>欧几里得距离（Euclidean Distance）</strong>：<ul>\n<li>欧几里得距离是向量空间中两点之间的直线距离，也称为L2范数。</li>\n<li>公式为：d(A, B) = √(∑(Ai - Bi)²)，其中Ai和B_i是两个向量中的对应元素。</li>\n<li>欧几里得距离越小，表示两个向量越相似。但是，由于它考虑了向量的长度，它可能不如余弦相似度适合度量文本的语义相似度。</li>\n</ul>\n</li>\n<li><strong>曼哈顿距离（Manhattan Distance）</strong>：<ul>\n<li>曼哈顿距离是向量空间中两点之间的城市街区距离，也称为L1范数。</li>\n<li>公式为：d(A, B) = ∑|Ai - Bi|，其中Ai和B_i是两个向量中的对应元素。</li>\n<li>曼哈顿距离在特定情况下也可能用于度量相似度，但它不像余弦相似度那样直接反映向量的方向关系。</li>\n</ul>\n</li>\n<li><strong>皮尔逊相关系数（Pearson Correlation Coefficient）</strong>：<ul>\n<li>皮尔逊相关系数用于度量两个变量之间的线性相关性。</li>\n<li>公式为：ρX,Y = cov(X, Y) / (σX σY)，其中cov(X, Y)是X和Y的协方差，σX和σY分别是X和Y的标准差。</li>\n<li>皮尔逊相关系数的值介于-1和1之间，值越接近1表示正相关性越强，值越接近-1表示负相关性越强，值为0表示没有线性相关性。 在实际应用中，选择哪种相似度度量方法取决于具体的应用场景和需求。例如，<strong>在文本检索和推荐系统中，余弦相似度是一种非常流行的选择</strong>，因为它能够有效地捕捉文本的语义相似性。而在某些需要考虑向量长度和方向的综合影响的场景中，可能会选择欧几里得距离或曼哈顿距离。皮尔逊相关系数则更多用于分析两个变量之间的关系。</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">en_question = <span class=\"string\">&quot;What kinds of pets do I like?&quot;</span></span><br><span class=\"line\">document = <span class=\"string\">&quot;My favorite pet is a cat.&quot;</span></span><br><span class=\"line\">chn_question = <span class=\"string\">&quot;我喜欢什么宠物？&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">en_query_result = embeddings_model.embed_query(en_question)</span><br><span class=\"line\">document_result = embeddings_model.embed_query(document)</span><br><span class=\"line\">chn_question_result = embeddings_model.embed_query(chn_question)</span><br><span class=\"line\"></span><br><span class=\"line\">en_similarity = cosine_similarity(en_query_result, document_result)</span><br><span class=\"line\">chn_similarity = cosine_similarity(chn_question_result, document_result)</span><br><span class=\"line\">qvq_similarity = cosine_similarity(chn_question_result, en_query_result)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;EN Cosine Similarity:&quot;</span>, en_similarity)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;CHN Cosine Similarity:&quot;</span>, chn_similarity)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;qvq Cosine Similarity:&quot;</span>, qvq_similarity)</span><br><span class=\"line\">------</span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">EN Cosine Similarity: <span class=\"number\">0.8519668706051049</span></span><br><span class=\"line\">CHN Cosine Similarity: <span class=\"number\">0.784625358639582</span></span><br><span class=\"line\">qvq Cosine Similarity: <span class=\"number\">0.8550725627294596</span></span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> HuggingFaceEmbeddings, QianfanEmbeddingsEndpoint</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cosine_similarity</span>(<span class=\"params\">vec1, vec2</span>):</span><br><span class=\"line\">    dot_product = np.dot(vec1, vec2)</span><br><span class=\"line\">    norm_vec1 = np.linalg.norm(vec1)</span><br><span class=\"line\">    norm_vec2 = np.linalg.norm(vec2)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dot_product / (norm_vec1 * norm_vec2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">    bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\">    bge_zh_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\Bge_models\\\\bge-large-zh-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">    bge_en_emb_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">        model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">        encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用CPU</span></span><br><span class=\"line\">    bge_zh_emb_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=bge_zh_v1p5_model_path,</span><br><span class=\"line\">        model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cpu&#x27;</span>&#125;,</span><br><span class=\"line\">        encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    en_embeddings = bge_en_emb_model.embed_documents(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            <span class=\"string\">&quot;Hi there!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;Oh, hello!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;What&#x27;s your name?&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;My friends call me World&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;Hello World!&quot;</span></span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(en_embeddings), <span class=\"built_in\">len</span>(en_embeddings[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    en_embedded_query = bge_en_emb_model.embed_query(<span class=\"string\">&quot;What was the name mentioned in the conversation?&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    zh_embeddings = bge_zh_emb_model.embed_documents(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            <span class=\"string\">&quot;哈喽啊&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;干啥呢!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;你看啥&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;快去上学！&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;嗯嗯，我知道了&quot;</span></span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(en_embeddings), <span class=\"built_in\">len</span>(en_embeddings[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    zh_embedded_query = bge_zh_emb_model.embed_query(<span class=\"string\">&quot;明天怎么去上班？&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 远程百度调用</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆 bge_large_en or bge_large_zh</span></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_zh&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_zh&quot;</span>)</span><br><span class=\"line\">    baidu_zh_embeddings = embeddings_model.embed_documents(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            <span class=\"string\">&quot;哈喽啊&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;干啥呢!&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;你看啥&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;快去上学！&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;嗯嗯，我知道了&quot;</span></span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(baidu_zh_embeddings), <span class=\"built_in\">len</span>(baidu_zh_embeddings[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    en_question = <span class=\"string\">&quot;What kinds of pets do I like?&quot;</span></span><br><span class=\"line\">    document = <span class=\"string\">&quot;My favorite pet is a cat.&quot;</span></span><br><span class=\"line\">    chn_question = <span class=\"string\">&quot;我喜欢什么宠物？&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    en_query_result = embeddings_model.embed_query(en_question)</span><br><span class=\"line\">    document_result = embeddings_model.embed_query(document)</span><br><span class=\"line\">    chn_question_result = embeddings_model.embed_query(chn_question)</span><br><span class=\"line\"></span><br><span class=\"line\">    en_similarity = cosine_similarity(en_query_result, document_result)</span><br><span class=\"line\">    chn_similarity = cosine_similarity(chn_question_result, document_result)</span><br><span class=\"line\">    qvq_similarity = cosine_similarity(chn_question_result, en_query_result)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;EN Cosine Similarity:&quot;</span>, en_similarity)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;CHN Cosine Similarity:&quot;</span>, chn_similarity)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;qvq Cosine Similarity:&quot;</span>, qvq_similarity)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[09]向量数据库 Chroma+Elastic Search","url":"/forward/28a937fe.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>了解向量数据库的作用，能够使用本地向量数据库Chroma 和 云端的 Elastic Search</p>\n<hr>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-09-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93-Chroma-Elastic-Search.assets/image-20240627100301866.png\" alt=\"image-20240627100301866\"></p>\n<p><strong>向量搜索</strong>是一种常见的存储和搜索非结构化数据（如非结构化文本）的方法。其思想是存储与文本相关的数值向量。给定一个查询，我们可以将其嵌入为相同维度的向量，并使用向量相似性度量来识别存储中的相关数据。</p>\n<p>LangChain VectorStore 对象包含用于将 <code>文本</code>和 <strong><code>Document</code></strong> 对象添加到存储中的方法，并使用各种相似性度量来查询它们。它们通常使用嵌入模型进行初始化，这些模型决定了文本数据如何转换为数值向量。</p>\n<p>LangChain 包含了一套与不同向量存储技术集成的工具。一些向量存储由提供商托管（例如，各种云服务提供商），使用时需要特定的凭据；</p>\n<p>另一些（如 Postgres）在独立的基础设施中运行，可以本地运行或通过第三方运行；还有一些可以内存运行，用于轻量级工作负载。</p>\n<hr>\n<h3 id=\"文档-Documents\"><a href=\"#文档-Documents\" class=\"headerlink\" title=\"文档 Documents\"></a>文档 Documents</h3><p>在正式进入主题之前，我们需要介绍一下langchain中对于文档的抽象Documents。</p>\n<p>LangChain 实现了一个 Document 抽象，旨在表示文本单元和相关元数据。它有两个属性：</p>\n<ul>\n<li><code>page_content</code>：表示内容的字符串</li>\n<li><code>metadata</code>：包含任意元数据的字典</li>\n</ul>\n<p>元数据属性可以捕获有关文档来源的信息、与其他文档的关系以及其他信息。</p>\n<p><strong>请注意，一个单独的 Document 对象通常代表了一个更大文档的一部分</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"></span><br><span class=\"line\">documents = [</span><br><span class=\"line\">    Document(</span><br><span class=\"line\">        page_content=<span class=\"string\">&quot;Dogs are great companions, known for their loyalty and friendliness.&quot;</span>,</span><br><span class=\"line\">        metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;mammal-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">    ),</span><br><span class=\"line\">    Document(</span><br><span class=\"line\">        page_content=<span class=\"string\">&quot;Cats are independent pets that often enjoy their own space.&quot;</span>,</span><br><span class=\"line\">        metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;mammal-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">    ),</span><br><span class=\"line\">    Document(</span><br><span class=\"line\">        page_content=<span class=\"string\">&quot;Goldfish are popular pets for beginners, requiring relatively simple care.&quot;</span>,</span><br><span class=\"line\">        metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;fish-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">    ),</span><br><span class=\"line\">    Document(</span><br><span class=\"line\">        page_content=<span class=\"string\">&quot;Parrots are intelligent birds capable of mimicking human speech.&quot;</span>,</span><br><span class=\"line\">        metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;bird-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">    ),</span><br><span class=\"line\">    Document(</span><br><span class=\"line\">        page_content=<span class=\"string\">&quot;Rabbits are social animals that need plenty of space to hop around.&quot;</span>,</span><br><span class=\"line\">        metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;mammal-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">    ),</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Chroma\"><a href=\"#Chroma\" class=\"headerlink\" title=\"Chroma\"></a><strong>Chroma</strong></h3><p><a href=\"https://www.trychroma.com/\">传送门</a></p>\n<p><strong>Chroma</strong> 是一个可以在本地运行的向量数据库。通过langchain 在本地建立一个数据库：</p>\n<p><strong>persist_directory</strong>:  chroma 数据库保存路径</p>\n<p><strong>embeddings_model</strong>:一个嵌入模型，可以是本地模型，可以是云端的模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 需要处理的文档对象数组</span></span><br><span class=\"line\">documents = [</span><br><span class=\"line\">    Document(</span><br><span class=\"line\">        page_content=<span class=\"string\">&quot;Dogs are great companions, known for their loyalty and friendliness.&quot;</span>,</span><br><span class=\"line\">        metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;mammal-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">    ),</span><br><span class=\"line\">Document(</span><br><span class=\"line\">    page_content=<span class=\"string\">&quot;Cats are independent pets that often enjoy their own space.&quot;</span>,</span><br><span class=\"line\">    metadata=&#123;<span class=\"string\">&quot;source&quot;</span>: <span class=\"string\">&quot;mammal-pets-doc&quot;</span>&#125;,</span><br><span class=\"line\">),</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这里我们用百度的 嵌入模型</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_AK&quot;</span>] = MY_QIANFAN_AK</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SK&quot;</span>] = MY_QIANFAN_SK</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 千帆 bge_large_en</span></span><br><span class=\"line\">embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Chroma 数据库</span></span><br><span class=\"line\">vector_store = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\">vector_store.add_documents(documents)</span><br><span class=\"line\"></span><br><span class=\"line\">query = <span class=\"string\">&#x27;Dogs？&#x27;</span></span><br><span class=\"line\"><span class=\"comment\">#查询方法1</span></span><br><span class=\"line\">docs = vector_store.similarity_search(query)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查询方法2</span></span><br><span class=\"line\">query_vctor = embeddingsa_model.embed_query(query)</span><br><span class=\"line\">docs = vector_store.similarity_search_by_vector(query_vctor)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(docs[<span class=\"number\">0</span>].page_content)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查询方法3</span></span><br><span class=\"line\">retriever = vector_store.as_retriever()</span><br><span class=\"line\">res = retriever.invoke(query)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Elastic-Search\"><a href=\"#Elastic-Search\" class=\"headerlink\" title=\"Elastic Search\"></a><strong>Elastic Search</strong></h3><p><strong>高性能</strong> +<strong>可视化 Dashboard</strong> + <strong>more</strong> …</p>\n<p>支持<strong>本地</strong>和<strong>云端</strong>部署 (阿里云和百度云有相关服务)</p>\n<p>安装</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install elasticsearch</span><br></pre></td></tr></table></figure>\n\n<p>ELASTIC_HOST_HTTP：服务端地址</p>\n<p>ELASTIC_ACCESS_PASSWORD：密码</p>\n<p>index_name：数据所在的索引</p>\n<p>es_user：用户名</p>\n<p>embedding：嵌入模型</p>\n<p>vector_query_field： 向量变量的名称</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 声明ES 数据库</span></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 上传文档</span></span><br><span class=\"line\">docs = [Document(page_content =<span class=\"string\">&#x27;Mojuan Test ES ..&#x27;</span>),</span><br><span class=\"line\">        Document(page_content=<span class=\"string\">&#x27;Susirial is a teacher&#x27;</span>)]</span><br><span class=\"line\">vectorstore.add_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 搜索</span></span><br><span class=\"line\">q_docs = vectorstore.similarity_search(<span class=\"string\">&#x27;Who is Susiral&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>Elasticsearch 支持以下向量距离相似性算法：</p>\n<ul>\n<li>余弦相似度（cosine）：这是默认的相似性算法，它测量两个向量在角度空间上的相似度，范围从-1（完全不同）到1（完全相同）。余弦相似度不考虑向量的大小，只考虑它们的方向，因此它对于高维空间中的文本数据特别有用。</li>\n<li>欧几里得距离（euclidean）：这是一种测量两个向量在欧几里得空间中的直线距离的算法。欧几里得距离越小，表示两个向量越相似。与余弦相似度不同，欧几里得距离考虑了向量的大小和方向。</li>\n<li>点积（dot_product）：这是一种基于向量点积的相似性度量方法。点积越大，表示两个向量越相似。点积实际上是一种特殊的余弦相似度，它假设向量已经被归一化（即长度为1）。 在 Elasticsearch 中，您可以通过设置 <code>similarity</code> 参数来指定所需的相似性算法。例如，当创建索引时，您可以指定使用哪种算法来计算向量之间的相似度。这允许您根据数据的特性和应用的需求选择最合适的相似性度量方法。</li>\n</ul>\n<hr>\n<p><strong>Elasticsearch 使用了许多信息检索技术，包括 BM25 算法和倒排索引</strong>。</p>\n<ol>\n<li><strong>倒排索引</strong>: Elasticsearch 使用倒排索引来存储文档中的词和它们所在的文档。<strong>每个词都与包含该词的所有文档的列表相关联</strong>。这样，Elasticsearch 可以快速地找到包含特定词的所有文档，而不需要检查每个文档。</li>\n<li><strong>BM25 算法</strong>: Elasticsearch 默认使用 BM25 算法来计算<strong>文档与查询之间的相关性</strong>。BM25 考虑了<strong>文档的词频</strong>（TF）、<strong>文档的倒数文档频率</strong>（IDF）以及<strong>文档长度</strong>等因素，来评估文档与查询的相关性。Elasticsearch 使用 BM25 算法来对搜索结果进行排序，返回与查询最相关的文档。 除了 BM25 算法和倒排索引，Elasticsearch 还使用了许多其他的信息检索技术，例如词干提取（Stemming）、词形还原（Lemmatization）、布尔查询（Boolean queries）等，以提供高效的搜索引擎功能。</li>\n</ol>\n<p>如果你对ES非常熟悉，你可以直接调用Langchain 里面的elasticsearch实例</p>\n<p>比如：普通字符串搜索</p>\n<p>query_dict： 是一个Elastic Search 支持的搜索格式</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">query = <span class=\"string\">&#x27;Susirial&#x27;</span></span><br><span class=\"line\">query_dict = &#123;<span class=\"string\">&quot;query&quot;</span>: &#123;<span class=\"string\">&quot;match&quot;</span>: &#123;<span class=\"string\">&quot;text&quot;</span>: query&#125;&#125;&#125;</span><br><span class=\"line\">res = vectorstore.client.search(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, body=query_dict)</span><br><span class=\"line\"></span><br><span class=\"line\">docs = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> res[<span class=\"string\">&quot;hits&quot;</span>][<span class=\"string\">&quot;hits&quot;</span>]:</span><br><span class=\"line\">    docs.append(Document(page_content=r[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;找到： &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(r[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>向量搜索 + BM25 =  提高文档召回率</p>\n<p>代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> HuggingFaceEmbeddings, QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.retrievers <span class=\"keyword\">import</span> ElasticSearchBM25Retriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cosine_similarity</span>(<span class=\"params\">vec1, vec2</span>):</span><br><span class=\"line\">    dot_product = np.dot(vec1, vec2)</span><br><span class=\"line\">    norm_vec1 = np.linalg.norm(vec1)</span><br><span class=\"line\">    norm_vec2 = np.linalg.norm(vec2)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dot_product / (norm_vec1 * norm_vec2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 远程百度调用</span></span><br><span class=\"line\">    <span class=\"comment\"># 这里我们用百度的 嵌入模型</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_AK&quot;</span>] = MY_QIANFAN_AK</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SK&quot;</span>] = MY_QIANFAN_SK</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆 bge_large_en</span></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Chroma 数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># 文档向量化 放入数据库</span></span><br><span class=\"line\">    vector_store = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\">    query = <span class=\"string\">&#x27;how can langsmith help with testing?&#x27;</span></span><br><span class=\"line\">    docs = vector_store.similarity_search(query)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    query_vctor = embeddings_model.embed_query(query)</span><br><span class=\"line\">    docs = vector_store.similarity_search_by_vector(query_vctor)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(docs[<span class=\"number\">0</span>].page_content)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    retriever = vector_store.as_retriever()</span><br><span class=\"line\">    res = retriever.invoke(query)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Elastic Search</span></span><br><span class=\"line\">    <span class=\"comment\"># # 向量数据库</span></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embeddings_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    docs = [Document(page_content =<span class=\"string\">&#x27;Mojuan Test ES ..&#x27;</span>),</span><br><span class=\"line\">            Document(page_content=<span class=\"string\">&#x27;Susirial is a teacher&#x27;</span>)]</span><br><span class=\"line\">    <span class=\"comment\"># vectorstore.add_documents(docs)</span></span><br><span class=\"line\">    <span class=\"comment\"># q_docs = vectorstore.similarity_search(&#x27;Who is Susiral&#x27;)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\">    query = <span class=\"string\">&#x27;Susirial&#x27;</span></span><br><span class=\"line\">    query_dict = &#123;<span class=\"string\">&quot;query&quot;</span>: &#123;<span class=\"string\">&quot;match&quot;</span>: &#123;<span class=\"string\">&quot;text&quot;</span>: query&#125;&#125;&#125;</span><br><span class=\"line\">    res = vectorstore.client.search(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, body=query_dict)</span><br><span class=\"line\"></span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> res[<span class=\"string\">&quot;hits&quot;</span>][<span class=\"string\">&quot;hits&quot;</span>]:</span><br><span class=\"line\">        docs.append(Document(page_content=r[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;找到： &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(r[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[10]文档加载 Document loader","url":"/forward/fbdea40c.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>能够熟练把文件载入到系统中，生成Document 对象。</p>\n<hr>\n<h3 id=\"CSV\"><a href=\"#CSV\" class=\"headerlink\" title=\"CSV\"></a><strong>CSV</strong></h3><p>默认参数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = CSVLoader(file_path=<span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>)</span><br><span class=\"line\">data = loader.load()</span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;姓名: 张三\\n年龄: 23\\n成绩: 优秀&#x27;</span>, </span><br><span class=\"line\">   metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">0</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 里斯\\n年龄: 26\\n成绩: 良&#x27;</span>, </span><br><span class=\"line\">   metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">1</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 王五\\n年龄: 34\\n成绩: 可&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">2</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<p>加上参数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = CSVLoader(file_path=<span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, csv_args=&#123;</span><br><span class=\"line\">    <span class=\"string\">&#x27;delimiter&#x27;</span>: <span class=\"string\">&#x27;,&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;quotechar&#x27;</span>: <span class=\"string\">&#x27;&quot;&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;fieldnames&#x27;</span>: [<span class=\"string\">&#x27;姓名&#x27;</span>, <span class=\"string\">&#x27;年龄&#x27;</span>, <span class=\"string\">&#x27;成绩&#x27;</span>]</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">data = loader.load()</span><br></pre></td></tr></table></figure>\n\n<p>每列前面加上fieldname</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;姓名: 姓名\\n年龄: 年龄\\n成绩: 成绩&#x27;</span>,</span><br><span class=\"line\">      metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">0</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 张三\\n年龄: 23\\n成绩: 优秀&#x27;</span>, </span><br><span class=\"line\">      metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">1</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 里斯\\n年龄: 26\\n成绩: 良&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">2</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 王五\\n年龄: 34\\n成绩: 可&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">3</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<p><strong>指定一列来识别文档来源</strong> 使用source_column参数为每行创建的文档指定一个来源。否则，file_path将用作从CSV文件创建的所有文档的来源。当使用从CSV文件加载的文档来回答问题时，这很有用，这样可以在链条中使用来源。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"> loader = CSVLoader(file_path=<span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, source_column=<span class=\"string\">&quot;姓名&quot;</span>)</span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;姓名: 张三\\n年龄: 23\\n成绩: 优秀&#x27;</span>, </span><br><span class=\"line\">          metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;张三\\t&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">0</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 里斯\\n年龄: 26\\n成绩: 良&#x27;</span>, </span><br><span class=\"line\">          metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;里斯&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">1</span>&#125;), </span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;姓名: 王五\\n年龄: 34\\n成绩: 可&#x27;</span>, </span><br><span class=\"line\">          metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;王五&#x27;</span>, <span class=\"string\">&#x27;row&#x27;</span>: <span class=\"number\">2</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<p>从文件夹载入</p>\n<p>安装</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install unstructured</span><br><span class=\"line\">pip install <span class=\"string\">&quot;unstructured[md]&quot;</span></span><br><span class=\"line\">    loader = DirectoryLoader(<span class=\"string\">&#x27;./test&#x27;</span>, glob=<span class=\"string\">&quot;**/*.md&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    docs = loader.load()</span><br></pre></td></tr></table></figure>\n\n<p>显示进度条 <strong>show_progress=True</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = DirectoryLoader(<span class=\"string\">&#x27;../&#x27;</span>, glob=<span class=\"string\">&quot;**/*.md&quot;</span>, show_progress=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<p>使用多线程 <strong>use_multithreading=True</strong> 默认情况下，加载操作是在单个线程中进行的。为了利用多个线程，请将use_multithreading标志设置为true。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = DirectoryLoader(<span class=\"string\">&#x27;../&#x27;</span>, glob=<span class=\"string\">&quot;**/*.md&quot;</span>, use_multithreading=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<p>修改loader类, 自动检测编码格式 <strong>‘autodetect_encoding’: True</strong></p>\n<h3 id=\"TXT\"><a href=\"#TXT\" class=\"headerlink\" title=\"TXT\"></a>TXT</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = DirectoryLoader(<span class=\"string\">&#x27;./test/&#x27;</span>, glob=<span class=\"string\">&quot;**/*.txt&quot;</span>, loader_cls=TextLoader,loader_kwargs=&#123;<span class=\"string\">&#x27;autodetect_encoding&#x27;</span>: <span class=\"literal\">True</span>&#125;)</span><br><span class=\"line\">docs = loader.load()</span><br></pre></td></tr></table></figure>\n\n<p>出错忽略，不打断整个载入过程 <strong>silent_errors=True</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = DirectoryLoader(<span class=\"string\">&#x27;./test/&#x27;</span>, glob=<span class=\"string\">&quot;**/*.txt&quot;</span>, </span><br><span class=\"line\">silent_errors=<span class=\"literal\">True</span>，</span><br><span class=\"line\">loader_cls=TextLoader,</span><br><span class=\"line\">loader_kwargs=&#123;<span class=\"string\">&#x27;autodetect_encoding&#x27;</span>: <span class=\"literal\">True</span>&#125;)</span><br><span class=\"line\">docs = loader.load()</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"Html\"><a href=\"#Html\" class=\"headerlink\" title=\"Html\"></a>Html</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = UnstructuredHTMLLoader(<span class=\"string\">&quot;./test/Langchain.html&quot;</span>)</span><br><span class=\"line\">data = loader.load()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;\\n\\nModules\\n\\nRetrieval\\...ulSoup4&#x27;</span>,</span><br><span class=\"line\">    metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/Langchain.html&#x27;</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"用BeautifulSoup4载入html\"><a href=\"#用BeautifulSoup4载入html\" class=\"headerlink\" title=\"用BeautifulSoup4载入html\"></a>用BeautifulSoup4载入html</h3><p>注意：需要设置 open_encoding=’utf-8’ 来应对gpk 解码错误</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = BSHTMLLoader(<span class=\"string\">&quot;./test/Langchain.html&quot;</span>,open_encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">data = loader.load()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\"># 输出</span></span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;\\n\\nHTML | 🦜️🔗 Langchain... mepageBlogYouTubeCopyright © 2024 LangChain, Inc.\\n\\n\\n&#x27;</span>, </span><br><span class=\"line\">  metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;./test/Langchain.html&#x27;</span>, <span class=\"string\">&#x27;title&#x27;</span>: <span class=\"string\">&#x27;HTML | 🦜️🔗 Langchain&#x27;</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Markdown\"><a href=\"#Markdown\" class=\"headerlink\" title=\"Markdown\"></a>Markdown</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># MD</span></span><br><span class=\"line\">loader = UnstructuredMarkdownLoader(<span class=\"string\">&#x27;D:\\\\LLM\\\\my_projects\\\\leanr_django_rag\\\\day_try\\\\test\\\\md-test.md&#x27;</span>)</span><br><span class=\"line\">data = loader.load()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出 ------</span></span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;CSV\\n\\n默认参数\\n\\nPython\\nl...&#x27;</span>, </span><br><span class=\"line\">    metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;D:\\\\LLM\\\\my_projects\\\\leanr_django_rag\\\\day_try\\\\test\\\\md-test.md&#x27;</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<p>细颗粒度文本收集 <strong>mode=”elements”</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = UnstructuredMarkdownLoader(<span class=\"string\">&#x27;D:\\\\LLM\\\\my_projects\\\\leanr_django_rag\\\\day_try\\\\test\\\\md-test.md&#x27;</span>,mode=<span class=\"string\">&quot;elements&quot;</span>)</span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;CSV&#x27;</span>, ...</span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&#x27;默认参数&#x27;</span>, ..</span><br><span class=\"line\"> Document(page_content=<span class=\"string\">&quot;Python\\nloader ..loader.load()&quot;</span>,..</span><br><span class=\"line\">Document(page_content=<span class=\"string\">&quot;Python\\n[D... &quot;</span></span><br><span class=\"line\">Document(page_content=<span class=\"string\">&#x27;加上参数&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: </span><br></pre></td></tr></table></figure>\n\n<h3 id=\"PDF\"><a href=\"#PDF\" class=\"headerlink\" title=\"PDF\"></a>PDF</h3><p>安装（虚拟环境）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install pypdf</span><br><span class=\"line\">    loader = PyPDFLoader(<span class=\"string\">&quot;test/pdf_带图带文字.pdf&quot;</span>)</span><br><span class=\"line\">    pages = loader.load_and_split()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pages[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>输出： 只解析了文字，没有识别图片中的文字</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[Document(page_content=<span class=\"string\">&quot;test pdf loader\\n图⽚\\x00闻\\n午\\x00时间\\x00\\x00吗\\x00\\n快\\x00连锁\\x00温\\x00（ Wendy&#x27;s ）否认\\x00有\\x00其\\x00对其菜单实\\x00\\x00\\x00\\x00\\x00的报\\x00。\\x00\\x00\\x00\\x00是 Uber 和其\\n他\\x00业采⽤的⼀种策略，\\x00在需\\x00\\x00加的任何时\\x00提\\x00\\x00格。这\\x00味\\x00，\\x00果温\\x00的  Pretzel\\nBaconators 需\\x00\\x00\\x00，顾\\x00可\\x00需\\x00\\x00付更\\x00的\\x00格。\\x00⽽，该\\x00司\\x00\\x00说，\\x00\\x00实\\x00的不是\\x00\\n\\x00\\x00\\x00，⽽是\\x00过其\\x00的\\x00\\x00菜单\\x00实⾏ “ 动态\\x00\\x00 ” 。这种动态\\x00\\x00策略\\x00许温\\x00在⼀\\x00中较\\x00的&quot;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;test/pdf_带图带文字.pdf&#x27;</span>, <span class=\"string\">&#x27;page&#x27;</span>: <span class=\"number\">0</span>&#125;), Document(page_content=<span class=\"string\">&#x27;时\\x00显⽰\\x00扣。需\\x00\\x00\\x00的是，动态\\x00\\x00\\x00\\x00\\x00\\x00\\x00不同，\\x00不\\x00\\x00基于需\\x00的涨\\x00。相\\x00，\\x00使\\n\\x00业\\x00\\x00\\x00据需\\x00变\\x00实时调\\x00\\x00格。这种\\x00技术的\\x00⽤\\x00映\\x00\\x00\\x00\\x00业\\x00据顾\\x00需\\x00优\\x00\\x00\\x00策\\n略的⽇\\x00\\x00⻓的趋势。&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;test/pdf_带图带文字.pdf&#x27;</span>, <span class=\"string\">&#x27;page&#x27;</span>: <span class=\"number\">1</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<p>咋办 ？安装</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install rapidocr-onnxruntime</span><br></pre></td></tr></table></figure>\n\n<p>带参数 <strong>extract_images=True</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loader = PyPDFLoader(<span class=\"string\">&quot;test/pdf_带图带文字.pdf&quot;</span>,extract_images=<span class=\"literal\">True</span>)</span><br><span class=\"line\">[Document(page_content=<span class=\"string\">&#x27;test pdf loader\\n图⽚\\x00闻\\n午\\x00时间\\x00\\x00吗\\x00\\n快\\x00连锁\\x00温\\x00（ Wendy\\&#x27;s ）否认\\x00有\\x00其\\x00对其菜单实\\x00\\x00\\x00\\x00\\x00的报\\x00。\\x00\\x00\\x00\\x00是 Uber 和其\\n他\\x00业采⽤的⼀种策略，\\x00在需\\x00\\x00加的任何时\\x00提\\x00\\x00格。这\\x00味\\x00，\\x00果温\\x00的  Pretzel\\nBaconators 需\\x00\\x00\\x00，顾\\x00可\\x00需\\x00\\x00付更\\x00的\\x00格。\\x00⽽，该\\x00司\\x00\\x00说，\\x00\\x00实\\x00的不是\\x00\\n\\x00\\x00\\x00，⽽是\\x00过其\\x00的\\x00\\x00菜单\\x00实⾏ “ 动态\\x00\\x00 ” 。这种动态\\x00\\x00策略\\x00许温\\x00在⼀\\x00中较\\x00的Timedforlunch?\\nWendy\\&#x27;s,afast-foodchain\\ndeniedreportsthatitwould\\nintroducesurgepricingforits\\nmenu.Surgepricingisusedby\\nUberandotherbusinessesto\\nraisepriceswhendemand\\nincreasesatanygiventime,so\\ncustomersatWendy\\&#x27;swould\\npaymoreiftherewasasurge\\nindemandforitsPretzel\\nBaconators.Thecompanysaid\\nthatinsteaditsnewdigital\\nmenuboardswouldbringin\\n&quot;dynamicpricing”,whichis\\nnotsurgepricing,itinsisted,\\nbutallowsittodisplaydis-\\ncounts“particularlyinthe\\nslowertimesofday&quot;New\\ntechnologyisincreasingly\\nallowingmanybusinessesto\\nadjusttheirpricesinrealtime\\ntochangesindemand.&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;test/pdf_带图带文字.pdf&#x27;</span>, <span class=\"string\">&#x27;page&#x27;</span>: <span class=\"number\">0</span>&#125;), Document(page_content=<span class=\"string\">&#x27;时\\x00显⽰\\x00扣。需\\x00\\x00\\x00的是，动态\\x00\\x00\\x00\\x00\\x00\\x00\\x00不同，\\x00不\\x00\\x00基于需\\x00的涨\\x00。相\\x00，\\x00使\\n\\x00业\\x00\\x00\\x00据需\\x00变\\x00实时调\\x00\\x00格。这种\\x00技术的\\x00⽤\\x00映\\x00\\x00\\x00\\x00业\\x00据顾\\x00需\\x00优\\x00\\x00\\x00策\\n略的⽇\\x00\\x00⻓的趋势。&#x27;</span>, metadata=&#123;<span class=\"string\">&#x27;source&#x27;</span>: <span class=\"string\">&#x27;test/pdf_带图带文字.pdf&#x27;</span>, <span class=\"string\">&#x27;page&#x27;</span>: <span class=\"number\">1</span>&#125;)]</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> uuid</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.memory <span class=\"keyword\">import</span> ConversationBufferMemory</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.csv_loader <span class=\"keyword\">import</span> CSVLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.directory <span class=\"keyword\">import</span> DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.html <span class=\"keyword\">import</span> UnstructuredHTMLLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.html_bs <span class=\"keyword\">import</span> BSHTMLLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.markdown <span class=\"keyword\">import</span> UnstructuredMarkdownLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> PyPDFLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.pdf <span class=\"keyword\">import</span> MathpixPDFLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.text <span class=\"keyword\">import</span> TextLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.llms.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanLLMEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage, SystemMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser, CommaSeparatedListOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompt_values <span class=\"keyword\">import</span> ChatPromptValue</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate, PromptTemplate, MessagesPlaceholder</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough, RunnableParallel, RunnableLambda, ConfigurableField</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> operator <span class=\"keyword\">import</span> itemgetter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.pydantic_v1 <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># CSV</span></span><br><span class=\"line\">    loader = CSVLoader(file_path=<span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    loader = CSVLoader(file_path=<span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, csv_args=&#123;</span><br><span class=\"line\">        <span class=\"string\">&#x27;delimiter&#x27;</span>: <span class=\"string\">&#x27;,&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;quotechar&#x27;</span>: <span class=\"string\">&#x27;&quot;&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;fieldnames&#x27;</span>: [<span class=\"string\">&#x27;姓名&#x27;</span>, <span class=\"string\">&#x27;年龄&#x27;</span>, <span class=\"string\">&#x27;成绩&#x27;</span>]</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\">    loader = CSVLoader(file_path=<span class=\"string\">&#x27;./test/csv_test.csv&#x27;</span>, source_column=<span class=\"string\">&quot;姓名&quot;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 从文件夹载入</span></span><br><span class=\"line\">    loader = DirectoryLoader(<span class=\"string\">&#x27;./test&#x27;</span>, glob=<span class=\"string\">&quot;**/*.md&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(docs)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 显示进度条</span></span><br><span class=\"line\">    loader = DirectoryLoader(<span class=\"string\">&#x27;../&#x27;</span>, glob=<span class=\"string\">&quot;**/*.md&quot;</span>, show_progress=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 多线程</span></span><br><span class=\"line\">    loader = DirectoryLoader(<span class=\"string\">&#x27;../&#x27;</span>, glob=<span class=\"string\">&quot;**/*.md&quot;</span>, use_multithreading=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用不同的loader</span></span><br><span class=\"line\">    loader = DirectoryLoader(<span class=\"string\">&#x27;./test/&#x27;</span>, glob=<span class=\"string\">&quot;**/*.txt&quot;</span>, loader_cls=TextLoader,loader_kwargs=&#123;<span class=\"string\">&#x27;autodetect_encoding&#x27;</span>: <span class=\"literal\">True</span>&#125;)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># HTML</span></span><br><span class=\"line\">    loader = UnstructuredHTMLLoader(<span class=\"string\">&quot;./test/Langchain.html&quot;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    loader = BSHTMLLoader(<span class=\"string\">&quot;./test/Langchain.html&quot;</span>,open_encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># MD</span></span><br><span class=\"line\">    loader = UnstructuredMarkdownLoader(<span class=\"string\">&#x27;D:\\\\LLM\\\\my_projects\\\\leanr_django_rag\\\\day_try\\\\test\\\\md-test.md&#x27;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    loader = UnstructuredMarkdownLoader(<span class=\"string\">&#x27;D:\\\\LLM\\\\my_projects\\\\leanr_django_rag\\\\day_try\\\\test\\\\md-test.md&#x27;</span>,mode=<span class=\"string\">&quot;elements&quot;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(data)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># PDF</span></span><br><span class=\"line\">    loader = PyPDFLoader(<span class=\"string\">&quot;test/pdf_带图带文字.pdf&quot;</span>)</span><br><span class=\"line\">    pages = loader.load_and_split()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pages[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    loader = PyPDFLoader(<span class=\"string\">&quot;test/pdf_带图带文字.pdf&quot;</span>,extract_images=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    pages = loader.load_and_split()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(pages[<span class=\"number\">0</span>])</span><br><span class=\"line\">    </span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[12]检索器 EnsembleRetriever","url":"/forward/a9247aca.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>了解EnsembleRetriever的使用场景</p>\n<hr>\n<p>EnsembleRetriever是一个工具，它<strong>将多个检索器的列表作为输入，并将这些检索器返回的相关文档结果进行整合</strong>。然后，它使用Reciprocal Rank Fusion算法对这些结果进行重新排序。 通过结合不同算法的优点，EnsembleRetriever的表现可以超过任何一个单独的算法。 最常见的方法是将一个基于稀疏特征的检索器（比如BM25）与一个基于密集特征的检索器（比如嵌入向量相似性）结合起来，因为它们的优点可以互相补充。这种方法也被称为“混合搜索”。稀疏检索器擅长根据关键词找到相关文档，而密集检索器则擅长根据语义相似度找到相关文档。</p>\n<p><strong>BM25搜索 + 向量搜索</strong></p>\n<hr>\n<p><strong>ElasticSearch BM25</strong>： langchain 实现的ES 数据库的BM25搜索</p>\n<p><strong>直接调用Langchain 的 ElasticSearchBM25Retriever 搜索方法，什么也查不到！？</strong></p>\n<p>代码分析：</p>\n<p>就是调用了ES的 search 方法，在 content 这个域搜索query</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">_get_relevant_documents</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">    self, query: <span class=\"built_in\">str</span>, *, run_manager: CallbackManagerForRetrieverRun</span></span><br><span class=\"line\"><span class=\"params\"> </span>) -&gt; <span class=\"type\">List</span>[Document]:</span><br><span class=\"line\">     query_dict = &#123;<span class=\"string\">&quot;query&quot;</span>: &#123;<span class=\"string\">&quot;match&quot;</span>: &#123;<span class=\"string\">&quot;content&quot;</span>: query&#125;&#125;&#125;</span><br><span class=\"line\">     res = self.client.search(index=self.index_name, body=query_dict)</span><br><span class=\"line\"></span><br><span class=\"line\">     docs = []</span><br><span class=\"line\">     <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> res[<span class=\"string\">&quot;hits&quot;</span>][<span class=\"string\">&quot;hits&quot;</span>]:</span><br><span class=\"line\">         docs.append(Document(page_content=r[<span class=\"string\">&quot;_source&quot;</span>][<span class=\"string\">&quot;content&quot;</span>]))</span><br><span class=\"line\">     <span class=\"keyword\">return</span> docs</span><br></pre></td></tr></table></figure>\n\n<p>回忆之前我们直接调用ES 底层进行搜素：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">query = <span class=\"string\">&#x27;Susirial&#x27;</span></span><br><span class=\"line\">query_dict = &#123;<span class=\"string\">&quot;query&quot;</span>: &#123;<span class=\"string\">&quot;match&quot;</span>: &#123;<span class=\"string\">&quot;text&quot;</span>: query&#125;&#125;&#125;</span><br><span class=\"line\">res = vectorstore.client.search(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, body=query_dict)</span><br><span class=\"line\"></span><br><span class=\"line\">docs = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> res[<span class=\"string\">&quot;hits&quot;</span>][<span class=\"string\">&quot;hits&quot;</span>]:</span><br><span class=\"line\">    docs.append(Document(page_content=r[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;找到： &#123;&#125;&#x27;</span>.<span class=\"built_in\">format</span>(r[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>{“query”: {“match”: {“content”: query}}} VS {“query”: {“match”: {“text”: query}}}</p>\n<p>重点： vectorstore.<strong>add_documents</strong>()</p>\n<p><strong>add_documents 方法默认把我们的数据上传到 数据的’text’ 这个域</strong></p>\n<p>我们需要修改 Langchain 的 ElasticSearch BM25 的搜索函数</p>\n<p>注意： 下面这个方法只适用于 ES</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#原来</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">_get_relevant_documents</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">    self, query: <span class=\"built_in\">str</span>, *, run_manager: CallbackManagerForRetrieverRun</span></span><br><span class=\"line\"><span class=\"params\"></span>) -&gt; <span class=\"type\">List</span>[Document]:</span><br><span class=\"line\">    query_dict = &#123;<span class=\"string\">&quot;query&quot;</span>: &#123;<span class=\"string\">&quot;match&quot;</span>: &#123;<span class=\"string\">&quot;content&quot;</span>: query&#125;&#125;&#125;</span><br><span class=\"line\">    res = self.client.search(index=self.index_name, body=query_dict)</span><br><span class=\"line\"></span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> res[<span class=\"string\">&quot;hits&quot;</span>][<span class=\"string\">&quot;hits&quot;</span>]:</span><br><span class=\"line\">        docs.append(Document(page_content=r[<span class=\"string\">&quot;_source&quot;</span>][<span class=\"string\">&quot;content&quot;</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> docs</span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\"># 修改为</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">_get_relevant_documents</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">      self, query: <span class=\"built_in\">str</span>, *, run_manager: CallbackManagerForRetrieverRun</span></span><br><span class=\"line\"><span class=\"params\">  </span>) -&gt; <span class=\"type\">List</span>[Document]:</span><br><span class=\"line\">      query_dict = &#123;<span class=\"string\">&quot;query&quot;</span>: &#123;<span class=\"string\">&quot;match&quot;</span>: &#123;<span class=\"string\">&quot;text&quot;</span>: query&#125;&#125;&#125;</span><br><span class=\"line\">      res = self.client.search(index=self.index_name, body=query_dict)</span><br><span class=\"line\"></span><br><span class=\"line\">      docs = []</span><br><span class=\"line\">      <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> res[<span class=\"string\">&quot;hits&quot;</span>][<span class=\"string\">&quot;hits&quot;</span>]:</span><br><span class=\"line\">          docs.append(Document(page_content=r[<span class=\"string\">&quot;_source&quot;</span>][<span class=\"string\">&quot;text&quot;</span>]))</span><br><span class=\"line\">      <span class=\"keyword\">return</span> docs</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>搜索内容对比，比如我们搜 ‘ReAct’</p>\n<p>BM25:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建立 BM25 检索器</span></span><br><span class=\"line\">bm25_retriever = ElasticSearchBM25Retriever(client=vectorstore.client, index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试 BM25</span></span><br><span class=\"line\">bm25_docs = bm25_retriever.get_relevant_documents(<span class=\"string\">&quot;ReAct&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>向量搜索</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">  es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">  index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">  embedding=embeddings_model,</span><br><span class=\"line\">  es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">  vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">  es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)  </span><br><span class=\"line\"></span><br><span class=\"line\">vector_docs = vector_retriever.get_relevant_documents(<span class=\"string\">&quot;ReAct &quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>文本块在分割时，按照chunk_size=500</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">500</span>, chunk_overlap=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<p>关键字搜索准确度，BM25 搜索结果 <strong>优于</strong> 向量搜索</p>\n<hr>\n<p>EnsembleRetriever： <strong>BM25搜索 + 向量搜索</strong></p>\n<p>设置权重weights=[0.5, 0.5]</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">ensemble_retriever = EnsembleRetriever(</span><br><span class=\"line\">    retrievers=[bm25_retriever, vector_retriever], weights=[<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">ensemble_docs = ensemble_retriever.invoke(<span class=\"string\">&quot;what is a LLM-powered autonomous agent system&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>用Agent 轻松实现复杂逻辑：先搜向量数据库，没有相关内容，再BM25搜索</strong></p>\n<p>安装：langchainhub  （从langsmith 上拿提示词，也可自己写）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install langchainhub</span><br></pre></td></tr></table></figure>\n\n<p>只需要写提示词</p>\n<p>你是茉卷知识库管理员,你掌握2个工具:search_vector_docs,  功能:在茉卷向量数据库中,搜索问题,并返回文档列表,里面是Document对象;search_bm25_docs,功能:在茉卷BM25数据库中,搜索问题,并返回文档列表,里面是Document对象.你需要<strong>先</strong>在茉卷向量数据库中进行搜索,如果搜到的内容无法回答用户的问题,你<strong>再</strong>到茉卷BM25数据库中搜索.用户的问题是:<strong>ReAct</strong>“</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># chat 模型</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">chat = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">    azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 向量检索器</span></span><br><span class=\"line\">vector_tool = create_retriever_tool(</span><br><span class=\"line\">    vector_retriever,</span><br><span class=\"line\">    <span class=\"string\">&quot;search_vector_docs&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;在茉卷向量数据库中,搜索问题,并返回文档列表,里面是Document对象&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># bm25 检索器</span></span><br><span class=\"line\">bm25_tool = create_retriever_tool(</span><br><span class=\"line\">    bm25_retriever,</span><br><span class=\"line\">    <span class=\"string\">&quot;search_bm25_docs&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;在茉卷BM25数据库中,搜索问题,并返回文档列表,里面是Document对象&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">tools = [vector_tool,bm25_tool]</span><br><span class=\"line\"></span><br><span class=\"line\">agent = create_openai_tools_agent(chat, tools, prompt)</span><br><span class=\"line\">agent_executor = AgentExecutor(agent=agent, tools=tools)</span><br><span class=\"line\">  user_input = (<span class=\"string\">&quot;你是茉卷知识库管理员,你掌握2个工具:search_vector_docs, 功能:在茉卷向量数据库中,搜索问题,并返回文档列表,里面是Document对象;&quot;</span></span><br><span class=\"line\">              <span class=\"string\">&quot;search_bm25_docs,功能:在茉卷BM25数据库中,搜索问题,并返回文档列表,里面是Document对象.&quot;</span></span><br><span class=\"line\">              <span class=\"string\">&quot;你需要先在茉卷向量数据库中进行搜索,如果搜到的内容无法回答用户的问题,你再到茉卷BM25数据库中搜索.&quot;</span></span><br><span class=\"line\">              <span class=\"string\">&quot;用户的问题是:ReAct&quot;</span>)</span><br><span class=\"line\">res = agent_executor.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: user_input&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>Agent 按照我们的要求执行，得到了结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;<span class=\"string\">&#x27;input&#x27;</span>: <span class=\"string\">&#x27;你是茉卷知识库管理员,你掌握2个工具:search_vector_docs, 功能:在茉卷向量数据库中,搜索问题,并返回文档列表,里面是Document对象;search_bm25_docs,功能:在茉卷BM25数据库中,搜索问题,并返回文档列表,里面是Document对象.你需要先在茉卷向量数据库中进行搜索,如果搜到的内容无法回答用户的问题,你再到茉卷BM25数据库中搜索.用户的问题是:ReAct&#x27;</span>, <span class=\"string\">&#x27;output&#x27;</span>: <span class=\"string\">&#x27;根据在茉卷BM25数据库中的搜索结果，找到了关于&quot;ReAct&quot;的文档。这些文档提到了ReAct模型，它在LLM中集成了推理和行动，并扩展了行动空间，使其成为任务特定离散行动和语言空间的组合。ReAct模型通过与环境交互（例如使用维基百科搜索API）和生成自然语言推理轨迹的方式，使LLM能够进行推理和行动。ReAct模型还提供了一个模板，用于指导LLM进行思考、行动和观察。\\n\\n如果在茉卷向量数据库中的搜索结果无法回答用户的问题，可以尝试在茉卷BM25数据库中进行搜索。在BM25数据库中的搜索结果显示，ReAct模型在知识密集型任务和决策任务上的实验中表现优于仅行动的基准模型。\\n\\n另外，还有一个案例研究提到了一个名为ChemCrow的领域特定示例，其中LLM通过13个专家设计的工具来完成有机合成、药物发现和材料设计等任务。这个案例研究中的工作流程与之前描述的ReAct和MRKLs相一致，并结合了与任务相关的工具和CoT推理。\\n\\n希望以上信息能够帮助回答用户的问题。如果还有其他问题，请随时提问。&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents <span class=\"keyword\">import</span> create_openai_tools_agent, AgentExecutor</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers <span class=\"keyword\">import</span> EnsembleRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.tools.retriever <span class=\"keyword\">import</span> create_retriever_tool</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.web_base <span class=\"keyword\">import</span> WebBaseLoader</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> HuggingFaceEmbeddings, QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.retrievers <span class=\"keyword\">import</span> ElasticSearchBM25Retriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_text_splitters <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置一个随机ID</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置一个Log 名称</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [Agent]BM25+向量  - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置 生成Langsmith 轨迹</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 填写你的 API KEY</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆 bge_large_en</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用ES</span></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embeddings_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    data = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># # 分割文本</span></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">500</span>, chunk_overlap=<span class=\"number\">0</span>)</span><br><span class=\"line\">    splits = text_splitter.split_documents(data)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 写入数据库，运行一次就行</span></span><br><span class=\"line\">    <span class=\"comment\">#vectorstore.add_documents(splits)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 建立向量检索器</span></span><br><span class=\"line\">    vector_retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&#x27;k&#x27;</span>: <span class=\"number\">10</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 建立 BM25 检索器</span></span><br><span class=\"line\">    bm25_retriever = ElasticSearchBM25Retriever(client=vectorstore.client, index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,search_kwargs=&#123;<span class=\"string\">&#x27;k&#x27;</span>: <span class=\"number\">10</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试 BM25</span></span><br><span class=\"line\">    <span class=\"comment\"># bm25_docs = bm25_retriever.get_relevant_documents(&quot;what is a LLM-powered autonomous agent system&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试 向量搜索</span></span><br><span class=\"line\">    <span class=\"comment\"># vector_docs = vector_retriever.get_relevant_documents(&quot;what is a LLM-powered autonomous agent system&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ensemble_retriever = EnsembleRetriever(</span><br><span class=\"line\">        retrievers=[bm25_retriever, vector_retriever], weights=[<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ensemble_docs = ensemble_retriever.invoke(&quot;what is a LLM-powered autonomous agent system&quot;)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    vector_tool = create_retriever_tool(</span><br><span class=\"line\">        vector_retriever,</span><br><span class=\"line\">        <span class=\"string\">&quot;search_vector_docs&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;在茉卷向量数据库中,搜索问题,并返回文档列表,里面是Document对象&quot;</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    bm25_tool = create_retriever_tool(</span><br><span class=\"line\">        bm25_retriever,</span><br><span class=\"line\">        <span class=\"string\">&quot;search_bm25_docs&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;在茉卷BM25数据库中,搜索问题,并返回文档列表,里面是Document对象&quot;</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    tools = [vector_tool,bm25_tool]</span><br><span class=\"line\"></span><br><span class=\"line\">    prompt = hub.pull(<span class=\"string\">&quot;hwchase17/openai-tools-agent&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 定义agent</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    chat = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">        temperature=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    agent = create_openai_tools_agent(chat, tools, prompt)</span><br><span class=\"line\">    agent_executor = AgentExecutor(agent=agent, tools=tools)</span><br><span class=\"line\">    user_input = (<span class=\"string\">&quot;你是茉卷知识库管理员,你掌握2个工具:search_vector_docs, 功能:在茉卷向量数据库中,搜索问题,并返回文档列表,里面是Document对象;&quot;</span></span><br><span class=\"line\">                  <span class=\"string\">&quot;search_bm25_docs,功能:在茉卷BM25数据库中,搜索问题,并返回文档列表,里面是Document对象.&quot;</span></span><br><span class=\"line\">                  <span class=\"string\">&quot;你需要先在茉卷向量数据库中进行搜索,如果搜到的内容无法回答用户的问题,你再到茉卷BM25数据库中搜索.&quot;</span></span><br><span class=\"line\">                  <span class=\"string\">&quot;用户的问题是:ReAct&quot;</span>)</span><br><span class=\"line\">    res = agent_executor.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: user_input&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[13]检索器 MultiVector Retriever","url":"/forward/69e87aa0.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>了解MultiVector Retriever 的使用场景</p>\n<hr>\n<p><strong>存储每个文档的多个向量通常是有益的。</strong></p>\n<p>LangChain 有一个基础的 MultiVectorRetriever，它可以轻松查询这种类型的设置。大部分复杂性在于如何为每个文档创建多个向量。</p>\n<p>创建每个文档的多个向量的方法包括：</p>\n<ol>\n<li>较小的块：将文档分成较小的块，并嵌入这些块（这就是 ParentDocumentRetriever）。</li>\n<li>摘要：为每个文档创建一个摘要，并嵌入该摘要，以及（或代替）文档。</li>\n<li>假设性问题：创建假设性问题，每个文档都适合回答，并嵌入这些问题，以及（或代替）文档。</li>\n<li><strong>手动添加</strong></li>\n</ol>\n<hr>\n<p>分割成小块</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-13-%E6%A3%80%E7%B4%A2%E5%99%A8-MultiVector-Retriever.assets/image-20240627105930681.png\" alt=\"image-20240627105930681\"></p>\n<p>生成摘要</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-13-%E6%A3%80%E7%B4%A2%E5%99%A8-MultiVector-Retriever.assets/image-20240627105938216.png\" alt=\"image-20240627105938216\"></p>\n<p>提问</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-13-%E6%A3%80%E7%B4%A2%E5%99%A8-MultiVector-Retriever.assets/image-20240627105946306.png\" alt=\"image-20240627105946306\"></p>\n<hr>\n<p>InMemoryByteStore： 将文件ID映射在内存，找到小块后，根据ID找到文件</p>\n<p>文本信息保存在内存：InMemoryByteStore</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">embeddings_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">    model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">    encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">vectorstore = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The storage layer for the parent documents</span></span><br><span class=\"line\">store = InMemoryByteStore()</span><br><span class=\"line\">id_key = <span class=\"string\">&quot;doc_id&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># The retriever (empty to start)</span></span><br><span class=\"line\">retriever = MultiVectorRetriever(</span><br><span class=\"line\">    vectorstore=vectorstore,</span><br><span class=\"line\">    byte_store=store,</span><br><span class=\"line\">    id_key=id_key,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">doc_ids = [<span class=\"built_in\">str</span>(uuid.uuid4()) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> docs]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The splitter to use to create smaller chunks</span></span><br><span class=\"line\">child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">sub_docs = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(docs):</span><br><span class=\"line\">    _<span class=\"built_in\">id</span> = doc_ids[i]</span><br><span class=\"line\">    _sub_docs = child_text_splitter.split_documents([doc])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _doc <span class=\"keyword\">in</span> _sub_docs:</span><br><span class=\"line\">        _doc.metadata[id_key] = _<span class=\"built_in\">id</span></span><br><span class=\"line\">    sub_docs.extend(_sub_docs)</span><br><span class=\"line\"></span><br><span class=\"line\">question = <span class=\"string\">&quot;What are the approaches to Task Decomposition?&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">retriever.vectorstore.add_documents(sub_docs)</span><br><span class=\"line\">retriever.docstore.mset(<span class=\"built_in\">list</span>(<span class=\"built_in\">zip</span>(doc_ids, docs)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得小块</span></span><br><span class=\"line\">doc = retriever.vectorstore.similarity_search(<span class=\"string\">&quot;justice breyer&quot;</span>)[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n\n<p>文本信息保存在ES</p>\n<p>小文本块 ←  doc_id  → 大文本</p>\n<p>思路：</p>\n<p>索引数据： 先索引小段文本（向量化），再推送文本（不向量化）</p>\n<p>小文本数据结构</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-13-%E6%A3%80%E7%B4%A2%E5%99%A8-MultiVector-Retriever.assets/image-20240627110013819.png\" alt=\"image-20240627110013819\"></p>\n<p>大文本数据结构</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-13-%E6%A3%80%E7%B4%A2%E5%99%A8-MultiVector-Retriever.assets/image-20240627110025237.png\" alt=\"image-20240627110025237\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">embeddings_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">    model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">    encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Elastic Search</span></span><br><span class=\"line\"><span class=\"comment\"># 向量数据库</span></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成 大文件ID</span></span><br><span class=\"line\">doc_ids = [<span class=\"built_in\">str</span>(uuid.uuid4()) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> docs]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分割成小块</span></span><br><span class=\"line\">child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\">id_key = <span class=\"string\">&#x27;doc_id&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(docs):</span><br><span class=\"line\">    _<span class=\"built_in\">id</span> = doc_ids[i]</span><br><span class=\"line\">    _sub_docs = child_text_splitter.split_documents([doc])</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _doc <span class=\"keyword\">in</span> _sub_docs:</span><br><span class=\"line\">        _doc.metadata[id_key] = _<span class=\"built_in\">id</span></span><br><span class=\"line\">        _doc.metadata[<span class=\"string\">&#x27;data_type&#x27;</span>] = <span class=\"string\">&#x27;small_chunk&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将小的文本段向量化推送到ES</span></span><br><span class=\"line\">    vectorstore.add_documents(_sub_docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将文件整个推送到ES(不做embedding)</span></span><br><span class=\"line\">    tmp_doc = &#123;</span><br><span class=\"line\">        <span class=\"string\">&#x27;text&#x27;</span>: doc.page_content,</span><br><span class=\"line\">        <span class=\"string\">&#x27;metadata&#x27;</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">&#x27;data_type&#x27;</span>: <span class=\"string\">&#x27;big_chunk&#x27;</span>,</span><br><span class=\"line\">            id_key: _<span class=\"built_in\">id</span>,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    vectorstore.client.index(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, <span class=\"built_in\">id</span>=_<span class=\"built_in\">id</span>, document=tmp_doc)</span><br></pre></td></tr></table></figure>\n\n<p>查询： 先用语义搜索找到小文本，再用小文本的doc_id 找到 大文本</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获得小块</span></span><br><span class=\"line\">small_chunk_docs = vectorstore.similarity_search(<span class=\"string\">&#x27;justice breyer&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得大块</span></span><br><span class=\"line\"><span class=\"comment\"># 获得不重复的大文本id</span></span><br><span class=\"line\">id_key = <span class=\"string\">&#x27;doc_id&#x27;</span></span><br><span class=\"line\">doc_uuid_list = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> small_chunk_docs:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> doc.metadata[id_key] <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> doc_uuid_list:</span><br><span class=\"line\">        doc_uuid_list.append(doc.metadata[id_key])</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;找到小文本[&#123;&#125;]&#x27;</span>.<span class=\"built_in\">format</span>(doc.metadata[id_key]))</span><br><span class=\"line\">big_docs= []</span><br><span class=\"line\"><span class=\"keyword\">for</span> doc_uuid <span class=\"keyword\">in</span> doc_uuid_list:</span><br><span class=\"line\">    res = vectorstore.client.get(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, <span class=\"built_in\">id</span>=doc_uuid)</span><br><span class=\"line\">    big_docs.append(Document(page_content = res.body[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;获得大块 [&#123;&#125;]个&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"built_in\">len</span>(big_docs)))</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents <span class=\"keyword\">import</span> create_openai_tools_agent, AgentExecutor</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers <span class=\"keyword\">import</span> EnsembleRetriever, MultiQueryRetriever, MultiVectorRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.storage <span class=\"keyword\">import</span> InMemoryByteStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.tools.retriever <span class=\"keyword\">import</span> create_retriever_tool</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.web_base <span class=\"keyword\">import</span> WebBaseLoader</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> HuggingFaceEmbeddings, QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.retrievers <span class=\"keyword\">import</span> ElasticSearchBM25Retriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_text_splitters <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">import</span> uuid</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置一个随机ID</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置一个Log 名称</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [MultiQueryRetriever] 小段  - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置 生成Langsmith 轨迹</span></span><br><span class=\"line\"><span class=\"comment\"># os.environ[&quot;LANGCHAIN_TRACING_V2&quot;] = &#x27;true&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 填写你的 API KEY</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">    bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">    embeddings_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">        model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">        encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Elastic Search</span></span><br><span class=\"line\">    <span class=\"comment\"># 向量数据库</span></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embeddings_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成 大文件ID</span></span><br><span class=\"line\">    doc_ids = [<span class=\"built_in\">str</span>(uuid.uuid4()) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> docs]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 分割成小块</span></span><br><span class=\"line\">    child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\">    id_key = <span class=\"string\">&#x27;doc_id&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(docs):</span><br><span class=\"line\">        _<span class=\"built_in\">id</span> = doc_ids[i]</span><br><span class=\"line\">        _sub_docs = child_text_splitter.split_documents([doc])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> _doc <span class=\"keyword\">in</span> _sub_docs:</span><br><span class=\"line\">            _doc.metadata[id_key] = _<span class=\"built_in\">id</span></span><br><span class=\"line\">            _doc.metadata[<span class=\"string\">&#x27;data_type&#x27;</span>] = <span class=\"string\">&#x27;small_chunk&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 将小的文本段向量化推送到ES</span></span><br><span class=\"line\">        vectorstore.add_documents(_sub_docs)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 将文件整个推送到ES(不做embedding)</span></span><br><span class=\"line\">        tmp_doc = &#123;</span><br><span class=\"line\">            <span class=\"string\">&#x27;text&#x27;</span>: doc.page_content,</span><br><span class=\"line\">            <span class=\"string\">&#x27;metadata&#x27;</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">&#x27;data_type&#x27;</span>: <span class=\"string\">&#x27;big_chunk&#x27;</span>,</span><br><span class=\"line\">                id_key: _<span class=\"built_in\">id</span>,</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        vectorstore.client.index(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, <span class=\"built_in\">id</span>=_<span class=\"built_in\">id</span>, document=tmp_doc)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获得小块</span></span><br><span class=\"line\">    small_chunk_docs = vectorstore.similarity_search(<span class=\"string\">&#x27;justice breyer&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获得大块</span></span><br><span class=\"line\">    <span class=\"comment\"># 获得不重复的大文本id</span></span><br><span class=\"line\">    id_key = <span class=\"string\">&#x27;doc_id&#x27;</span></span><br><span class=\"line\">    doc_uuid_list = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> small_chunk_docs:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> doc.metadata[id_key] <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> doc_uuid_list:</span><br><span class=\"line\">            doc_uuid_list.append(doc.metadata[id_key])</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;找到小文本[&#123;&#125;]&#x27;</span>.<span class=\"built_in\">format</span>(doc.metadata[id_key]))</span><br><span class=\"line\">    big_docs= []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> doc_uuid <span class=\"keyword\">in</span> doc_uuid_list:</span><br><span class=\"line\">        res = vectorstore.client.get(index=<span class=\"string\">&#x27;index_sd_1024_vectors&#x27;</span>, <span class=\"built_in\">id</span>=doc_uuid)</span><br><span class=\"line\">        big_docs.append(Document(page_content = res.body[<span class=\"string\">&#x27;_source&#x27;</span>][<span class=\"string\">&#x27;text&#x27;</span>]))</span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;获得大块 [&#123;&#125;]个&#x27;</span>.<span class=\"built_in\">format</span>(<span class=\"built_in\">len</span>(big_docs)))</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[11]检索器 MultiQueryRetriever","url":"/forward/995d7fde.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>了解 <strong>MultiQueryRetriever</strong> 的使用场景和用法。</p>\n<hr>\n<p><strong>检索可能会因查询用词的微小变化或在嵌入不能很好地捕获数据语义时产生不同的结果。</strong></p>\n<p>多查询检索器（MultiQueryRetriever）通过使用大型语言模型（LLM）来自动化提示调优过程。<strong>对于给定的用户输入查询，它生成多个查询，每个查询都从不同的角度生成</strong>。</p>\n<p>对于每个查询，它检索一组相关的文档，并取所有查询的独特并集，以获得一组可能相关的更大文档集合。通过为同一问题生成多个视角，多查询检索器可能能够克服基于距离的检索的一些局限性，并获取更丰富的结果集。</p>\n<p>MultiQueryRetriever 基本思想 ：</p>\n<p><strong>基于某个问题，从不同角度提出新问题，每个新问题从数据库中召回文本</strong> <img src=\"/images/Langchain%E7%B3%BB%E5%88%97-11-%E6%A3%80%E7%B4%A2%E5%99%A8-MultiQueryRetriever/image-20240627110621795.png\" alt=\"image-20240627110621795\"></p>\n<p>关键提示词</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">You are an AI language model assistant. Your task <span class=\"keyword\">is</span> </span><br><span class=\"line\">    to generate <span class=\"number\">3</span> different versions of the given user </span><br><span class=\"line\">    question to retrieve relevant documents <span class=\"keyword\">from</span> a vector  database. </span><br><span class=\"line\">    By generating multiple perspectives on the user question, </span><br><span class=\"line\">    your goal <span class=\"keyword\">is</span> to <span class=\"built_in\">help</span> the user overcome some of the limitations </span><br><span class=\"line\">    of distance-based similarity search. Provide these alternative </span><br><span class=\"line\">    questions separated by newlines. Original question: </span><br></pre></td></tr></table></figure>\n\n<p>langchain: 只需要传入 chatModel 和 检索器</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 千帆 bge_large_en</span></span><br><span class=\"line\">embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Chroma 数据库</span></span><br><span class=\"line\"><span class=\"comment\"># 文档向量化 放入数据库</span></span><br><span class=\"line\">vectorstore = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">chat = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">    azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">retriever_from_llm = MultiQueryRetriever.from_llm(</span><br><span class=\"line\">    retriever=vectorstore.as_retriever(), llm=chat</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">question = <span class=\"string\">&quot;What are the approaches to Task Decomposition?&quot;</span></span><br><span class=\"line\">unique_docs = retriever_from_llm.get_relevant_documents(query=question)</span><br><span class=\"line\"><span class=\"built_in\">len</span>(unique_docs)</span><br></pre></td></tr></table></figure>\n\n<p>![image-20240627110636492]([Vol][11]检索器 MultiQueryRetriever.assets/image-20240627110636492.png)</p>\n<p>自己实现：<strong>MultiQueryRetriever</strong>: 单一问题扩展</p>\n<p>先获得问题，再查找</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">  You are an AI language model assistant. Your task is </span></span><br><span class=\"line\"><span class=\"string\">      to generate 3 different versions of the given user </span></span><br><span class=\"line\"><span class=\"string\">      question to retrieve relevant documents from a vector  database. </span></span><br><span class=\"line\"><span class=\"string\">      By generating multiple perspectives on the user question, </span></span><br><span class=\"line\"><span class=\"string\">      your goal is to help the user overcome some of the limitations </span></span><br><span class=\"line\"><span class=\"string\">      of distance-based similarity search. Provide these alternative </span></span><br><span class=\"line\"><span class=\"string\">      questions separated by newlines. Original question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\"></span><br><span class=\"line\">    add_q_chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">        | LineListOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># 获取问题</span></span><br><span class=\"line\">    question_list = add_q_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>:question&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 数据库 retriever</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> question <span class=\"keyword\">in</span> question_list:</span><br><span class=\"line\">        tmp_doc = retriever.get_relevant_documents(question)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(tmp_doc) &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">            docs += tmp_doc</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;done&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>自己实现：复杂问题拆分</strong></p>\n<p>问题：</p>\n<p><strong>什么是任务分解的方法？您能提供不同的任务分解方法或策略吗？ 有哪些方法可以用来将任务分解成更小的子任务？如何使用不同的技术或方法来执行任务分解？</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        你是一个问题分析助手，如果用户的问题过于复杂，你需要将问题拆解成几个问题。</span></span><br><span class=\"line\"><span class=\"string\">        只返回问题。</span></span><br><span class=\"line\"><span class=\"string\">        原始问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\"></span><br><span class=\"line\">    decompose_q_chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | LineListOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    什么是任务分解的方法？您能提供不同的任务分解方法或策略吗？</span></span><br><span class=\"line\"><span class=\"string\">    有哪些方法可以用来将任务分解成更小的子任务？如何使用不同的技术或方法来执行任务分解？</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 分解问题</span></span><br><span class=\"line\">    question_list = decompose_q_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 数据库 retriever</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> question <span class=\"keyword\">in</span> question_list:</span><br><span class=\"line\">        tmp_doc = retriever.get_relevant_documents(question)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(tmp_doc) &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">            docs += tmp_doc</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;done&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>自动判断是否需要拆解或者新增</p>\n<p>【1】是不是复杂问题？</p>\n<p>【2】复杂问题→拆解</p>\n<p>【3】单一问题→提出新问题</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">  <span class=\"comment\"># 判断问题类型 选择分支</span></span><br><span class=\"line\">  prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">      你是一个问题分析助手，如果问题非常复杂，可以拆解出多个问题，返回yes,否则返回No</span></span><br><span class=\"line\"><span class=\"string\">      原始问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">      &quot;&quot;&quot;</span></span><br><span class=\"line\">  prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\"></span><br><span class=\"line\">  check_q_chain = (</span><br><span class=\"line\">          &#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125;</span><br><span class=\"line\">          | prompt</span><br><span class=\"line\">          | chat</span><br><span class=\"line\">          | StrOutputParser()</span><br><span class=\"line\">  )  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">route</span>(<span class=\"params\">info</span>):</span><br><span class=\"line\">      <span class=\"keyword\">if</span> <span class=\"string\">&quot;yes&quot;</span> <span class=\"keyword\">in</span> info[<span class=\"string\">&quot;need_decompose&quot;</span>].lower():</span><br><span class=\"line\">          <span class=\"keyword\">return</span> decompose_q_chain</span><br><span class=\"line\">      <span class=\"keyword\">else</span>:</span><br><span class=\"line\">          <span class=\"keyword\">return</span> add_q_chain</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">  full_chain = &#123;<span class=\"string\">&quot;need_decompose&quot;</span>: check_q_chain, <span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125; | RunnableLambda(route)</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># 简单问题 question = &#x27;什么是任务分解的方法？&#x27;</span></span><br><span class=\"line\">  <span class=\"comment\"># 复杂问题</span></span><br><span class=\"line\">  question = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">  什么是任务分解的方法？您能提供不同的任务分解方法或策略吗？</span></span><br><span class=\"line\"><span class=\"string\">  有哪些方法可以用来将任务分解成更小的子任务？如何使用不同的技术或方法来执行任务分解？</span></span><br><span class=\"line\"><span class=\"string\">  &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  res = full_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question&#125;)</span><br><span class=\"line\">  <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.chains.llm <span class=\"keyword\">import</span> LLMChain</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers.multi_query <span class=\"keyword\">import</span> LineListOutputParser, MultiQueryRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.web_base <span class=\"keyword\">import</span> WebBaseLoader</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> HuggingFaceEmbeddings, QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.retrievers <span class=\"keyword\">import</span> ElasticSearchBM25Retriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.chroma <span class=\"keyword\">import</span> Chroma</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">List</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.chains <span class=\"keyword\">import</span> LLMChain</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.output_parsers <span class=\"keyword\">import</span> PydanticOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.prompts <span class=\"keyword\">import</span> PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnableLambda</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_text_splitters <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> pydantic <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置一个随机ID</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置一个Log 名称</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [问题类型判断] 复杂问题  - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置 生成Langsmith 轨迹</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 填写你的 API KEY</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 远程百度调用</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆 文心一言4, 会出错</span></span><br><span class=\"line\">    <span class=\"comment\"># chat = QianfanChatEndpoint(</span></span><br><span class=\"line\">    <span class=\"comment\">#     model=&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    chat = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">        temperature=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 千帆 bge_large_en</span></span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_en&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_en&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Chroma 数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># 文档向量化 放入数据库</span></span><br><span class=\"line\">    vectorstore = Chroma(persist_directory=<span class=\"string\">&quot;D:\\\\LLM\\\\my_projects\\\\chroma_db&quot;</span>, embedding_function=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    <span class=\"comment\"># loader = WebBaseLoader(&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># data = loader.load()</span></span><br><span class=\"line\">    <span class=\"comment\">#</span></span><br><span class=\"line\">    <span class=\"comment\"># # 分割文本</span></span><br><span class=\"line\">    <span class=\"comment\"># text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)</span></span><br><span class=\"line\">    <span class=\"comment\"># splits = text_splitter.split_documents(data)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 写入数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># vectorstore.add_documents(splits)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    retriever_from_llm = MultiQueryRetriever.from_llm(</span><br><span class=\"line\">        retriever=vectorstore.as_retriever(), llm=chat</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&quot;What are the approaches to Task Decomposition?&quot;</span></span><br><span class=\"line\">    unique_docs = retriever_from_llm.get_relevant_documents(query=question)</span><br><span class=\"line\">    <span class=\"built_in\">len</span>(unique_docs)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 拆解 Langchain ，自己实现这个功能</span></span><br><span class=\"line\">    prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    You are an AI language model assistant. Your task is to generate five</span></span><br><span class=\"line\"><span class=\"string\">        different versions of the given user question to retrieve relevant documents from a vector</span></span><br><span class=\"line\"><span class=\"string\">        database. By generating multiple perspectives on the user question, your goal is to help</span></span><br><span class=\"line\"><span class=\"string\">        the user overcome some of the limitations of the distance-based similarity search.</span></span><br><span class=\"line\"><span class=\"string\">        Provide these alternative questions separated by newlines.</span></span><br><span class=\"line\"><span class=\"string\">        Original question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\"></span><br><span class=\"line\">    add_q_chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">        | LineListOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># 获取问题</span></span><br><span class=\"line\">    question_list = add_q_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>:question&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 数据库 retriever</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> question <span class=\"keyword\">in</span> question_list:</span><br><span class=\"line\">        tmp_doc = retriever.get_relevant_documents(question)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(tmp_doc) &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">            docs += tmp_doc</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;done&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 实现一个问题的 拆解</span></span><br><span class=\"line\">    prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        你是一个问题分析助手，如果用户的问题过于复杂，你需要将问题拆解成几个问题。</span></span><br><span class=\"line\"><span class=\"string\">        只返回问题。</span></span><br><span class=\"line\"><span class=\"string\">        原始问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\"></span><br><span class=\"line\">    decompose_q_chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | LineListOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    什么是任务分解的方法？您能提供不同的任务分解方法或策略吗？</span></span><br><span class=\"line\"><span class=\"string\">    有哪些方法可以用来将任务分解成更小的子任务？如何使用不同的技术或方法来执行任务分解？</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 分解问题</span></span><br><span class=\"line\">    question_list = decompose_q_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 数据库 retriever</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> question <span class=\"keyword\">in</span> question_list:</span><br><span class=\"line\">        tmp_doc = retriever.get_relevant_documents(question)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(tmp_doc) &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">            docs += tmp_doc</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;done&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 判断问题类型 选择分支</span></span><br><span class=\"line\">    prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        你是一个问题分析助手，如果问题非常复杂，可以拆解出多个问题，返回yes,否则返回No</span></span><br><span class=\"line\"><span class=\"string\">        原始问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\"></span><br><span class=\"line\">    check_q_chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\">    question = <span class=\"string\">&#x27;今天星期几？&#x27;</span></span><br><span class=\"line\">    res = check_q_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">route</span>(<span class=\"params\">info</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&quot;yes&quot;</span> <span class=\"keyword\">in</span> info[<span class=\"string\">&quot;need_decompose&quot;</span>].lower():</span><br><span class=\"line\">            <span class=\"keyword\">return</span> decompose_q_chain</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> add_q_chain</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    full_chain = &#123;<span class=\"string\">&quot;need_decompose&quot;</span>: check_q_chain, <span class=\"string\">&quot;question&quot;</span>: <span class=\"keyword\">lambda</span> x: x[<span class=\"string\">&quot;question&quot;</span>]&#125; | RunnableLambda(route)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 简单问题 question = &#x27;什么是任务分解的方法？&#x27;</span></span><br><span class=\"line\">    <span class=\"comment\"># 复杂问题</span></span><br><span class=\"line\">    question = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    什么是任务分解的方法？您能提供不同的任务分解方法或策略吗？</span></span><br><span class=\"line\"><span class=\"string\">    有哪些方法可以用来将任务分解成更小的子任务？如何使用不同的技术或方法来执行任务分解？</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    res = full_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[15]向量过滤 VS 文档去重","url":"/forward/5bde2632.html","content":"<p>向量过滤 <code>EmbeddingsFilter</code></p>\n<p>使用大型语言模型（LLM）来处理每个找到的文件很费钱，而且速度不快。</p>\n<p>而EmbeddingsFilter这个工具提供了一种更经济、更迅速的方法。</p>\n<p><strong>它会先将文件和你的问题转换成一种数学表达（嵌入），然后只挑出那些和你的问题在数学表达上相似的文件</strong>。这样就不需要每个文件都去麻烦那个大模型，省时省力。</p>\n<p><strong>设定一个门限值，通过输入问题和内容的相关度（0~1），进行过滤</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">question = <span class=\"string\">&quot;What is Task Decomposition ?&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\">docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 索引数据 ，一次就够，后续可以注释</span></span><br><span class=\"line\"><span class=\"comment\"># # vectorstore.add_documents(docs)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># EmbeddingsFilter</span></span><br><span class=\"line\"></span><br><span class=\"line\">embedding_filter_embeddings_filter = EmbeddingsFilter(embeddings=embeddings_model, similarity_threshold=<span class=\"number\">0.7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 直接过滤文档</span></span><br><span class=\"line\">filtered_docs = embedding_filter_embeddings_filter.compress_documents(docs[:<span class=\"number\">10</span>],question)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">embedding_filter_compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">    base_compressor=embedding_filter_embeddings_filter, base_retriever=retriever</span><br><span class=\"line\">)</span><br><span class=\"line\">embedding_filter_docs = embedding_filter_compression_retriever.get_relevant_documents(question)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>文档去重 EmbeddingsRedundantFilter</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102230593.png\" alt=\"image-20240627102230593\"></p>\n<p>相似度矩阵右上部分：相似度阈值：similarity_threshold**:** float <strong>=</strong> 0.95</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102244474.png\" alt=\"image-20240627102244474\"></p>\n<p>使用方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">docs = [</span><br><span class=\"line\">    Document(page_content = <span class=\"string\">&quot;粥余知识库&quot;</span>),</span><br><span class=\"line\">    Document(page_content = <span class=\"string\">&quot;粥余知识库&quot;</span>),</span><br><span class=\"line\">    Document(page_content=<span class=\"string\">&quot;同学你好！&quot;</span>),</span><br><span class=\"line\">    Document(page_content=<span class=\"string\">&quot;同学你好！&quot;</span>),</span><br><span class=\"line\">]</span><br><span class=\"line\">redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings_model)</span><br><span class=\"line\">filered_docs = redundant_filter.transform_documents(docs)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102251937.png\" alt=\"image-20240627102251937\"></p>\n<hr>\n<p>文档一条龙处理：<code>DocumentCompressorPipeline</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 文本去重</span></span><br><span class=\"line\">redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings_model)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 通过问题和文本的 语义相似度过滤</span></span><br><span class=\"line\">emb_filter = EmbeddingsFilter(embeddings=embeddings_model, similarity_threshold=<span class=\"number\">0.6</span>)</span><br><span class=\"line\"><span class=\"comment\"># 文档压缩</span></span><br><span class=\"line\">qianfan_compressor = LLMChainExtractor.from_llm(qianfan_chat)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建立管道： 过滤 + 压缩</span></span><br><span class=\"line\">pipeline_compressor = DocumentCompressorPipeline(</span><br><span class=\"line\">    transformers=[emb_filter,redundant_filter,qianfan_compressor]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建立 语境压缩 Retriever</span></span><br><span class=\"line\">compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">    base_compressor=pipeline_compressor, base_retriever=retriever</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 文档召回</span></span><br><span class=\"line\">compressed_docs = compression_retriever.get_relevant_documents(question)</span><br><span class=\"line\"> </span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>Long-Context Reorder： 多个文档→重新排序</strong></p>\n<p>相关论文<a href=\"https://arxiv.org/abs/2307.03172\">https://arxiv.org/abs/2307.03172</a></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102259819.png\" alt=\"image-20240627102259819\"></p>\n<p>调用方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 文档重排序</span></span><br><span class=\"line\">retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&quot;k&quot;</span>: <span class=\"number\">10</span>&#125;)</span><br><span class=\"line\">docs_pre = retriever.get_relevant_documents(<span class=\"string\">&#x27;Decomposition&#x27;</span>)</span><br><span class=\"line\">reordering = LongContextReorder()</span><br><span class=\"line\">reordered_docs = reordering.transform_documents(docs_pre)</span><br><span class=\"line\"></span><br><span class=\"line\">   </span><br></pre></td></tr></table></figure>\n\n<p>排序之前</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102307259.png\" alt=\"image-20240627102307259\"></p>\n<p>排序之后</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102314989.png\" alt=\"image-20240627102314989\"></p>\n<p>长文本注意事项</p>\n<p><a href=\"https://blog.langchain.dev/multi-needle-in-a-haystack/\">https://blog.langchain.dev/multi-needle-in-a-haystack/</a></p>\n<p>在长文本提示词中（甚至长达1MB），将<strong>事实</strong>放到不同的位置，召回效果不同</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102413330.png\" alt=\"image-20240627102413330\"></p>\n<p>正确的召回</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102817494.png\" alt=\"image-20240627102817494\"></p>\n<p>不完整的召回</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102902072.png\" alt=\"image-20240627102902072\"></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102922081.png\" alt=\"image-20240627102922081\"></p>\n<p>事实 处于不同的文档深度时</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-15-%E5%90%91%E9%87%8F%E8%BF%87%E6%BB%A4-VS-%E6%96%87%E6%A1%A3%E5%8E%BB%E9%87%8D.assets/image-20240627102932168.png\" alt=\"image-20240627102932168\"></p>\n<p>代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers <span class=\"keyword\">import</span> ContextualCompressionRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers.document_compressors <span class=\"keyword\">import</span> LLMChainExtractor, LLMChainFilter, EmbeddingsFilter, \\</span><br><span class=\"line\">    DocumentCompressorPipeline</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> CharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.web_base <span class=\"keyword\">import</span> WebBaseLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_transformers <span class=\"keyword\">import</span> EmbeddingsRedundantFilter, LongContextReorder</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.llms.chatglm3 <span class=\"keyword\">import</span> ChatGLM3</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> SystemMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_text_splitters <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> zhipuai <span class=\"keyword\">import</span> ZhipuAI</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Langsmith 配置，不用可注掉</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; 文档处理管道 Walkthrough - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_TRACING_V2&quot;</span>] = <span class=\"string\">&#x27;true&#x27;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">embeddings_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">    model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">    encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># # 向量数据库</span></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&quot;k&quot;</span>: <span class=\"number\">4</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">azure_chat = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">    azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 千帆 chatModel</span></span><br><span class=\"line\">qianfan_chat = QianfanChatEndpoint(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">messages = [</span><br><span class=\"line\">    SystemMessage(content=<span class=\"string\">&quot;You are an intelligent AI assistant, named ChatGLM3.&quot;</span>),</span><br><span class=\"line\">]</span><br><span class=\"line\"><span class=\"comment\"># 本地GLM3-6B模型</span></span><br><span class=\"line\">LOCAL_GLM3_6B_ENDPOINT = <span class=\"string\">&quot;http://127.0.0.1:8000/v1/chat/completions&quot;</span></span><br><span class=\"line\">local_glm3_chat = ChatGLM3(</span><br><span class=\"line\">    endpoint_url=LOCAL_GLM3_6B_ENDPOINT,</span><br><span class=\"line\">    max_tokens=(<span class=\"number\">1024</span> * <span class=\"number\">32</span>),</span><br><span class=\"line\">    prefix_messages=messages,</span><br><span class=\"line\">    top_p=<span class=\"number\">0.9</span>,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">    stream=<span class=\"literal\">True</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&quot;What is Task Decomposition ?&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 索引数据 ，一次就够，后续可以注释</span></span><br><span class=\"line\">    <span class=\"comment\"># # vectorstore.add_documents(docs)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># EmbeddingsFilter</span></span><br><span class=\"line\"></span><br><span class=\"line\">    embedding_filter_embeddings_filter = EmbeddingsFilter(embeddings=embeddings_model, similarity_threshold=<span class=\"number\">0.7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 直接过滤文档</span></span><br><span class=\"line\">    filtered_docs = embedding_filter_embeddings_filter.compress_documents(docs[:<span class=\"number\">10</span>],question)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    embedding_filter_compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=embedding_filter_embeddings_filter, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># embedding_filter_docs = embedding_filter_compression_retriever.get_relevant_documents(question)</span></span><br><span class=\"line\">    <span class=\"comment\"># pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    docs = [</span><br><span class=\"line\">        Document(page_content = <span class=\"string\">&quot;粥余知识库&quot;</span>),</span><br><span class=\"line\">        Document(page_content = <span class=\"string\">&quot;粥余知识库&quot;</span>),</span><br><span class=\"line\">        Document(page_content=<span class=\"string\">&quot;同学你好！&quot;</span>),</span><br><span class=\"line\">        Document(page_content=<span class=\"string\">&quot;同学你好！&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\">    <span class=\"comment\"># 文本去重</span></span><br><span class=\"line\">    redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings_model)</span><br><span class=\"line\">    <span class=\"comment\"># filered_docs = redundant_filter.transform_documents(docs)</span></span><br><span class=\"line\">    <span class=\"comment\"># pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 通过问题和文本的 语义相似度过滤</span></span><br><span class=\"line\">    relevant_filter = EmbeddingsFilter(embeddings=embeddings_model, similarity_threshold=<span class=\"number\">0.6</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 文档压缩</span></span><br><span class=\"line\">    qianfan_compressor = LLMChainExtractor.from_llm(qianfan_chat)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 文档快速处理</span></span><br><span class=\"line\">    pipeline_compressor = DocumentCompressorPipeline(</span><br><span class=\"line\">        transformers=[redundant_filter, relevant_filter,qianfan_compressor]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=pipeline_compressor, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># compressed_docs = compression_retriever.get_relevant_documents(question)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 重排序</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&quot;k&quot;</span>: <span class=\"number\">10</span>&#125;)</span><br><span class=\"line\">    docs_pre = retriever.get_relevant_documents(<span class=\"string\">&#x27;Decomposition&#x27;</span>)</span><br><span class=\"line\">    reordering = LongContextReorder()</span><br><span class=\"line\">    reordered_docs = reordering.transform_documents(docs_pre)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[14]文档内容提取vs内容过滤","url":"/forward/ee0ed6e3.html","content":"<p><strong>文档内容提取:LLMChainExtractor</strong></p>\n<p>在检索过程中，一个挑战是通常你不知道你的文档存储系统在数据导入时会遇到哪些具体的查询。这意味着<strong>对查询来说最相关的信息可能埋没在一个包含大量不相关文本的文档中</strong>。</p>\n<p><strong>将整个文档通过你的应用程序可能会导致更昂贵的LLM（大型语言模型）调用和更差的响应。</strong> 上下文压缩旨在解决这个问题。这个想法很简单：不是立即按原样返回检索到的文档，而是可以使用给定查询的上下文来压缩它们，以便只返回相关信息。这里的“压缩”既指压缩单个文档的内容，也指整体过滤掉文档。 要使用上下文压缩检索器，你需要：- 一个<strong>基础检索器</strong>- 一个文<strong>档压缩器</strong> 上下文压缩检索器将查询传递给基础检索器，获取初始文档并通过文档压缩器传递它们。文档压缩器接收一个文档列表，通过减少文档内容或完全删除文档来缩短列表。</p>\n<p>核心思想：<strong>对召回的文档进行关键信息提取</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110142953.png\" alt=\"image-20240627110142953\"></p>\n<p>langchain 解决办法</p>\n<p>retriever ： 向量数据库实例化的检索器</p>\n<p>compressor： 本质是一个chain, 传入一个语言模型（比如千帆）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># LLMChainExtractor</span></span><br><span class=\"line\">compressor = LLMChainExtractor.from_llm(qianfan_chat)</span><br><span class=\"line\">compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">    base_compressor=compressor, base_retriever=retriever</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>关键提示词</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n&gt; Question: &#123;question&#125;\\n&gt; Context:\\n&gt;&gt;&gt;\\n&#123;context&#125;\\n&gt;&gt;&gt;\\nExtracted relevant parts:&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;在给定的问题和上下文中，提取与回答问题相关的任何部分AS IS。如果上下文中没有任何相关部分，请返回NO_OUTPUT。请记住，不要编辑提取的上下文部分。</span></span><br><span class=\"line\"><span class=\"string\">问题：&#123;question&#125; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\">提取的相关部分：&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>调用过程：</p>\n<p>[1]检索器搜索文档 [2] 模型抽取文档内容（成功） [3] 4个文档对应4次抽取</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110156987.png\" alt=\"image-20240627110156987\"></p>\n<p>抽取失败的情况</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110205236.png\" alt=\"image-20240627110205236\"></p>\n<hr>\n<p>用本地 GLM3-6B-128K 模型实现 内容提取chain</p>\n<p>先启动你的Glm3-6B 服务端（详见Day8天内容）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 本地GLM3-6B模型</span></span><br><span class=\"line\">LOCAL_GLM3_6B_ENDPOINT = <span class=\"string\">&quot;http://127.0.0.1:8000/v1/chat/completions&quot;</span></span><br><span class=\"line\">local_glm3_chat = ChatGLM3(</span><br><span class=\"line\">    endpoint_url=LOCAL_GLM3_6B_ENDPOINT,</span><br><span class=\"line\">    max_tokens=(<span class=\"number\">1024</span> * <span class=\"number\">32</span>),</span><br><span class=\"line\">    prefix_messages=messages,</span><br><span class=\"line\">    top_p=<span class=\"number\">0.9</span>,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">    stream=<span class=\"literal\">True</span>,</span><br><span class=\"line\">)  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"><span class=\"comment\"># 随便来个文档</span></span><br><span class=\"line\">doc = docs[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">template =<span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">在给定的问题和上下文中，提取与回答问题相关的任何部分。</span></span><br><span class=\"line\"><span class=\"string\">如果上下文中没有任何相关部分，请返回NO_OUTPUT。请记住，不要编辑提取的上下文部分。</span></span><br><span class=\"line\"><span class=\"string\">问题：&#123;question&#125; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\">提取的相关部分：</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">output_parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\">chain = prompt | local_glm3_chat | output_parser</span><br><span class=\"line\"></span><br><span class=\"line\">res = chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question,<span class=\"string\">&quot;context&quot;</span>:doc.page_content&#125;)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110218193.png\" alt=\"image-20240627110218193\"></p>\n<p>用第三方 API实现提取逻辑</p>\n<p>智谱清言</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 随便来个文档</span></span><br><span class=\"line\">context = docs[<span class=\"number\">1</span>].page_content</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#zhipu ai</span></span><br><span class=\"line\">ZHIPUAI_API_KEY = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">client = ZhipuAI(api_key=ZHIPUAI_API_KEY)  <span class=\"comment\"># 填写您自己的APIKey</span></span><br><span class=\"line\"></span><br><span class=\"line\">question = <span class=\"string\">&#x27;Memory can be defined as what ?&#x27;</span></span><br><span class=\"line\">user_msg =<span class=\"string\">f&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">在给定的问题和上下文中，提取与回答问题相关的任何部分。</span></span><br><span class=\"line\"><span class=\"string\">如果上下文中没有任何相关部分，请返回NO_OUTPUT。请记住，不要编辑提取的上下文部分。</span></span><br><span class=\"line\"><span class=\"string\">问题：<span class=\"subst\">&#123;question&#125;</span> 上下文：</span></span><br><span class=\"line\"><span class=\"string\"><span class=\"subst\">&#123;context&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">提取的相关部分：</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">response = client.chat.completions.create(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">    messages=[</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你是一个文稿编辑，负责从文本中摘取内容&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: user_msg&#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message.content)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>内容过滤LLMChainFilter</p>\n<p>LLMChainFilter 是一个稍微简单但更健壮的压缩器，它使用 LLM 链来决定哪些最初检索到的文档需要被过滤掉，哪些需要返回，而不会操作文档内容。</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110234654.png\" alt=\"image-20240627110234654\"></p>\n<p>关键提示词</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">template=<span class=\"string\">&quot;Given the following question and context, return YES if the context is relevant to the question and NO if it isn&#x27;t.\\n\\n&gt; Question: &#123;question&#125;\\n&gt; Context:\\n&gt;&gt;&gt;\\n&#123;context&#125;\\n&gt;&gt;&gt;\\n&gt; Relevant (YES / NO):&quot;</span>), </span><br></pre></td></tr></table></figure>\n\n<p>使用方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># LLMChainFilter</span></span><br><span class=\"line\">doc_filter = LLMChainFilter.from_llm(qianfan_chat)</span><br><span class=\"line\">filter_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">    base_compressor=doc_filter, base_retriever=retriever</span><br><span class=\"line\">)</span><br><span class=\"line\">filtered_docs = filter_retriever.get_relevant_documents(question)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>[1] 检索起搜素，返回文档</p>\n<p>[2] 模型判断是否跟问题有相关性</p>\n<p>[3]每个文档跑一遍</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110256947.png\" alt=\"image-20240627110256947\"></p>\n<p>智谱AI 实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 得到文档</span></span><br><span class=\"line\">loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># zhipuai 支持较大的输入token 128K，大文件分割</span></span><br><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># zhipuai 初始化</span></span><br><span class=\"line\">ZHIPUAI_API_KEY = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">client = ZhipuAI(api_key=ZHIPUAI_API_KEY)  <span class=\"comment\"># 填写您自己的APIKey</span></span><br><span class=\"line\"></span><br><span class=\"line\">question = <span class=\"string\">&#x27;Memory can be defined as what ?&#x27;</span></span><br><span class=\"line\">context = docs[<span class=\"number\">0</span>].page_content</span><br><span class=\"line\">user_msg =<span class=\"string\">f&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">根据给出的问题和上下文，如果上下文与问题相关，则返回YES，如果不相关，则返回NO。</span></span><br><span class=\"line\"><span class=\"string\">&gt; 问题： <span class=\"subst\">&#123;question&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">&gt; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\"><span class=\"subst\">&#123;context&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">&gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">&gt; 相关（YES / NO）：</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">response = client.chat.completions.create(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">    messages=[</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你是一个文稿编辑，负责判断用户问题是否和文档相关&quot;</span>&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: user_msg&#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message.content)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-14-%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96vs%E5%86%85%E5%AE%B9%E8%BF%87%E6%BB%A4.assets/image-20240627110513348.png\" alt=\"image-20240627110513348\"></p>\n<p>如何在chain中添加第三方模型的过滤？</p>\n<p>检索→文档列表→第三方过滤（可扩展）→模型处理</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 第三方实现文档过滤，并应用在chain 中</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">local_filter</span>(<span class=\"params\">documents: Iterable[Document]</span>) -&gt; <span class=\"type\">List</span>[Document]:</span><br><span class=\"line\">    <span class=\"comment\"># zhipuai 初始化</span></span><br><span class=\"line\">    ZHIPUAI_API_KEY = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    client = ZhipuAI(api_key=ZHIPUAI_API_KEY)  <span class=\"comment\"># 填写您自己的APIKey</span></span><br><span class=\"line\"></span><br><span class=\"line\">    new_docs = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> documents:</span><br><span class=\"line\">        <span class=\"comment\"># 这个问题 在函数外面，每次赋值question</span></span><br><span class=\"line\">        context = doc.page_content</span><br><span class=\"line\">        user_msg = <span class=\"string\">f&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            根据给出的问题和上下文，如果上下文与问题相关，则返回YES，如果不相关，则返回NO。</span></span><br><span class=\"line\"><span class=\"string\">            &gt; 问题： <span class=\"subst\">&#123;question&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">            &gt; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">            &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">            <span class=\"subst\">&#123;context&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">            &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">            &gt; 相关（DOC_YES / DOC_NO）：</span></span><br><span class=\"line\"><span class=\"string\">            &quot;&quot;&quot;</span></span><br><span class=\"line\">        response = client.chat.completions.create(</span><br><span class=\"line\">            model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">            messages=[</span><br><span class=\"line\">                &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你是一个文稿编辑，负责判断用户问题是否和文档相关&quot;</span>&#125;,</span><br><span class=\"line\">                &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: user_msg&#125;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&#x27;DOC_YES&#x27;</span> <span class=\"keyword\">in</span> response.choices[<span class=\"number\">0</span>].message.content:</span><br><span class=\"line\">            new_docs.append(doc)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> new_docs</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 提示词</span></span><br><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: retriever | RunnableLambda(local_filter), <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | qianfan_chat</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br><span class=\"line\">res = chain.invoke(question)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>代码</p>\n<p>抽取</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers <span class=\"keyword\">import</span> ContextualCompressionRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers.document_compressors <span class=\"keyword\">import</span> LLMChainExtractor, LLMChainFilter, EmbeddingsFilter, \\</span><br><span class=\"line\">    DocumentCompressorPipeline</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> CharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.web_base <span class=\"keyword\">import</span> WebBaseLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_transformers <span class=\"keyword\">import</span> EmbeddingsRedundantFilter, LongContextReorder</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.llms.chatglm3 <span class=\"keyword\">import</span> ChatGLM3</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> SystemMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_text_splitters <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> zhipuai <span class=\"keyword\">import</span> ZhipuAI</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Langsmith 配置，不用可注掉</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [语境压缩] 内容提取 qianfan Tracing Walkthrough - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># os.environ[&quot;LANGCHAIN_TRACING_V2&quot;] = &#x27;true&#x27;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">embeddings_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">    model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">    encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># # 向量数据库</span></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&quot;k&quot;</span>: <span class=\"number\">4</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">azure_chat = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">    azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 千帆 chatModel</span></span><br><span class=\"line\">qianfan_chat = QianfanChatEndpoint(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">messages = [</span><br><span class=\"line\">    SystemMessage(content=<span class=\"string\">&quot;You are an intelligent AI assistant, named ChatGLM3.&quot;</span>),</span><br><span class=\"line\">]</span><br><span class=\"line\"><span class=\"comment\"># 本地GLM3-6B模型</span></span><br><span class=\"line\">LOCAL_GLM3_6B_ENDPOINT = <span class=\"string\">&quot;http://127.0.0.1:8000/v1/chat/completions&quot;</span></span><br><span class=\"line\">local_glm3_chat = ChatGLM3(</span><br><span class=\"line\">    endpoint_url=LOCAL_GLM3_6B_ENDPOINT,</span><br><span class=\"line\">    max_tokens=(<span class=\"number\">1024</span> * <span class=\"number\">32</span>),</span><br><span class=\"line\">    prefix_messages=messages,</span><br><span class=\"line\">    top_p=<span class=\"number\">0.9</span>,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">    stream=<span class=\"literal\">True</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&quot;What is Task Decomposition ?&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 索引数据 ，一次就够，后续可以注释</span></span><br><span class=\"line\">    <span class=\"comment\"># # vectorstore.add_documents(docs)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># LLMChainExtractor</span></span><br><span class=\"line\">    compressor = LLMChainExtractor.from_llm(qianfan_chat)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 压缩文档集合</span></span><br><span class=\"line\">    compressed_docs = compressor.compress_documents(docs[:<span class=\"number\">1</span>],question)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 直接给出压缩之后的 检索器</span></span><br><span class=\"line\">    compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=compressor, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    compressed_docs = compression_retriever.get_relevant_documents(question)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 内容压缩chain： 本地 Glm3-6B 128K</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\">    <span class=\"comment\"># 随便来个文档</span></span><br><span class=\"line\">    doc = docs[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    template =<span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    在给定的问题和上下文中，提取与回答问题相关的任何部分。</span></span><br><span class=\"line\"><span class=\"string\">    如果上下文中没有任何相关部分，请返回NO_OUTPUT。请记住，不要编辑提取的上下文部分。</span></span><br><span class=\"line\"><span class=\"string\">    问题：&#123;question&#125; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">    &#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\">    提取的相关部分：</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">    output_parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\">    chain = prompt | local_glm3_chat | output_parser</span><br><span class=\"line\"></span><br><span class=\"line\">    res = chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: question,<span class=\"string\">&quot;context&quot;</span>:doc.page_content&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 用第三方的API 实现</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\">    <span class=\"comment\"># 随便来个文档</span></span><br><span class=\"line\">    context = docs[<span class=\"number\">1</span>].page_content</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#zhipu ai</span></span><br><span class=\"line\">    ZHIPUAI_API_KEY = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    client = ZhipuAI(api_key=ZHIPUAI_API_KEY)  <span class=\"comment\"># 填写您自己的APIKey</span></span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&#x27;Memory can be defined as what ?&#x27;</span></span><br><span class=\"line\">    user_msg =<span class=\"string\">f&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    在给定的问题和上下文中，提取与回答问题相关的任何部分。</span></span><br><span class=\"line\"><span class=\"string\">    如果上下文中没有任何相关部分，请返回NO_OUTPUT。请记住，不要编辑提取的上下文部分。</span></span><br><span class=\"line\"><span class=\"string\">    问题：<span class=\"subst\">&#123;question&#125;</span> 上下文：</span></span><br><span class=\"line\"><span class=\"string\">    <span class=\"subst\">&#123;context&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">    提取的相关部分：</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    response = client.chat.completions.create(</span><br><span class=\"line\">        model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">        messages=[</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你是一个文稿编辑，负责从文本中摘取内容&quot;</span>&#125;,</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: user_msg&#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message.content)</span><br></pre></td></tr></table></figure>\n\n<p>过滤</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers <span class=\"keyword\">import</span> ContextualCompressionRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers.document_compressors <span class=\"keyword\">import</span> LLMChainExtractor, LLMChainFilter, EmbeddingsFilter, \\</span><br><span class=\"line\">    DocumentCompressorPipeline</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> CharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders.web_base <span class=\"keyword\">import</span> WebBaseLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_transformers <span class=\"keyword\">import</span> EmbeddingsRedundantFilter, LongContextReorder</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough, RunnableLambda</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_text_splitters <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> zhipuai <span class=\"keyword\">import</span> ZhipuAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> (</span><br><span class=\"line\">    AbstractSet,</span><br><span class=\"line\">    <span class=\"type\">Any</span>,</span><br><span class=\"line\">    <span class=\"type\">Callable</span>,</span><br><span class=\"line\">    Collection,</span><br><span class=\"line\">    Iterable,</span><br><span class=\"line\">    <span class=\"type\">List</span>,</span><br><span class=\"line\">    <span class=\"type\">Literal</span>,</span><br><span class=\"line\">    <span class=\"type\">Optional</span>,</span><br><span class=\"line\">    <span class=\"type\">Sequence</span>,</span><br><span class=\"line\">    <span class=\"type\">Type</span>,</span><br><span class=\"line\">    TypeVar,</span><br><span class=\"line\">    <span class=\"type\">Union</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Langsmith 配置，不用可注掉</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [语境压缩] 内容过滤 qianfan Tracing Walkthrough - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># os.environ[&quot;LANGCHAIN_TRACING_V2&quot;] = &#x27;true&#x27;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 本地 BGE 模型</span></span><br><span class=\"line\">bge_en_v1p5_model_path = <span class=\"string\">&quot;D:\\\\LLM\\\\Bge_models\\\\bge-base-en-v1.5&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">embeddings_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=bge_en_v1p5_model_path,</span><br><span class=\"line\">    model_kwargs=&#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;,</span><br><span class=\"line\">    encode_kwargs=&#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># # 向量数据库</span></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&quot;k&quot;</span>: <span class=\"number\">4</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">azure_chat = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">    azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 千帆 chatModel</span></span><br><span class=\"line\">qianfan_chat = QianfanChatEndpoint(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&quot;What is Task Decomposition ?&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 解析并载入url</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 索引数据</span></span><br><span class=\"line\">    vectorstore.add_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    LLMChainFilter</span><br><span class=\"line\">    doc_filter = LLMChainFilter.from_llm(qianfan_chat)</span><br><span class=\"line\">    filter_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=doc_filter, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\">    filtered_docs = filter_retriever.get_relevant_documents(question)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 第三方实现</span></span><br><span class=\"line\">    loader = WebBaseLoader(<span class=\"string\">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># zhipuai 支持较大的输入token 128K，大文件分割</span></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">10000</span>)</span><br><span class=\"line\">    docs = text_splitter.split_documents(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># zhipuai 初始化</span></span><br><span class=\"line\">    ZHIPUAI_API_KEY = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    client = ZhipuAI(api_key=ZHIPUAI_API_KEY)  <span class=\"comment\"># 填写您自己的APIKey</span></span><br><span class=\"line\"></span><br><span class=\"line\">    question = <span class=\"string\">&#x27;Memory can be defined as what ?&#x27;</span></span><br><span class=\"line\">    context = docs[<span class=\"number\">0</span>].page_content</span><br><span class=\"line\">    user_msg =<span class=\"string\">f&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    根据给出的问题和上下文，如果上下文与问题相关，则返回YES，如果不相关，则返回NO。</span></span><br><span class=\"line\"><span class=\"string\">    &gt; 问题： <span class=\"subst\">&#123;question&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">    &gt; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">    &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">    <span class=\"subst\">&#123;context&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">    &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">    &gt; 相关（YES / NO）：</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    response = client.chat.completions.create(</span><br><span class=\"line\">        model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">        messages=[</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你是一个文稿编辑，负责判断用户问题是否和文档相关&quot;</span>&#125;,</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: user_msg&#125;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.choices[<span class=\"number\">0</span>].message.content)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 第三方实现文档过滤，并应用在chain 中</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">local_filter</span>(<span class=\"params\">documents: Iterable[Document]</span>) -&gt; <span class=\"type\">List</span>[Document]:</span><br><span class=\"line\">        <span class=\"comment\"># zhipuai 初始化</span></span><br><span class=\"line\">        ZHIPUAI_API_KEY = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">        client = ZhipuAI(api_key=ZHIPUAI_API_KEY)  <span class=\"comment\"># 填写您自己的APIKey</span></span><br><span class=\"line\"></span><br><span class=\"line\">        new_docs = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> documents:</span><br><span class=\"line\">            <span class=\"comment\"># 这个问题 在函数外面，每次赋值question</span></span><br><span class=\"line\">            context = doc.page_content</span><br><span class=\"line\">            user_msg = <span class=\"string\">f&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">                根据给出的问题和上下文，如果上下文与问题相关，则返回YES，如果不相关，则返回NO。</span></span><br><span class=\"line\"><span class=\"string\">                &gt; 问题： <span class=\"subst\">&#123;question&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">                &gt; 上下文：</span></span><br><span class=\"line\"><span class=\"string\">                &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">                <span class=\"subst\">&#123;context&#125;</span></span></span><br><span class=\"line\"><span class=\"string\">                &gt;&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">                &gt; 相关（DOC_YES / DOC_NO）：</span></span><br><span class=\"line\"><span class=\"string\">                &quot;&quot;&quot;</span></span><br><span class=\"line\">            response = client.chat.completions.create(</span><br><span class=\"line\">                model=<span class=\"string\">&quot;glm-4&quot;</span>,  <span class=\"comment\"># 填写需要调用的模型名称</span></span><br><span class=\"line\">                messages=[</span><br><span class=\"line\">                    &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;system&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;你是一个文稿编辑，负责判断用户问题是否和文档相关&quot;</span>&#125;,</span><br><span class=\"line\">                    &#123;<span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>, <span class=\"string\">&quot;content&quot;</span>: user_msg&#125;</span><br><span class=\"line\">                ],</span><br><span class=\"line\">            )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"string\">&#x27;DOC_YES&#x27;</span> <span class=\"keyword\">in</span> response.choices[<span class=\"number\">0</span>].message.content:</span><br><span class=\"line\">                new_docs.append(doc)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> new_docs</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词</span></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class=\"line\"><span class=\"string\">    &#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;context&quot;</span>: retriever | RunnableLambda(local_filter), <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | qianfan_chat</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\">    res = chain.invoke(question)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>"},{"title":"Langchain系列[16]下载和使用Rerank模型","url":"/forward/b8db8981.html","content":"<p><strong>Rerank</strong></p>\n<p>即重新排序，是信息检索、推荐系统、自然语言处理和机器学习领域中的一种常见技术。它的目的是提高搜索结果、推荐列表或生成内容的相关性，使其更符合用户的需求或期望。</p>\n<p>在RAG里，我们主要利用Rerank 模型来对初步检索出的文档（比如通过BM25或者向量检索召回的文档）进行<strong>重排序</strong>和<strong>过滤</strong>。</p>\n<hr>\n<p>支持一种语言的嵌入模型</p>\n<ul>\n<li>英语 bge-large-en</li>\n<li>中文 bge-large-zh</li>\n</ul>\n<p>支持<strong>双语</strong>的嵌入模型</p>\n<ul>\n<li><strong>网易有道 BCEmbedding</strong></li>\n</ul>\n<hr>\n<p><strong>网易有道 BCEmbedding</strong></p>\n<p><strong>优势</strong></p>\n<ul>\n<li><strong>双语和跨语种能力</strong>：基于有道翻译引擎的强大能力，<code>BCEmbedding</code>实现强大的中英双语和跨语种语义表征能力。</li>\n<li><strong>RAG适配</strong>：面向RAG做针对性优化，可适配大多数相关任务，比如<strong>翻译，摘要，问答</strong>等。此外，针对 <strong>问题理解（query understanding）</strong> 也做了针对优化</li>\n<li><strong>高效且精确的语义检索</strong>：<code>EmbeddingModel</code>采用双编码器，可以在第一阶段实现高效的语义检索。<code>RerankerModel</code>采用交叉编码器，可以在第二阶段实现更高精度的语义顺序精排。</li>\n<li><strong>更好的领域泛化性</strong>：为了在更多场景实现更好的效果，我们收集了多种多样的领域数据。</li>\n<li><strong>用户友好</strong>：语义检索时不需要特殊指令前缀。也就是，你不需要为各种任务绞尽脑汁设计指令前缀。</li>\n<li><strong>有意义的重排序分数</strong>：<code>RerankerModel</code>可以提供有意义的语义相关性分数（不仅仅是排序），可以用于过滤无意义文本片段，提高大模型生成效果。</li>\n<li><strong>产品化检验</strong>：<code>BCEmbedding</code>已经被有道众多产品检验。</li>\n</ul>\n<hr>\n<p><strong>模型列表</strong></p>\n<p><a href=\"https://github.com/netease-youdao/BCEmbedding/blob/master/README_zh.md#-%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8\">https://github.com/netease-youdao/BCEmbedding/blob/master/README_zh.md#-%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8</a></p>\n<table>\n<thead>\n<tr>\n<th>模型名称</th>\n<th>模型类型</th>\n<th>支持语种</th>\n<th>参数量</th>\n<th>开源权重</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>bce-embedding-base_v1</td>\n<td><code>EmbeddingModel</code></td>\n<td>中英</td>\n<td>279M</td>\n<td><a href=\"https://huggingface.co/maidalun1020/bce-embedding-base_v1\">Huggingface(推荐)</a>, <a href=\"https://hf-mirror.com/maidalun1020/bce-embedding-base_v1\">国内通道</a>, <a href=\"https://www.modelscope.cn/models/maidalun/bce-embedding-base_v1/summary\">ModelScope</a>, <a href=\"https://wisemodel.cn/models/Netease_Youdao/bce-embedding-base_v1\">WiseModel</a></td>\n</tr>\n<tr>\n<td>bce-reranker-base_v1</td>\n<td><code>RerankerModel</code></td>\n<td>中英日韩</td>\n<td>279M</td>\n<td><a href=\"https://huggingface.co/maidalun1020/bce-reranker-base_v1\">Huggingface(推荐)</a>, <a href=\"https://hf-mirror.com/maidalun1020/bce-reranker-base_v1\">国内通道</a>, <a href=\"https://www.modelscope.cn/models/maidalun/bce-reranker-base_v1/summary\">ModelScope</a>, <a href=\"https://wisemodel.cn/models/Netease_Youdao/bce-reranker-base_v1\">WiseModel</a></td>\n</tr>\n</tbody></table>\n<p><strong>模型下载</strong></p>\n<p>嵌入模型：<a href=\"https://www.modelscope.cn/models/maidalun/bce-embedding-base_v1/files\">https://www.modelscope.cn/models/maidalun/bce-embedding-base_v1/files</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone https://www.modelscope.cn/maidalun/bce-embedding-base_v1.git</span><br></pre></td></tr></table></figure>\n\n<p>Rerank 模型：<a href=\"https://www.modelscope.cn/models/maidalun/bce-reranker-base_v1/summary\">https://www.modelscope.cn/models/maidalun/bce-reranker-base_v1/summary</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone https://www.modelscope.cn/maidalun/bce-reranker-base_v1.git</span><br></pre></td></tr></table></figure>\n\n<p><strong>模型性能：</strong></p>\n<p><img src=\"%5BVol%5D%5B16%5D%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%BD%BF%E7%94%A8Rerank%E6%A8%A1%E5%9E%8B.assets/image-20240627102045642.png\" alt=\"image-20240627102045642\"></p>\n<p>关键参数</p>\n<ul>\n<li><code>RerankerModel</code>支持 <strong>长 passage（超过512 tokens，不超过32k tokens）rerank</strong>；</li>\n<li><code>RerankerModel</code>可以给出有意义 <strong>相关性分数</strong> （<strong>区别于cosine分数</strong>），帮助 <strong>过滤低质量召回</strong>；</li>\n<li><code>EmbeddingModel</code> 768 维度</li>\n</ul>\n<hr>\n<p>安装 BCEmbedding</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">pip install BCEmbedding</span><br></pre></td></tr></table></figure>\n\n<p><strong>理解Rerank 和 cosine 语义相似 的不同</strong></p>\n<p>问题：你最喜欢的电影是什么？ 和下面这些回答的cosine语义相似度</p>\n<p><strong>bce-embedding-base_v1  和 bge_large_zh 结果一致</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[<span class=\"number\">1</span>] 我最喜欢的电影是《阿甘正传》。        Score:<span class=\"number\">0.6105921907574262</span></span><br><span class=\"line\">[<span class=\"number\">2</span>] 我最喜欢的电影类型是恐怖片。          Score:<span class=\"number\">0.5381861816884799</span></span><br><span class=\"line\">[<span class=\"number\">3</span>] 我最喜欢的电影导演是斯皮尔伯格。       Score:<span class=\"number\">0.4905046919817628</span></span><br><span class=\"line\">[<span class=\"number\">4</span>] 我最喜欢的书是《哈利波特》。          Score:<span class=\"number\">0.4652198126696215</span></span><br><span class=\"line\">[<span class=\"number\">5</span>] 我不喜欢看电影。                     Score:<span class=\"number\">0.44154025662995605</span></span><br><span class=\"line\">[<span class=\"number\">6</span>] 我喜欢看科幻电影，尤其是《星际穿越》。 Score:<span class=\"number\">0.4249389530579074</span></span><br><span class=\"line\">[<span class=\"number\">7</span>] 我最喜欢的音乐是爵士乐。               Score:<span class=\"number\">0.39165986473334957</span></span><br><span class=\"line\">[<span class=\"number\">8</span>] 昨天晚上我看了一部很好的电影。         Score:<span class=\"number\">0.35591581297344105</span></span><br><span class=\"line\">[<span class=\"number\">9</span>] 我最喜欢的运动是篮球。                 Score:<span class=\"number\">0.3554765233404198</span></span><br><span class=\"line\">[<span class=\"number\">10</span>] 我喜欢吃披萨。                       Score:<span class=\"number\">0.34989368275228544</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>经过re-rank，效果非常明显！</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">我最喜欢的电影是《阿甘正传》。 [<span class=\"number\">1</span>]</span><br><span class=\"line\">我最喜欢的电影类型是恐怖片 [<span class=\"number\">2</span>]</span><br><span class=\"line\">我喜欢看科幻电影，尤其是《星际穿越》。 [<span class=\"number\">6</span>]</span><br><span class=\"line\">我最喜欢的电影导演是斯皮尔伯格。 [<span class=\"number\">3</span>]</span><br><span class=\"line\">昨天晚上我看了一部很好的电影。 [<span class=\"number\">8</span>]</span><br><span class=\"line\">我最喜欢的书是《哈利波特》。 [<span class=\"number\">4</span>]</span><br><span class=\"line\">我不喜欢看电影。 [<span class=\"number\">5</span>]</span><br><span class=\"line\">我最喜欢的音乐是爵士乐。 [<span class=\"number\">7</span>]</span><br><span class=\"line\">我喜欢吃披萨。 [<span class=\"number\">10</span>]</span><br><span class=\"line\">我最喜欢的运动是篮球。 [<span class=\"number\">9</span>]</span><br></pre></td></tr></table></figure>\n\n<p>嵌入模型使用方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 初始化本地的 embedding 模块</span></span><br><span class=\"line\">embedding_model_name = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-embedding-base_v1&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># 使用 GPU</span></span><br><span class=\"line\"><span class=\"comment\"># embedding_model_kwargs = &#123;&#x27;device&#x27;: &#x27;cuda:0&#x27;&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用 CPU</span></span><br><span class=\"line\">embedding_model_kwargs = &#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cpu&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">embedding_encode_kwargs = &#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化</span></span><br><span class=\"line\">embed_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=embedding_model_name,</span><br><span class=\"line\">    model_kwargs=embedding_model_kwargs,</span><br><span class=\"line\">    encode_kwargs=embedding_encode_kwargs</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 小测试</span></span><br><span class=\"line\">query = <span class=\"string\">&#x27;你好呀兄弟！&#x27;</span></span><br><span class=\"line\">passages = [<span class=\"string\">&#x27;天真热&#x27;</span>, <span class=\"string\">&#x27;嗯呢&#x27;</span>]</span><br><span class=\"line\">query_embedding = embed_model.embed_query(query)</span><br><span class=\"line\">passages_embeddings = embed_model.embed_documents(passages)</span><br></pre></td></tr></table></figure>\n\n<p>Rerank 模型使用方法</p>\n<p>非langchain 方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">query = <span class=\"string\">&#x27;你最喜欢的电影是什么？&#x27;</span></span><br><span class=\"line\">passages = [</span><br><span class=\"line\">    <span class=\"string\">&#x27;我最喜欢的电影是《阿甘正传》。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我最喜欢的电影类型是恐怖片&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我最喜欢的电影导演是斯皮尔伯格。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我最喜欢的书是《哈利波特》。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我不喜欢看电影。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我喜欢看科幻电影，尤其是《星际穿越》。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我最喜欢的音乐是爵士乐。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;昨天晚上我看了一部很好的电影。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我最喜欢的运动是篮球。&#x27;</span>,</span><br><span class=\"line\">    <span class=\"string\">&#x27;我喜欢吃披萨。&#x27;</span></span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># construct sentence pairs</span></span><br><span class=\"line\">sentence_pairs = [[query, passage] <span class=\"keyword\">for</span> passage <span class=\"keyword\">in</span> passages]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># rerank 模型所在目录</span></span><br><span class=\"line\">reranker_model = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-reranker-base_v1&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化</span></span><br><span class=\"line\">model = RerankerModel(model_name_or_path=reranker_model)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 得到模型评估的分数</span></span><br><span class=\"line\">scores = model.compute_score(sentence_pairs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># rerank 过滤</span></span><br><span class=\"line\">rerank_results = model.rerank(query, passages)</span><br><span class=\"line\">doc_list = rerank_results[<span class=\"string\">&#x27;rerank_passages&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> doc_list:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(line)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>langchain 调用方法： 可以作为compressor直接传给ContextualCompressionRetriever</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 定义 reranker</span></span><br><span class=\"line\">reranker_args = &#123;<span class=\"string\">&#x27;model&#x27;</span>: <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-reranker-base_v1&#x27;</span>, <span class=\"string\">&#x27;top_n&#x27;</span>: <span class=\"number\">10</span>, <span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class=\"line\">reranker = BCERerank(**reranker_args)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成一个langchain 的语境压缩检索器</span></span><br><span class=\"line\">compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">    base_compressor=reranker, base_retriever=retriever</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 搜索</span></span><br><span class=\"line\">docs = compression_retriever.get_relevant_documents(<span class=\"string\">&#x27;你最喜欢的电影是什么?&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ------- 一条龙处理 </span></span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"comment\"># 文档分割器</span></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 向量过滤</span></span><br><span class=\"line\">    embedding_filter = EmbeddingsFilter(embeddings=embed_model, similarity_threshold=<span class=\"number\">0.6</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 文档去重</span></span><br><span class=\"line\">    redundant_filter = EmbeddingsRedundantFilter(embeddings=embed_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 内容抽取</span></span><br><span class=\"line\">    llm_extractor = LLMChainExtractor.from_llm(qianfan_chat)</span><br><span class=\"line\"></span><br><span class=\"line\">    pipeline_compressor = DocumentCompressorPipeline(</span><br><span class=\"line\">        transformers=[text_splitter, embedding_filter, redundant_filter, reranker, llm_extractor]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    pipeline_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=pipeline_compressor, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\">    docs = pipeline_retriever.get_relevant_documents(query)</span><br></pre></td></tr></table></figure>\n\n<p>召回了20个文档，经过 <strong>分割</strong>、<strong>向量过滤</strong>、<strong>文档去重</strong>、<strong>rerank</strong>，只有3个文档到了 <strong>信息抽取</strong> 环节</p>\n<p><img src=\"%5BVol%5D%5B16%5D%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%BD%BF%E7%94%A8Rerank%E6%A8%A1%E5%9E%8B.assets/image-20240627102059130.png\" alt=\"image-20240627102059130\"></p>\n<p>相关代码</p>\n<ul>\n<li>测试数据放到数据库</li>\n<li>langchain中rerank 查询</li>\n<li>非langchain 调用方法</li>\n</ul>\n<hr>\n<p>测试数据放到数据库</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> TextLoader, DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cosine_similarity</span>(<span class=\"params\">vec1, vec2</span>):</span><br><span class=\"line\">    dot_product = np.dot(vec1, vec2)</span><br><span class=\"line\">    norm_vec1 = np.linalg.norm(vec1)</span><br><span class=\"line\">    norm_vec2 = np.linalg.norm(vec2)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dot_product / (norm_vec1 * norm_vec2)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用本地网易有道模型  BCE</span></span><br><span class=\"line\">    embedding_model_name = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-embedding-base_v1&#x27;</span></span><br><span class=\"line\">    embedding_model_kwargs = &#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class=\"line\">    embedding_encode_kwargs = &#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    embed_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=embedding_model_name,</span><br><span class=\"line\">        model_kwargs=embedding_model_kwargs,</span><br><span class=\"line\">        encode_kwargs=embedding_encode_kwargs</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    doc_list = [</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的电影是《阿甘正传》。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的电影类型是恐怖片&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的电影导演是斯皮尔伯格。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的书是《哈利波特》。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我不喜欢看电影。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我喜欢看科幻电影，尤其是《星际穿越》。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的音乐是爵士乐。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;昨天晚上我看了一部很好的电影。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的运动是篮球。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我喜欢吃披萨。&#x27;</span></span><br><span class=\"line\">    ]</span><br><span class=\"line\">    docs = []</span><br><span class=\"line\">    index =<span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> doc_list:</span><br><span class=\"line\">        tmp_doc = Document(page_content=line)</span><br><span class=\"line\">        tmp_doc.metadata[<span class=\"string\">&#x27;num&#x27;</span>] = index</span><br><span class=\"line\">        index += <span class=\"number\">1</span></span><br><span class=\"line\">        docs.append(tmp_doc)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_ex_768_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embed_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># 将本文加入数据库（注意，只需要运行一次；多次运行会有冗余数据）</span></span><br><span class=\"line\">    vectorstore.add_documents(docs)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Done!&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>langchain中rerank 查询</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers <span class=\"keyword\">import</span> ContextualCompressionRetriever</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.retrievers.document_compressors <span class=\"keyword\">import</span> DocumentCompressorPipeline, EmbeddingsFilter, LLMChainExtractor</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> TextLoader, DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_transformers <span class=\"keyword\">import</span> EmbeddingsRedundantFilter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"><span class=\"keyword\">from</span> BCEmbedding.tools.langchain <span class=\"keyword\">import</span> BCERerank</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 千帆 chatModel</span></span><br><span class=\"line\">qianfan_chat = QianfanChatEndpoint(</span><br><span class=\"line\">    model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Langsmith 配置，不用可注掉</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; [一条龙] qianfan Tracing Walkthrough - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># os.environ[&quot;LANGCHAIN_TRACING_V2&quot;] = &#x27;true&#x27;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用本地网易有道模型  BCE， 使用CPU</span></span><br><span class=\"line\">    embedding_model_name = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-embedding-base_v1&#x27;</span></span><br><span class=\"line\">    embedding_model_kwargs = &#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cpu&#x27;</span>&#125;</span><br><span class=\"line\">    embedding_encode_kwargs = &#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    embed_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">        model_name=embedding_model_name,</span><br><span class=\"line\">        model_kwargs=embedding_model_kwargs,</span><br><span class=\"line\">        encode_kwargs=embedding_encode_kwargs</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_ex_768_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embed_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&quot;k&quot;</span>: <span class=\"number\">20</span>&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    query = <span class=\"string\">&#x27;粥余知识库&#x27;</span></span><br><span class=\"line\">    <span class=\"comment\"># 使用GPU</span></span><br><span class=\"line\">    reranker_args = &#123;<span class=\"string\">&#x27;model&#x27;</span>: <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-reranker-base_v1&#x27;</span>, <span class=\"string\">&#x27;top_n&#x27;</span>: <span class=\"number\">10</span>, <span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class=\"line\">    reranker = BCERerank(**reranker_args)</span><br><span class=\"line\"></span><br><span class=\"line\">    compression_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=reranker, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># rerank 过滤文档</span></span><br><span class=\"line\">    <span class=\"comment\"># docs = compression_retriever.get_relevant_documents(query)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 文档分割器</span></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class=\"number\">400</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 向量过滤</span></span><br><span class=\"line\">    embedding_filter = EmbeddingsFilter(embeddings=embed_model, similarity_threshold=<span class=\"number\">0.6</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 文档去重</span></span><br><span class=\"line\">    redundant_filter = EmbeddingsRedundantFilter(embeddings=embed_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 内容抽取</span></span><br><span class=\"line\">    llm_extractor = LLMChainExtractor.from_llm(qianfan_chat)</span><br><span class=\"line\"></span><br><span class=\"line\">    pipeline_compressor = DocumentCompressorPipeline(</span><br><span class=\"line\">        transformers=[text_splitter, embedding_filter, redundant_filter, reranker, llm_extractor]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    pipeline_retriever = ContextualCompressionRetriever(</span><br><span class=\"line\">        base_compressor=pipeline_compressor, base_retriever=retriever</span><br><span class=\"line\">    )</span><br><span class=\"line\">    docs = pipeline_retriever.get_relevant_documents(query)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>非langchain 调用方法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> BCEmbedding <span class=\"keyword\">import</span> RerankerModel, EmbeddingModel</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试嵌入模块</span></span><br><span class=\"line\">    embedding_model_name = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-embedding-base_v1&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># list of sentences</span></span><br><span class=\"line\">    sentences = [<span class=\"string\">&#x27;哈喽啊兄弟&#x27;</span>, <span class=\"string\">&#x27;明天去上学了&#x27;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># init embedding model</span></span><br><span class=\"line\">    model = EmbeddingModel(model_name_or_path=embedding_model_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># extract embeddings</span></span><br><span class=\"line\">    <span class=\"comment\"># embeddings = model.encode(sentences)</span></span><br><span class=\"line\">    <span class=\"comment\"># pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># your query and corresponding passages</span></span><br><span class=\"line\">    query = <span class=\"string\">&#x27;你最喜欢的电影是什么？&#x27;</span></span><br><span class=\"line\">    passages = [</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的电影是《阿甘正传》。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的电影类型是恐怖片&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的电影导演是斯皮尔伯格。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的书是《哈利波特》。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我不喜欢看电影。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我喜欢看科幻电影，尤其是《星际穿越》。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的音乐是爵士乐。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;昨天晚上我看了一部很好的电影。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我最喜欢的运动是篮球。&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;我喜欢吃披萨。&#x27;</span></span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># construct sentence pairs</span></span><br><span class=\"line\">    sentence_pairs = [[query, passage] <span class=\"keyword\">for</span> passage <span class=\"keyword\">in</span> passages]</span><br><span class=\"line\">    reranker_model = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-reranker-base_v1&#x27;</span></span><br><span class=\"line\">    <span class=\"comment\"># init reranker model</span></span><br><span class=\"line\">    model = RerankerModel(model_name_or_path=reranker_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># method 0: calculate scores of sentence pairs</span></span><br><span class=\"line\">    scores = model.compute_score(sentence_pairs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># method 1: rerank passages</span></span><br><span class=\"line\">    rerank_results = model.rerank(query, passages)</span><br><span class=\"line\">    doc_list = rerank_results[<span class=\"string\">&#x27;rerank_passages&#x27;</span>]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> doc_list:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(line)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>其实如果要达到一个好的效果，还是需要根据使用场景去选择适合的ReRank和embedding</strong></p>\n","tags":["langchain"]},{"title":"Langchain系列[17]基于用户的搜索 + 添加引文信息","url":"/forward/90a12009.html","content":"<h3 id=\"注意本文只是一个思路，实际上常规业务场景并不会采用这个方案。\"><a href=\"#注意本文只是一个思路，实际上常规业务场景并不会采用这个方案。\" class=\"headerlink\" title=\"注意本文只是一个思路，实际上常规业务场景并不会采用这个方案。\"></a>注意本文只是一个思路，实际上常规业务场景并不会采用这个方案。</h3><p><strong>基于用户的搜索</strong></p>\n<p>当构建一个检索应用时，你通常需要<strong>考虑</strong>到<strong>多个用户</strong>。</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-17-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2-%E6%B7%BB%E5%8A%A0%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF.assets/image-20240627101842908.png\" alt=\"image-20240627101842908\"></p>\n<p><strong>目前，LangChain 中没有统一的标志或过滤器来实现这一点。相反，每个向量存储和检索器可能都有自己的实现，并且可能被称为不同的事物。</strong> 对于向量存储来说，<strong>这通常作为一个关键字参数在</strong> <code>similarity_search</code> 过程中传递。通过阅读文档或源代码，弄清楚你使用的检索器是否支持多个用户，如果支持，如何使用它。这意味着你可能不仅仅是为一个用户存储数据，而是为许多不同的用户存储数据，<strong>他们不应该能够看到彼此的数据</strong>。</p>\n<p>实现步骤：</p>\n<p><strong>第一步：确保你使用的检索器支持多个用户 （自己设计数据存储结构）</strong></p>\n<p><strong>第二步：将该参数作为一个可配置字段添加到链中（当作参数传递）</strong></p>\n<p><strong>第三步：使用该可配置字段调用链（调用时，区分用户）</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">比如ElasticSearch 在相似度搜索时，可以添加过滤参数</span><br><span class=\"line\">    docs = vectorstore.similarity_search(</span><br><span class=\"line\">        query_text, <span class=\"built_in\">filter</span>=[&#123;<span class=\"string\">&quot;term&quot;</span>: &#123;<span class=\"string\">&quot;metadata.author.keyword&quot;</span>: <span class=\"string\">&quot;userid_002&quot;</span>&#125;&#125;]</span><br><span class=\"line\">    )</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"在添加数据时，增加metadata信息\"><a href=\"#在添加数据时，增加metadata信息\" class=\"headerlink\" title=\"在添加数据时，增加metadata信息\"></a>在添加数据时，增加metadata信息</h1><p>巴菲特与索罗斯21个投资秘籍.txt 是docs[0]，作者 <strong>userid_001</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-17-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2-%E6%B7%BB%E5%8A%A0%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF.assets/image-20240627101907273.png\" alt=\"image-20240627101907273\"></p>\n<p>维特根斯坦读本.txt 是docs[1]，作者 <strong>userid_022</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">doc_list = []</span><br><span class=\"line\">owner_one_doc = docs[<span class=\"number\">0</span>]</span><br><span class=\"line\">owner_one_docs = text_splitter.create_documents([owner_one_doc.page_content])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加入metadata 信息，作者信息 userid_001</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(owner_one_docs):</span><br><span class=\"line\">    doc.metadata[<span class=\"string\">&quot;author&quot;</span>] = [<span class=\"string\">&quot;userid_001&quot;</span>]</span><br><span class=\"line\">    doc_list.append(doc)</span><br><span class=\"line\"></span><br><span class=\"line\">owner_two_doc = docs[<span class=\"number\">1</span>]</span><br><span class=\"line\">owner_two_docs = text_splitter.create_documents([owner_two_doc.page_content])</span><br><span class=\"line\"><span class=\"comment\"># 加入metadata 信息，作者信息 userid_022</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(owner_two_docs):</span><br><span class=\"line\">    doc.metadata[<span class=\"string\">&quot;author&quot;</span>] = [<span class=\"string\">&quot;userid_022&quot;</span>]</span><br><span class=\"line\">    doc_list.append(doc)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-17-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2-%E6%B7%BB%E5%8A%A0%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF.assets/image-20240627101924823.png\" alt=\"image-20240627101924823\"></p>\n<p>生成过滤特定用户的检索器</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 你需要搜索谁的数据？</span></span><br><span class=\"line\">user_id= <span class=\"string\">&quot;userid_001&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># user_id = &quot;userid_002&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基于user_id， 定义你的过滤器</span></span><br><span class=\"line\">filter_criteria = [&#123;<span class=\"string\">&quot;term&quot;</span>: &#123;<span class=\"string\">&quot;metadata.author.keyword&quot;</span>: user_id&#125;&#125;]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成只过滤user_id的检索器</span></span><br><span class=\"line\">special_retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&#x27;filter&#x27;</span>: filter_criteria&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>测试你的效果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 测试检索器效果，应该只能搜到metadata.author.keyword 为 user_id 的文档</span></span><br><span class=\"line\"> test_chain = RunnableParallel(</span><br><span class=\"line\">     &#123;<span class=\"string\">&quot;context&quot;</span>: special_retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\"> )</span><br><span class=\"line\">test_docs = test_chain.invoke(<span class=\"string\">&quot;谁在2007年荣登“世界首富”的宝座，成了财富和成功的象征？&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>建立问答chain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;使用下面的资料中的内容回答问题，如果没有资料，就回答：资料不全，无法回答您的问题。</span></span><br><span class=\"line\"><span class=\"string\">参考资料：</span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">用户问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">你的回答:&quot;&quot;&quot;</span></span><br><span class=\"line\">custom_rag_prompt = PromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">chat = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将文档连接成字符串</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 你需要搜索谁的数据？</span></span><br><span class=\"line\">user_id= <span class=\"string\">&quot;userid_001&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># user_id = &quot;userid_002&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基于user_id， 定义你的过滤器</span></span><br><span class=\"line\">filter_criteria = [&#123;<span class=\"string\">&quot;term&quot;</span>: &#123;<span class=\"string\">&quot;metadata.author.keyword&quot;</span>: user_id&#125;&#125;]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成只过滤user_id的检索器</span></span><br><span class=\"line\">special_retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&#x27;filter&#x27;</span>: filter_criteria&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义RAG chain</span></span><br><span class=\"line\">rag_chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: special_retriever | format_docs, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | custom_rag_prompt</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p><strong>在userid_001 的文档中，有下面一段话</strong></p>\n<p>但<strong>巴菲特</strong>却从来不被技术分析师的预测所左右，他从不相信所谓的“权威分析”。不仅如此，就连他的老师格雷厄姆的投资理论他都不迷信。</p>\n<p>我的问题：<strong>谁从来不被技术分析师的预测所左右？</strong></p>\n<p>上面的问题是有语境的，只有context里有这句话，才能正确回答。</p>\n<p><strong>当我用user_id= “userid_001” 时</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">巴菲特从来不被技术分析师的预测所左右。他通常不会花时间去阅读证券公司的报告或听取技术分析师的预测，因为他认为这些预测是非常漂浮不定的，不值得他这个长远的价值投资者一用。相反，他更注重自己的独立分析和价值投资原则，从而取得了长期的投资成功。</span><br></pre></td></tr></table></figure>\n\n<p>*<em>当我用user_id= “*<em>userid_002*</em>“ 时</em>*</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">很抱歉，我无法准确回答这个问题，因为这个问题可能有很多可能的答案，且需要更多的上下文信息来确定。</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>在回答中添加引文信息</strong></p>\n<p>【1】用户问题</p>\n<p>【2】服务端查询的文档</p>\n<p>【3】服务端回答</p>\n<p>【4】引文信息</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-17-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2-%E6%B7%BB%E5%8A%A0%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF.assets/image-20240627101941020.png\" alt=\"image-20240627101941020\"></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-17-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2-%E6%B7%BB%E5%8A%A0%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF.assets/image-20240627101946985.png\" alt=\"image-20240627101946985\"></p>\n<p>关键提示词</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">system = <span class=\"string\">&quot;&quot;&quot;You&#x27;re a helpful AI assistant. Given a user question and some document snippets, \\</span></span><br><span class=\"line\"><span class=\"string\">answer the user question and provide citations. If none of the articles answer the question, just say you don&#x27;t know.</span></span><br><span class=\"line\"><span class=\"string\">Remember, you must return both an answer and citations. A citation consists of a VERBATIM quote that \\</span></span><br><span class=\"line\"><span class=\"string\">justifies the answer and the ID of the quote article. Return a citation for every quote across all articles \\</span></span><br><span class=\"line\"><span class=\"string\">that justify the answer. Use the following format for your final output:</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">&lt;cited_answer&gt;</span></span><br><span class=\"line\"><span class=\"string\">    &lt;answer&gt;&lt;/answer&gt;</span></span><br><span class=\"line\"><span class=\"string\">    &lt;citations&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;citation&gt;&lt;source_id&gt;&lt;/source_id&gt;&lt;quote&gt;&lt;/quote&gt;&lt;/citation&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;citation&gt;&lt;source_id&gt;&lt;/source_id&gt;&lt;quote&gt;&lt;/quote&gt;&lt;/citation&gt;</span></span><br><span class=\"line\"><span class=\"string\">        ...</span></span><br><span class=\"line\"><span class=\"string\">    &lt;/citations&gt;</span></span><br><span class=\"line\"><span class=\"string\">&lt;/cited_answer&gt;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Here are the document:&#123;context&#125;&quot;&quot;&quot;</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">    [(<span class=\"string\">&quot;system&quot;</span>, system), (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;question&#125;&quot;</span>)]</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>source_id 来自哪里？ 召回文档后，自己拼接产生你需要的“引文”格式</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs: <span class=\"type\">List</span>[Document]</span>) -&gt; <span class=\"built_in\">str</span>:</span><br><span class=\"line\">    formatted = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(docs):</span><br><span class=\"line\">        doc_str = <span class=\"string\">f&quot;&quot;&quot;\\</span></span><br><span class=\"line\"><span class=\"string\">    &lt;source id=\\&quot;<span class=\"subst\">&#123;i&#125;</span>\\&quot;&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;article_snippet&gt;<span class=\"subst\">&#123;doc.page_content&#125;</span>&lt;/article_snippet&gt;</span></span><br><span class=\"line\"><span class=\"string\">    &lt;/source&gt;&quot;&quot;&quot;</span></span><br><span class=\"line\">        formatted.append(doc_str)</span><br><span class=\"line\">    final_text = <span class=\"string\">&quot;\\n\\n&lt;sources&gt;&quot;</span> + <span class=\"string\">&quot;\\n&quot;</span>.join(formatted) + <span class=\"string\">&quot;&lt;/sources&gt;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> final_text</span><br></pre></td></tr></table></figure>\n\n<p>拼接后</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;source <span class=\"built_in\">id</span>=<span class=\"string\">&quot;0&quot;</span>&gt;</span><br><span class=\"line\">    &lt;article_snippet&gt;因此，常常会有一些证券公司...</span><br><span class=\"line\">    &lt;/article_snippet&gt;</span><br><span class=\"line\">&lt;/source&gt;</span><br></pre></td></tr></table></figure>\n\n<p>问答chain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\"><span class=\"built_in\">format</span> = itemgetter(<span class=\"string\">&quot;docs&quot;</span>) | RunnableLambda(format_docs)</span><br><span class=\"line\">answer = prompt | chat | StrOutputParser()</span><br><span class=\"line\">chain = (</span><br><span class=\"line\">    RunnableParallel(question=RunnablePassthrough(), docs=retriever)</span><br><span class=\"line\">    .assign(context=<span class=\"built_in\">format</span>)</span><br><span class=\"line\">    .assign(cited_answer=answer)</span><br><span class=\"line\">    .pick([<span class=\"string\">&quot;cited_answer&quot;</span>, <span class=\"string\">&quot;docs&quot;</span>])</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 测试一下</span></span><br><span class=\"line\">res = chain.invoke(<span class=\"string\">&quot;谁从来不被技术分析师的预测所左右?&quot;</span>)</span><br><span class=\"line\">ai_res = res[<span class=\"string\">&#x27;cited_answer&#x27;</span>]</span><br></pre></td></tr></table></figure>\n\n<p>输出</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-17-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2-%E6%B7%BB%E5%8A%A0%E5%BC%95%E6%96%87%E4%BF%A1%E6%81%AF.assets/image-20240627101959279.png\" alt=\"image-20240627101959279\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;<span class=\"string\">&#x27;cited_answer&#x27;</span>: </span><br><span class=\"line\"> <span class=\"string\">&#x27;&lt;cited_answer&gt;\\n    </span></span><br><span class=\"line\"><span class=\"string\">   &lt;answer&gt;巴菲特从来不被技术分析师的预测所左右。&lt;/answer&gt;\\n    </span></span><br><span class=\"line\"><span class=\"string\">   &lt;citations&gt;\\n        </span></span><br><span class=\"line\"><span class=\"string\">     &lt;citation&gt;</span></span><br><span class=\"line\"><span class=\"string\">         &lt;source_id&gt;0&lt;/source_id&gt;</span></span><br><span class=\"line\"><span class=\"string\">             &lt;quote&gt;巴菲特却从来不被技术分析师的预测所左右，他从不相信所谓的“权威分析”。    </span></span><br><span class=\"line\"><span class=\"string\">             &lt;/quote&gt;</span></span><br><span class=\"line\"><span class=\"string\">     &lt;/citation&gt;\\n    </span></span><br><span class=\"line\"><span class=\"string\">   &lt;/citations&gt;\\n</span></span><br><span class=\"line\"><span class=\"string\"> &lt;/cited_answer&gt;&#x27;</span>, ...</span><br></pre></td></tr></table></figure>\n\n<p>解析上面的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_response_to_json</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 匹配回答前的文本</span></span><br><span class=\"line\">    pre_answer_match = re.search(<span class=\"string\">r&#x27;^(.*?)(?=&lt;cited_answer&gt;)&#x27;</span>, text, re.DOTALL)</span><br><span class=\"line\">    pre_answer_text = pre_answer_match.group(<span class=\"number\">1</span>).strip() <span class=\"keyword\">if</span> pre_answer_match <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 匹配cited_answer块</span></span><br><span class=\"line\">    cited_answer_match = re.search(<span class=\"string\">r&#x27;&lt;cited_answer&gt;(.*?)&lt;\\/cited_answer&gt;&#x27;</span>, text, re.DOTALL)</span><br><span class=\"line\">    cited_answer_text = cited_answer_match.group(<span class=\"number\">1</span>).strip() <span class=\"keyword\">if</span> cited_answer_match <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化JSON结构</span></span><br><span class=\"line\">    output_json = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;response&quot;</span>: pre_answer_text,</span><br><span class=\"line\">        <span class=\"string\">&quot;cited_answer&quot;</span>: <span class=\"literal\">None</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 如果存在cited_answer块, 处理它</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cited_answer_text:</span><br><span class=\"line\">        <span class=\"comment\"># 匹配answer和citations</span></span><br><span class=\"line\">        answer_match = re.search(<span class=\"string\">r&#x27;&lt;answer&gt;(.*?)&lt;\\/answer&gt;&#x27;</span>, cited_answer_text)</span><br><span class=\"line\">        citations_match = re.findall(</span><br><span class=\"line\">            <span class=\"string\">r&#x27;&lt;citation&gt;\\s*&lt;source_id&gt;(.*?)&lt;\\/source_id&gt;\\s*&lt;quote&gt;(.*?)&lt;\\/quote&gt;\\s*&lt;\\/citation&gt;&#x27;</span>, cited_answer_text,</span><br><span class=\"line\">            re.DOTALL)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 构建cited_answer部分</span></span><br><span class=\"line\">        cited_answer_part = &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;answer&quot;</span>: answer_match.group(<span class=\"number\">1</span>).strip() <span class=\"keyword\">if</span> answer_match <span class=\"keyword\">else</span> <span class=\"literal\">None</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;citations&quot;</span>: []</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 添加citations</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> source_id, quote <span class=\"keyword\">in</span> citations_match:</span><br><span class=\"line\">            cited_answer_part[<span class=\"string\">&quot;citations&quot;</span>].append(&#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;source_id&quot;</span>: source_id.strip(),</span><br><span class=\"line\">                <span class=\"string\">&quot;quote&quot;</span>: quote.strip()</span><br><span class=\"line\">            &#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 更新JSON结构</span></span><br><span class=\"line\">        output_json[<span class=\"string\">&quot;cited_answer&quot;</span>] = cited_answer_part</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 返回JSON字符串</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> json.dumps(output_json, ensure_ascii=<span class=\"literal\">False</span>, indent=<span class=\"number\">4</span>)</span><br></pre></td></tr></table></figure>\n\n<p>解析后</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">    ai_res = res[<span class=\"string\">&#x27;cited_answer&#x27;</span>]</span><br><span class=\"line\">    json_obj_str = parse_response_to_json(ai_res)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br><span class=\"line\">    json_obj_obj = json.loads(json_obj_str)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(json_obj_obj)</span><br><span class=\"line\">&#123;<span class=\"string\">&#x27;response&#x27;</span>: <span class=\"string\">&#x27;&#x27;</span>, <span class=\"string\">&#x27;cited_answer&#x27;</span>: &#123;<span class=\"string\">&#x27;answer&#x27;</span>: <span class=\"string\">&#x27;巴菲特从来不被技术分析师的预测所左右。&#x27;</span>, <span class=\"string\">&#x27;citations&#x27;</span>: [&#123;<span class=\"string\">&#x27;source_id&#x27;</span>: <span class=\"string\">&#x27;0&#x27;</span>, <span class=\"string\">&#x27;quote&#x27;</span>: <span class=\"string\">&#x27;巴菲特却从来不被技术分析师的预测所左右，他从不相信所谓的“权威分析”。&#x27;</span>&#125;]&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>代码</p>\n<p>基于用户的搜索</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> TextLoader, DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough, RunnableParallel</span><br><span class=\"line\"></span><br><span class=\"line\">embedding_model_name = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-embedding-base_v1&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># 使用 GPU</span></span><br><span class=\"line\">embedding_model_kwargs = &#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用 CPU</span></span><br><span class=\"line\"><span class=\"comment\"># embedding_model_kwargs = &#123;&#x27;device&#x27;: &#x27;cpu&#x27;&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">embedding_encode_kwargs = &#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化</span></span><br><span class=\"line\">embed_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=embedding_model_name,</span><br><span class=\"line\">    model_kwargs=embedding_model_kwargs,</span><br><span class=\"line\">    encode_kwargs=embedding_encode_kwargs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【1】 建立文本的向量数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># 【1-1】 载入数据</span></span><br><span class=\"line\">    path = <span class=\"string\">&quot;./test&quot;</span></span><br><span class=\"line\">    text_loader_kwargs = &#123;<span class=\"string\">&#x27;autodetect_encoding&#x27;</span>: <span class=\"literal\">True</span>&#125;</span><br><span class=\"line\">    loader = DirectoryLoader(path, glob=<span class=\"string\">&quot;**/*.txt&quot;</span>, loader_cls=TextLoader, loader_kwargs=text_loader_kwargs,</span><br><span class=\"line\">                             show_progress=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【1-2】 分割数据</span></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class=\"line\">        <span class=\"comment\"># Set a really small chunk size, just to show.</span></span><br><span class=\"line\">        chunk_size=<span class=\"number\">500</span>,</span><br><span class=\"line\">        chunk_overlap=<span class=\"number\">0</span>,</span><br><span class=\"line\">        length_function=<span class=\"built_in\">len</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 建立2个作者的文档资料</span></span><br><span class=\"line\"></span><br><span class=\"line\">    doc_list = []</span><br><span class=\"line\">    owner_one_doc = docs[<span class=\"number\">0</span>]</span><br><span class=\"line\">    owner_one_docs = text_splitter.create_documents([owner_one_doc.page_content])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 加入metadata 信息，作者信息 userid_001</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(owner_one_docs):</span><br><span class=\"line\">        doc.metadata[<span class=\"string\">&quot;author&quot;</span>] = [<span class=\"string\">&quot;userid_001&quot;</span>]</span><br><span class=\"line\">        doc_list.append(doc)</span><br><span class=\"line\"></span><br><span class=\"line\">    owner_two_doc = docs[<span class=\"number\">1</span>]</span><br><span class=\"line\">    owner_two_docs = text_splitter.create_documents([owner_two_doc.page_content])</span><br><span class=\"line\">    <span class=\"comment\"># 加入metadata 信息，作者信息 userid_022</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(owner_two_docs):</span><br><span class=\"line\">        doc.metadata[<span class=\"string\">&quot;author&quot;</span>] = [<span class=\"string\">&quot;userid_022&quot;</span>]</span><br><span class=\"line\">        doc_list.append(doc)</span><br><span class=\"line\"></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embed_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># 将本文加入数据库（注意，只需要运行一次；多次运行会有冗余数据）</span></span><br><span class=\"line\">    <span class=\"comment\"># vectorstore.add_documents(doc_list)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 得到向量数据库的一个【检索器】</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【2】 建立查询 chain</span></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;使用下面的资料中的内容回答问题，如果没有资料，就回答：资料不全，无法回答您的问题。</span></span><br><span class=\"line\"><span class=\"string\">    参考资料：</span></span><br><span class=\"line\"><span class=\"string\">    &#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    用户问题: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    你的回答:&quot;&quot;&quot;</span></span><br><span class=\"line\">    custom_rag_prompt = PromptTemplate.from_template(template)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\">    chat = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将文档连接成字符串</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 你需要搜索谁的数据？</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#user_id= &quot;userid_001&quot;</span></span><br><span class=\"line\">    user_id = <span class=\"string\">&quot;userid_002&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 基于user_id， 定义你的过滤器</span></span><br><span class=\"line\">    filter_criteria = [&#123;<span class=\"string\">&quot;term&quot;</span>: &#123;<span class=\"string\">&quot;metadata.author.keyword&quot;</span>: user_id&#125;&#125;]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成只过滤user_id的检索器</span></span><br><span class=\"line\">    special_retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class=\"string\">&#x27;filter&#x27;</span>: filter_criteria&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试检索器效果，应该只能搜到metadata.author.keyword 为 user_id 的文档</span></span><br><span class=\"line\">    test_chain = RunnableParallel(</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: special_retriever, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># test_docs = test_chain.invoke(&quot;谁在2007年荣登“世界首富”的宝座，成了财富和成功的象征？&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 特殊的RAG chain， 只检索某个user_id 的文档</span></span><br><span class=\"line\">    rag_chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;context&quot;</span>: special_retriever | format_docs, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">            | custom_rag_prompt</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    go_on = <span class=\"literal\">True</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> go_on:</span><br><span class=\"line\">        query_text = <span class=\"built_in\">input</span>(<span class=\"string\">&quot;你的问题: &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&#x27;exit&#x27;</span> <span class=\"keyword\">in</span> query_text:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;AI需要回答的问题 [&#123;&#125;]\\n&quot;</span>.<span class=\"built_in\">format</span>(query_text))</span><br><span class=\"line\">        <span class=\"comment\"># res = rag_chain.invoke(query_text)</span></span><br><span class=\"line\">        <span class=\"comment\"># print(res)</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 基于问题返回文档</span></span><br><span class=\"line\">        docs = vectorstore.similarity_search(query_text)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(docs)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 基于metadata 关键字，搜索文档</span></span><br><span class=\"line\">        docs = vectorstore.similarity_search(</span><br><span class=\"line\">            query_text, <span class=\"built_in\">filter</span>=[&#123;<span class=\"string\">&quot;term&quot;</span>: &#123;<span class=\"string\">&quot;metadata.author.keyword&quot;</span>: user_id&#125;&#125;]</span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(docs) != <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(docs[<span class=\"number\">0</span>].metadata)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;没找到文档！&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        res = rag_chain.invoke(query_text)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(res)</span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>输出引文</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">from</span> operator <span class=\"keyword\">import</span> itemgetter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint, HuggingFaceEmbeddings</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">List</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.documents <span class=\"keyword\">import</span> Document</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> (</span><br><span class=\"line\">    RunnableLambda,</span><br><span class=\"line\">    RunnableParallel,</span><br><span class=\"line\">    RunnablePassthrough,</span><br><span class=\"line\">)</span><br><span class=\"line\">embedding_model_name = <span class=\"string\">&#x27;D:\\LLM\\\\bce_modesl\\\\bce-embedding-base_v1&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># 使用 GPU</span></span><br><span class=\"line\">embedding_model_kwargs = &#123;<span class=\"string\">&#x27;device&#x27;</span>: <span class=\"string\">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用 CPU</span></span><br><span class=\"line\"><span class=\"comment\"># embedding_model_kwargs = &#123;&#x27;device&#x27;: &#x27;cpu&#x27;&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">embedding_encode_kwargs = &#123;<span class=\"string\">&#x27;batch_size&#x27;</span>: <span class=\"number\">32</span>, <span class=\"string\">&#x27;normalize_embeddings&#x27;</span>: <span class=\"literal\">True</span>, &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化</span></span><br><span class=\"line\">embed_model = HuggingFaceEmbeddings(</span><br><span class=\"line\">    model_name=embedding_model_name,</span><br><span class=\"line\">    model_kwargs=embedding_model_kwargs,</span><br><span class=\"line\">    encode_kwargs=embedding_encode_kwargs</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_response_to_json</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 匹配回答前的文本</span></span><br><span class=\"line\">    pre_answer_match = re.search(<span class=\"string\">r&#x27;^(.*?)(?=&lt;cited_answer&gt;)&#x27;</span>, text, re.DOTALL)</span><br><span class=\"line\">    pre_answer_text = pre_answer_match.group(<span class=\"number\">1</span>).strip() <span class=\"keyword\">if</span> pre_answer_match <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 匹配cited_answer块</span></span><br><span class=\"line\">    cited_answer_match = re.search(<span class=\"string\">r&#x27;&lt;cited_answer&gt;(.*?)&lt;\\/cited_answer&gt;&#x27;</span>, text, re.DOTALL)</span><br><span class=\"line\">    cited_answer_text = cited_answer_match.group(<span class=\"number\">1</span>).strip() <span class=\"keyword\">if</span> cited_answer_match <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 初始化JSON结构</span></span><br><span class=\"line\">    output_json = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;response&quot;</span>: pre_answer_text,</span><br><span class=\"line\">        <span class=\"string\">&quot;cited_answer&quot;</span>: <span class=\"literal\">None</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 如果存在cited_answer块, 处理它</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cited_answer_text:</span><br><span class=\"line\">        <span class=\"comment\"># 匹配answer和citations</span></span><br><span class=\"line\">        answer_match = re.search(<span class=\"string\">r&#x27;&lt;answer&gt;(.*?)&lt;\\/answer&gt;&#x27;</span>, cited_answer_text)</span><br><span class=\"line\">        citations_match = re.findall(</span><br><span class=\"line\">            <span class=\"string\">r&#x27;&lt;citation&gt;\\s*&lt;source_id&gt;(.*?)&lt;\\/source_id&gt;\\s*&lt;quote&gt;(.*?)&lt;\\/quote&gt;\\s*&lt;\\/citation&gt;&#x27;</span>, cited_answer_text,</span><br><span class=\"line\">            re.DOTALL)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 构建cited_answer部分</span></span><br><span class=\"line\">        cited_answer_part = &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;answer&quot;</span>: answer_match.group(<span class=\"number\">1</span>).strip() <span class=\"keyword\">if</span> answer_match <span class=\"keyword\">else</span> <span class=\"literal\">None</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;citations&quot;</span>: []</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 添加citations</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> source_id, quote <span class=\"keyword\">in</span> citations_match:</span><br><span class=\"line\">            cited_answer_part[<span class=\"string\">&quot;citations&quot;</span>].append(&#123;</span><br><span class=\"line\">                <span class=\"string\">&quot;source_id&quot;</span>: source_id.strip(),</span><br><span class=\"line\">                <span class=\"string\">&quot;quote&quot;</span>: quote.strip()</span><br><span class=\"line\">            &#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># 更新JSON结构</span></span><br><span class=\"line\">        output_json[<span class=\"string\">&quot;cited_answer&quot;</span>] = cited_answer_part</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 返回JSON字符串</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> json.dumps(output_json, ensure_ascii=<span class=\"literal\">False</span>, indent=<span class=\"number\">4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用ElasticSearch</span></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embed_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 得到向量数据库的一个【检索器】</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【2】 建立查询连</span></span><br><span class=\"line\">    system = <span class=\"string\">&quot;&quot;&quot;You&#x27;re a helpful AI assistant. Given a user question and some document snippets, \\</span></span><br><span class=\"line\"><span class=\"string\">    answer the user question and provide citations. If none of the articles answer the question, just say you don&#x27;t know.</span></span><br><span class=\"line\"><span class=\"string\">    Remember, you must return both an answer and citations. A citation consists of a VERBATIM quote that \\</span></span><br><span class=\"line\"><span class=\"string\">    justifies the answer and the ID of the quote article. Return a citation for every quote across all articles \\</span></span><br><span class=\"line\"><span class=\"string\">    that justify the answer. Use the following format for your final output:</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    &lt;cited_answer&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;answer&gt;&lt;/answer&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;citations&gt;</span></span><br><span class=\"line\"><span class=\"string\">            &lt;citation&gt;&lt;source_id&gt;&lt;/source_id&gt;&lt;quote&gt;&lt;/quote&gt;&lt;/citation&gt;</span></span><br><span class=\"line\"><span class=\"string\">            &lt;citation&gt;&lt;source_id&gt;&lt;/source_id&gt;&lt;quote&gt;&lt;/quote&gt;&lt;/citation&gt;</span></span><br><span class=\"line\"><span class=\"string\">            ...</span></span><br><span class=\"line\"><span class=\"string\">        &lt;/citations&gt;</span></span><br><span class=\"line\"><span class=\"string\">    &lt;/cited_answer&gt;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Here are the document:&#123;context&#125;&quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">        [(<span class=\"string\">&quot;system&quot;</span>, system), (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;question&#125;&quot;</span>)]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">    DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">    chat = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">        azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">        temperature=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># GPT4 演示</span></span><br><span class=\"line\">    <span class=\"comment\"># os.environ[&quot;AZURE_OPENAI_API_KEY&quot;] = &quot;你的key&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># os.environ[&quot;AZURE_OPENAI_ENDPOINT&quot;] = &quot;你的endpoint&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># chat = AzureChatOpenAI(</span></span><br><span class=\"line\">    <span class=\"comment\">#     openai_api_version=&quot;2023-05-15&quot;,</span></span><br><span class=\"line\">    <span class=\"comment\">#     azure_deployment=&#x27;你的部署名称&#x27;,</span></span><br><span class=\"line\">    <span class=\"comment\">#     # temperature=0, # &lt;------ 温度</span></span><br><span class=\"line\">    <span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 之前我们对Docs 列表的处理</span></span><br><span class=\"line\">    <span class=\"comment\"># def format_docs(docs):</span></span><br><span class=\"line\">    <span class=\"comment\">#     return &quot;\\n\\n&quot;.join(doc.page_content for doc in docs)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 改进后的 Docs 列表的处理</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs: <span class=\"type\">List</span>[Document]</span>) -&gt; <span class=\"built_in\">str</span>:</span><br><span class=\"line\">        formatted = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, doc <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(docs):</span><br><span class=\"line\">            doc_str = <span class=\"string\">f&quot;&quot;&quot;\\</span></span><br><span class=\"line\"><span class=\"string\">        &lt;source id=\\&quot;<span class=\"subst\">&#123;i&#125;</span>\\&quot;&gt;</span></span><br><span class=\"line\"><span class=\"string\">            &lt;article_snippet&gt;<span class=\"subst\">&#123;doc.page_content&#125;</span>&lt;/article_snippet&gt;</span></span><br><span class=\"line\"><span class=\"string\">        &lt;/source&gt;&quot;&quot;&quot;</span></span><br><span class=\"line\">            formatted.append(doc_str)</span><br><span class=\"line\">        final_text = <span class=\"string\">&quot;\\n\\n&lt;sources&gt;&quot;</span> + <span class=\"string\">&quot;\\n&quot;</span>.join(formatted) + <span class=\"string\">&quot;&lt;/sources&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> final_text</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\">    <span class=\"built_in\">format</span> = itemgetter(<span class=\"string\">&quot;docs&quot;</span>) | RunnableLambda(format_docs)</span><br><span class=\"line\">    answer = prompt | chat | StrOutputParser()</span><br><span class=\"line\">    chain = (</span><br><span class=\"line\">        RunnableParallel(question=RunnablePassthrough(), docs=retriever)</span><br><span class=\"line\">        .assign(context=<span class=\"built_in\">format</span>)</span><br><span class=\"line\">        .assign(cited_answer=answer)</span><br><span class=\"line\">        .pick([<span class=\"string\">&quot;cited_answer&quot;</span>, <span class=\"string\">&quot;docs&quot;</span>])</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试一下</span></span><br><span class=\"line\">    res = chain.invoke(<span class=\"string\">&quot;谁从来不被技术分析师的预测所左右?&quot;</span>)</span><br><span class=\"line\">    ai_res = res[<span class=\"string\">&#x27;cited_answer&#x27;</span>]</span><br><span class=\"line\">    json_obj_str = parse_response_to_json(ai_res)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br><span class=\"line\">    json_obj_obj = json.loads(json_obj_str)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(json_obj_obj)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    go_on = <span class=\"literal\">True</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> go_on:</span><br><span class=\"line\">        query_text = <span class=\"built_in\">input</span>(<span class=\"string\">&quot;你的问题: &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&#x27;exit&#x27;</span> <span class=\"keyword\">in</span> query_text:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;AI需要回答的问题 [&#123;&#125;]\\n&quot;</span>.<span class=\"built_in\">format</span>(query_text))</span><br><span class=\"line\">        res = chain.invoke(query_text)</span><br><span class=\"line\">        <span class=\"comment\"># 连续体验</span></span><br><span class=\"line\">        <span class=\"comment\"># ai_res = res[&#x27;cited_answer&#x27;]</span></span><br><span class=\"line\">        <span class=\"comment\"># json_obj_str = parse_response_to_json(ai_res)</span></span><br><span class=\"line\">        <span class=\"comment\"># json_obj_obj = json.loads(json_obj_str)</span></span><br><span class=\"line\">        <span class=\"comment\"># print(json_obj_obj)</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[18]RAG：命令行 + UI + Agent","url":"/forward/6bf22a39.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>初步认识 RAG。学习基本RAG的实现方式。</p>\n<hr>\n<p><strong>索引数据</strong></p>\n<p>第一步，我们用Loader载入文档</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">path = <span class=\"string\">&quot;./test&quot;</span></span><br><span class=\"line\">text_loader_kwargs = &#123;<span class=\"string\">&#x27;autodetect_encoding&#x27;</span>: <span class=\"literal\">True</span>&#125;</span><br><span class=\"line\">loader = DirectoryLoader(path, glob=<span class=\"string\">&quot;**/*.txt&quot;</span>, loader_cls=TextLoader, loader_kwargs=text_loader_kwargs,show_progress=<span class=\"literal\">True</span>)</span><br><span class=\"line\">docs = loader.load()</span><br></pre></td></tr></table></figure>\n\n<p>第二部，我们分割文档</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class=\"line\">    <span class=\"comment\"># Set a really small chunk size, just to show.</span></span><br><span class=\"line\">    chunk_size=<span class=\"number\">500</span>,</span><br><span class=\"line\">    chunk_overlap=<span class=\"number\">0</span>,</span><br><span class=\"line\">    length_function=<span class=\"built_in\">len</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">doc_list = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs:</span><br><span class=\"line\">    tmp_docs = text_splitter.create_documents([doc.page_content])</span><br><span class=\"line\">    doc_list += tmp_docs</span><br></pre></td></tr></table></figure>\n\n<p>第三步，我们向量化文档，并保存到向量数据库</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用千帆 embedding bge_large_zh 模块</span></span><br><span class=\"line\">embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_zh&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_zh&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用ElasticSearch 数据库</span></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 将本文加入数据库（注意，只需要运行一次；多次运行会有冗余数据）</span></span><br><span class=\"line\">vectorstore.add_documents(doc_list)</span><br></pre></td></tr></table></figure>\n\n<p><strong>检索和生成、</strong></p>\n<p>到langsmith上抓取提示词模板</p>\n<p>prompt = hub.pull(“rlm/rag-prompt”)</p>\n<p>【1】点击hug 图标 【2】查询关键词</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-18-RAG%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C-UI-Agent.assets/image-20240627101543526.png\" alt=\"image-20240627101543526\"></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-18-RAG%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C-UI-Agent.assets/image-20240627101550907.png\" alt=\"image-20240627101550907\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 得到向量数据库的一个【检索器】</span></span><br><span class=\"line\">retriever = vectorstore.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 【2】 建立查询连</span></span><br><span class=\"line\">chat = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Use the following pieces of context to answer the question at the end.</span></span><br><span class=\"line\"><span class=\"string\">If you don&#x27;t know the answer, just say that you don&#x27;t know, don&#x27;t try to make up an answer.</span></span><br><span class=\"line\"><span class=\"string\">Use three sentences maximum and keep the answer as concise as possible.</span></span><br><span class=\"line\"><span class=\"string\">Always say &quot;thanks for asking!&quot; at the end of the answer.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Helpful Answer:&quot;&quot;&quot;</span></span><br><span class=\"line\">custom_rag_prompt = PromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以直接从langsmith 获取</span></span><br><span class=\"line\"><span class=\"comment\">#custom_rag_prompt = hub.pull(&quot;rlm/rag-prompt&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将文档连接成字符串</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\">rag_chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: retriever | format_docs, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | custom_rag_prompt</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">go_on = <span class=\"literal\">True</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> go_on:</span><br><span class=\"line\">    query_text = <span class=\"built_in\">input</span>(<span class=\"string\">&quot;你的问题: &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"string\">&#x27;exit&#x27;</span> <span class=\"keyword\">in</span> query_text:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;AI需要回答的问题 [&#123;&#125;]\\n&quot;</span>.<span class=\"built_in\">format</span>(query_text))</span><br><span class=\"line\">    res = rag_chain.invoke(query_text)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p><strong>什么？就这？我都会了！</strong></p>\n<p><strong>用Langserve 打开我的第一个RAG</strong></p>\n<p>LangServe帮助开发者将LangChain可运行程序和链部署为REST API。</p>\n<p><strong>功能特点</strong></p>\n<ul>\n<li>从您的LangChain对象自动推断输入和输出模式，并在每次API调用时强制执行，提供丰富的错误消息</li>\n<li>带有JSONSchema和Swagger的API文档页面（插入示例链接）</li>\n<li>高效的支持单个服务器上许多并发请求的/invoke/、/batch/和/stream/端点 /stream_log/端点，用于流式传输链/代理的所有（或部分）中间步骤</li>\n<li>从0.0.40版本开始支持astream_events，使流式传输更加容易，无需解析stream_log的输出。 /playground/页面具有流式输出和中间步骤的游乐场</li>\n<li>内置（可选）跟踪到LangSmith，只需添加您的API密钥（参见说明）</li>\n<li>所有这些都是使用经过实战测试的开源Python库构建的，如FastAPI、Pydantic、uvloop和asyncio。 使用客户端SDK调用LangServe服务器，就像它是本地运行的可运行程序一样（或者直接调用HTTP API） LangServe中心</li>\n</ul>\n<p>实现</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 定义APP</span></span><br><span class=\"line\">app = FastAPI(</span><br><span class=\"line\">    title=<span class=\"string\">&quot;LangChain Server&quot;</span>,</span><br><span class=\"line\">    version=<span class=\"string\">&quot;1.0&quot;</span>,</span><br><span class=\"line\">    description=<span class=\"string\">&quot;A simple API server using LangChain&#x27;s Runnable interfaces&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 将chain加入 服务器的rag_chain 路径</span></span><br><span class=\"line\">add_routes(</span><br><span class=\"line\">    app,</span><br><span class=\"line\">    rag_chain,</span><br><span class=\"line\">    path=<span class=\"string\">&quot;/rag_chain&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_routes(</span><br><span class=\"line\">    app,</span><br><span class=\"line\">    retriever,</span><br><span class=\"line\">    path=<span class=\"string\">&quot;/rag_docs&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> uvicorn</span><br><span class=\"line\">    <span class=\"comment\"># 访问 http://localhost:8001/rag_chain/playground/</span></span><br><span class=\"line\">    uvicorn.run(app, host=<span class=\"string\">&quot;localhost&quot;</span>, port=<span class=\"number\">8001</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>通过Agent实现RAG</strong></p>\n<ul>\n<li><p><strong>之前的做法：主动控制数据的流向，硬编码</strong></p>\n<p>问题→retriever→doc处理→生成提示词→大模型处理→数据解析→用户</p>\n</li>\n<li><p><strong>通过Agents：交给大模型自己判断，依赖模型</strong></p>\n<p>问题→<strong>Agents</strong>→用户</p>\n</li>\n</ul>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-18-RAG%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C-UI-Agent.assets/image-20240627101606370.png\" alt=\"image-20240627101606370\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">tool = create_retriever_tool(</span><br><span class=\"line\">    retriever,</span><br><span class=\"line\">    <span class=\"string\">&quot;search_mojuan_docs&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;搜索粥余知识库中的文档并返回&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\">tools = [tool]</span><br><span class=\"line\"></span><br><span class=\"line\">prompt = hub.pull(<span class=\"string\">&quot;hwchase17/openai-tools-agent&quot;</span>)</span><br><span class=\"line\">prompt.messages</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义agent</span></span><br><span class=\"line\">agent = create_openai_tools_agent(chat, tools, prompt)</span><br><span class=\"line\">agent_executor = AgentExecutor(agent=agent, tools=tools)</span><br><span class=\"line\"></span><br><span class=\"line\">go_on = <span class=\"literal\">True</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> go_on:</span><br><span class=\"line\">    query_text = <span class=\"built_in\">input</span>(<span class=\"string\">&quot;你的问题: &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"string\">&#x27;exit&#x27;</span> <span class=\"keyword\">in</span> query_text:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;AI需要回答的问题 [&#123;&#125;]\\n&quot;</span>.<span class=\"built_in\">format</span>(query_text))</span><br><span class=\"line\"></span><br><span class=\"line\">    result = agent_executor.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: query_text&#125;) <span class=\"comment\"># &lt;---- 调用</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(result)</span><br></pre></td></tr></table></figure>\n\n<p>Agent 对提示词敏感，不提示“粥余知识库”，就不会调用工具</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-18-RAG%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C-UI-Agent.assets/image-20240627101617176.png\" alt=\"image-20240627101617176\"></p>\n<p>修改问题，明确在“粥余知识库”中搜索，才会使用retriever工具</p>\n<p>【1】识别到需要调用工具（retriever）</p>\n<p>【2】在数据库中召回文档</p>\n<p>【3】根据文档回答</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-18-RAG%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C-UI-Agent.assets/image-20240627101641116.png\" alt=\"image-20240627101641116\"></p>\n<p>完整代码</p>\n<p>命令行RAG</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> TextLoader, DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【1】 建立文本的向量数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># 【1-1】 载入数据</span></span><br><span class=\"line\">    path = <span class=\"string\">&quot;./test&quot;</span></span><br><span class=\"line\">    text_loader_kwargs = &#123;<span class=\"string\">&#x27;autodetect_encoding&#x27;</span>: <span class=\"literal\">True</span>&#125;</span><br><span class=\"line\">    loader = DirectoryLoader(path, glob=<span class=\"string\">&quot;**/*.txt&quot;</span>, loader_cls=TextLoader, loader_kwargs=text_loader_kwargs,</span><br><span class=\"line\">                             show_progress=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    docs = loader.load()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【1-2】 分割数据</span></span><br><span class=\"line\">    text_splitter = RecursiveCharacterTextSplitter(</span><br><span class=\"line\">        <span class=\"comment\"># Set a really small chunk size, just to show.</span></span><br><span class=\"line\">        chunk_size=<span class=\"number\">400</span>,</span><br><span class=\"line\">        chunk_overlap=<span class=\"number\">0</span>,</span><br><span class=\"line\">        length_function=<span class=\"built_in\">len</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 分割Document 对象</span></span><br><span class=\"line\">    doc_list = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs:</span><br><span class=\"line\">        tmp_docs = text_splitter.create_documents([doc.page_content])</span><br><span class=\"line\">        doc_list += tmp_docs</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 文本向量化，存入数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># 使用千帆 embedding bge_large_zh 模块</span></span><br><span class=\"line\">    <span class=\"comment\"># 远程百度调用</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_zh&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_zh&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embeddings_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\"># 将本文加入数据库（注意，只需要运行一次；多次运行会有冗余数据）</span></span><br><span class=\"line\">    <span class=\"comment\"># vectorstore.add_documents(doc_list)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 得到向量数据库的一个【检索器】</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 【2】 建立查询连</span></span><br><span class=\"line\">    chat = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;Use the following pieces of context to answer the question at the end.</span></span><br><span class=\"line\"><span class=\"string\">    If you don&#x27;t know the answer, just say that you don&#x27;t know, don&#x27;t try to make up an answer.</span></span><br><span class=\"line\"><span class=\"string\">    Use three sentences maximum and keep the answer as concise as possible.</span></span><br><span class=\"line\"><span class=\"string\">    Always say &quot;thanks for asking!&quot; at the end of the answer.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    &#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Helpful Answer:&quot;&quot;&quot;</span></span><br><span class=\"line\">    custom_rag_prompt = PromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 可以直接从langsmith 获取</span></span><br><span class=\"line\">    <span class=\"comment\"># custom_rag_prompt = hub.pull(&quot;rlm/rag-prompt&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 将文档连接成字符串</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\">    rag_chain = (</span><br><span class=\"line\">            &#123;<span class=\"string\">&quot;context&quot;</span>: retriever | format_docs, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">            | custom_rag_prompt</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    go_on = <span class=\"literal\">True</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> go_on:</span><br><span class=\"line\">        query_text = <span class=\"built_in\">input</span>(<span class=\"string\">&quot;你的问题: &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&#x27;exit&#x27;</span> <span class=\"keyword\">in</span> query_text:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;AI需要回答的问题 [&#123;&#125;]\\n&quot;</span>.<span class=\"built_in\">format</span>(query_text))</span><br><span class=\"line\">        res = rag_chain.invoke(query_text)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(res)</span><br></pre></td></tr></table></figure>\n\n<p>Langserve RAG</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastapi <span class=\"keyword\">import</span> FastAPI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> TextLoader, DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"><span class=\"keyword\">from</span> langserve <span class=\"keyword\">import</span> add_routes</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用千帆 embedding bge_large_zh 模块</span></span><br><span class=\"line\"><span class=\"comment\"># 远程百度调用</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\">embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_zh&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_zh&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">vectorstore = ElasticsearchStore(</span><br><span class=\"line\">    es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">    index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">    embedding=embeddings_model,</span><br><span class=\"line\">    es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">    vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">    es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 得到向量数据库的一个【检索器】</span></span><br><span class=\"line\">retriever = vectorstore.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建立查询chain</span></span><br><span class=\"line\">chat = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Use the following pieces of context to answer the question at the end.</span></span><br><span class=\"line\"><span class=\"string\">If you don&#x27;t know the answer, just say that you don&#x27;t know, don&#x27;t try to make up an answer.</span></span><br><span class=\"line\"><span class=\"string\">Use three sentences maximum and keep the answer as concise as possible.</span></span><br><span class=\"line\"><span class=\"string\">Always say &quot;thanks for asking!&quot; at the end of the answer.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">&#123;context&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Helpful Answer:&quot;&quot;&quot;</span></span><br><span class=\"line\">custom_rag_prompt = PromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以直接从langsmith 获取</span></span><br><span class=\"line\"><span class=\"comment\"># custom_rag_prompt = hub.pull(&quot;rlm/rag-prompt&quot;)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将文档连接成字符串</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">format_docs</span>(<span class=\"params\">docs</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&quot;\\n\\n&quot;</span>.join(doc.page_content <span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> docs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检索 + 回答 chain</span></span><br><span class=\"line\">rag_chain = (</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;context&quot;</span>: retriever | format_docs, <span class=\"string\">&quot;question&quot;</span>: RunnablePassthrough()&#125;</span><br><span class=\"line\">        | custom_rag_prompt</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"comment\"># 1. 定义APP</span></span><br><span class=\"line\">app = FastAPI(</span><br><span class=\"line\">    title=<span class=\"string\">&quot;LangChain Server&quot;</span>,</span><br><span class=\"line\">    version=<span class=\"string\">&quot;1.0&quot;</span>,</span><br><span class=\"line\">    description=<span class=\"string\">&quot;A simple API server using LangChain&#x27;s Runnable interfaces&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 将chain加入 服务器的rag_chain 路径</span></span><br><span class=\"line\">add_routes(</span><br><span class=\"line\">    app,</span><br><span class=\"line\">    rag_chain,</span><br><span class=\"line\">    path=<span class=\"string\">&quot;/rag_chain&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">add_routes(</span><br><span class=\"line\">    app,</span><br><span class=\"line\">    retriever,</span><br><span class=\"line\">    path=<span class=\"string\">&quot;/rag_docs&quot;</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    <span class=\"keyword\">import</span> uvicorn</span><br><span class=\"line\">    <span class=\"comment\"># 访问 http://localhost:8001/rag_chain/playground/</span></span><br><span class=\"line\">    uvicorn.run(app, host=<span class=\"string\">&quot;localhost&quot;</span>, port=<span class=\"number\">8001</span>)</span><br></pre></td></tr></table></figure>\n\n<p>Langserve client</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langserve <span class=\"keyword\">import</span> RemoteRunnable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    remote_runnable = RemoteRunnable(<span class=\"string\">&quot;http://localhost:8001/rag_docs&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    docs = remote_runnable.invoke(<span class=\"string\">&quot;巴菲特&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>Agent</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> uuid <span class=\"keyword\">import</span> uuid4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents <span class=\"keyword\">import</span> create_openai_tools_agent, AgentExecutor</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.text_splitter <span class=\"keyword\">import</span> RecursiveCharacterTextSplitter</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.tools.retriever <span class=\"keyword\">import</span> create_retriever_tool</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.azure_openai <span class=\"keyword\">import</span> AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.document_loaders <span class=\"keyword\">import</span> TextLoader, DirectoryLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.embeddings <span class=\"keyword\">import</span> QianfanEmbeddingsEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.vectorstores.elasticsearch <span class=\"keyword\">import</span> ElasticsearchStore</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;AZURE_OPENAI_ENDPOINT&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_AZURE_OPENAI_ENDPOINT&#x27;</span>)</span><br><span class=\"line\">DEPLOYMENT_NAME_GPT3P5 = os.getenv(<span class=\"string\">&#x27;MY_DEPLOYMENT_NAME_GPT3P5&#x27;</span>)</span><br><span class=\"line\">chat = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2023-05-15&quot;</span>,</span><br><span class=\"line\">    azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Langsmith 配置，不用可注掉</span></span><br><span class=\"line\">unique_id = uuid4().<span class=\"built_in\">hex</span>[<span class=\"number\">0</span>:<span class=\"number\">8</span>]</span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_PROJECT&quot;</span>] = <span class=\"string\">f&quot; Agent RAG - <span class=\"subst\">&#123;unique_id&#125;</span>&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># os.environ[&quot;LANGCHAIN_TRACING_V2&quot;] = &#x27;true&#x27;</span></span><br><span class=\"line\">os.environ[<span class=\"string\">&quot;LANGCHAIN_API_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_LANGCHAIN_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用千帆 embedding bge_large_zh 模块</span></span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\">    embeddings_model = QianfanEmbeddingsEndpoint(model=<span class=\"string\">&quot;bge_large_zh&quot;</span>, endpoint=<span class=\"string\">&quot;bge_large_zh&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用ElasticSearch</span></span><br><span class=\"line\">    vectorstore = ElasticsearchStore(</span><br><span class=\"line\">        es_url=os.environ[<span class=\"string\">&#x27;ELASTIC_HOST_HTTP&#x27;</span>],</span><br><span class=\"line\">        index_name=<span class=\"string\">&quot;index_sd_1024_vectors&quot;</span>,</span><br><span class=\"line\">        embedding=embeddings_model,</span><br><span class=\"line\">        es_user=<span class=\"string\">&quot;elastic&quot;</span>,</span><br><span class=\"line\">        vector_query_field=<span class=\"string\">&#x27;question_vectors&#x27;</span>,</span><br><span class=\"line\">        es_password=os.environ[<span class=\"string\">&#x27;ELASTIC_ACCESS_PASSWORD&#x27;</span>]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 得到向量数据库的一个【检索器】</span></span><br><span class=\"line\">    retriever = vectorstore.as_retriever()</span><br><span class=\"line\"></span><br><span class=\"line\">    tool = create_retriever_tool(</span><br><span class=\"line\">        retriever,</span><br><span class=\"line\">        <span class=\"string\">&quot;search_mojuan_docs&quot;</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;搜索粥余知识库中的文档并返回&quot;</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    tools = [tool]</span><br><span class=\"line\"></span><br><span class=\"line\">    prompt = hub.pull(<span class=\"string\">&quot;hwchase17/openai-tools-agent&quot;</span>)</span><br><span class=\"line\">    prompt.messages</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    agent = create_openai_tools_agent(chat, tools, prompt)</span><br><span class=\"line\">    agent_executor = AgentExecutor(agent=agent, tools=tools)</span><br><span class=\"line\"></span><br><span class=\"line\">    go_on = <span class=\"literal\">True</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> go_on:</span><br><span class=\"line\">        query_text = <span class=\"built_in\">input</span>(<span class=\"string\">&quot;你的问题: &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"string\">&#x27;exit&#x27;</span> <span class=\"keyword\">in</span> query_text:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;AI需要回答的问题 [&#123;&#125;]\\n&quot;</span>.<span class=\"built_in\">format</span>(query_text))</span><br><span class=\"line\"></span><br><span class=\"line\">        result = agent_executor.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: query_text&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(result)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[19]信息抽取+langserve服务端","url":"/forward/5cb2ba7c.html","content":"<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>了解如何利用模型 抽取信息</p>\n<hr>\n<h1 id=\"1-概览\"><a href=\"#1-概览\" class=\"headerlink\" title=\"1.概览\"></a>1.概览</h1><p>大型语言模型（LLMs）正在成为驱动信息提取应用的一种极其强大的技术。 传统的信息提取解决方案依赖于人力、大量手工制作的规则（例如正则表达式）以及定制微调的机器学习模型。随着时间的推移，这些系统往往会变得复杂，维护成本逐渐增加，且难以提升。 LLMs可以快速适应特定的提取任务，只需向它们提供适当的指令和合适的参考示例。 <strong>通过LLM提取文本关键信息。</strong></p>\n<hr>\n<p>…</p>\n<blockquote>\n<p>《美棠来信：我们一家人》 作者：饶平如 出品方/出版社：小阅读Random 预计出版时间：2023年6月 （书封待定，图为作者饶平如） 继《平如美棠》后，《美棠来信》更加细致地呈现出家书中一个中国普通家庭的记忆。1973年至1979年，饶平如下放安徽，毛美棠留在上海照顾家庭。不久，家中年长的孩子们也响应知识青年上山下乡，去安徽、江西等地下乡。分散在各地的家庭成员，唯一连接他们亲情的，是一封封往来两地的家书。</p>\n</blockquote>\n<p>本书收录了饶平如在1973年到1979年之间收到的来自妻子美棠和孩子的近两百封家书。在那个通讯不便的年代，在这些家书里，他们互相汇报生活近况，通报生活上遇到的困难，给对方出谋划策，嘘寒问暖，这些家书支撑他们度过了两地分散的艰难时期，同时也是那个年代一个普通中国家庭生活的真实侧写。</p>\n<p>…</p>\n<hr>\n<h1 id=\"2-使用LLMs进行信息提取有三种广泛的方法：\"><a href=\"#2-使用LLMs进行信息提取有三种广泛的方法：\" class=\"headerlink\" title=\"2.使用LLMs进行信息提取有三种广泛的方法：\"></a>2.使用LLMs进行信息提取有三种广泛的方法：</h1><ul>\n<li><p>工具/函数调用模式：<strong>通过模型的Tool/Function Calling实现</strong></p>\n<p>一些LLMs支持工具或函数调用模式。这些LLMs可以根据给定的模式结构化输出。通常，这种方法最易于操作，并且预计会取得良好的结果。</p>\n</li>\n<li><p>JSON模式：<strong>某些模型可以强制输出JSON格式</strong></p>\n<p>一些LLMs可以被强制输出有效的JSON。这与工具/函数调用方法类似，不同之处在于模式是作为提示的一部分提供的。通常，我们的直觉是这种方法的表现不如工具/函数调用方法，但不要轻信我们，而是为您自己的用例进行验证！</p>\n</li>\n<li><p>基于提示的方法：<strong>基于提示工程生成指定格式的内容</strong></p>\n<p>能够很好地遵循指令的LLMs可以被指令以所需的格式生成文本。生成的文本可以使用现有的输出解析器或使用自定义解析器解析成结构化格式</p>\n<p><strong>举例见附录代码</strong></p>\n</li>\n</ul>\n<h1 id=\"3-实现方法\"><a href=\"#3-实现方法\" class=\"headerlink\" title=\"3. 实现方法\"></a>3. 实现方法</h1><h2 id=\"3-1-Schema-是什么\"><a href=\"#3-1-Schema-是什么\" class=\"headerlink\" title=\"3-1 Schema 是什么\"></a>3-1 <strong>Schema 是什么</strong></h2><p>上面3类方法langchain推荐用<strong>Tool/Function Calling实现</strong></p>\n<p><strong>Langchain 推出了 Schema 机制，它是一种 tool/function call 机制</strong></p>\n<p>比如：一个 Person的<strong>Schema</strong> ，定义了提取信息的内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">Optional</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.pydantic_v1 <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Information about a person.&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ^ Doc-string for the entity Person.</span></span><br><span class=\"line\">    <span class=\"comment\"># This doc-string is sent to the LLM as the description of the schema Person,</span></span><br><span class=\"line\">    <span class=\"comment\"># and it can help to improve extraction results.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Note that:</span></span><br><span class=\"line\">    <span class=\"comment\"># 1. Each field is an `optional` -- this allows the model to decline to extract it!</span></span><br><span class=\"line\">    <span class=\"comment\"># 2. Each field has a `description` -- this description is used by the LLM.</span></span><br><span class=\"line\">    <span class=\"comment\"># Having a good description can help improve extraction results.</span></span><br><span class=\"line\">    name: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(..., description=<span class=\"string\">&quot;The name of the person&quot;</span>)</span><br><span class=\"line\">    hair_color: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(</span><br><span class=\"line\">        ..., description=<span class=\"string\">&quot;The color of the peron&#x27;s hair if known&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    height_in_meters: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(</span><br><span class=\"line\">        ..., description=<span class=\"string\">&quot;Height measured in meters&quot;</span></span><br><span class=\"line\">    )</span><br></pre></td></tr></table></figure>\n\n<p>name，hair_color，height_in_meters： <strong>需要大模型抽取的信息</strong></p>\n<p>Optional： <strong>告诉模型可以不输出，别编</strong></p>\n<p>description： <strong>告诉模型变量的意思是什么</strong></p>\n<h2 id=\"3-2-Schema-如何定义\"><a href=\"#3-2-Schema-如何定义\" class=\"headerlink\" title=\"3-2 Schema 如何定义\"></a>3-2 <strong>Schema 如何定义</strong></h2><p>抽取信息时，一般不止一个，所以我么应该<strong>定义2个Schema ：</strong></p>\n<ul>\n<li><strong>具体信息的Schema</strong> ，比如 3-1 中的Person</li>\n<li><strong>包含多个具体信息</strong>（比如 3-1 中的Person）的<strong>列表</strong></li>\n</ul>\n<p><strong>Person</strong> vs <strong>Data</strong> (Person 的集合)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">List</span>, <span class=\"type\">Optional</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.pydantic_v1 <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Information about a person.&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># ^ Doc-string for the entity Person.</span></span><br><span class=\"line\">    <span class=\"comment\"># This doc-string is sent to the LLM as the description of the schema Person,</span></span><br><span class=\"line\">    <span class=\"comment\"># and it can help to improve extraction results.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Note that:</span></span><br><span class=\"line\">    <span class=\"comment\"># 1. Each field is an `optional` -- this allows the model to decline to extract it!</span></span><br><span class=\"line\">    <span class=\"comment\"># 2. Each field has a `description` -- this description is used by the LLM.</span></span><br><span class=\"line\">    <span class=\"comment\"># Having a good description can help improve extraction results.</span></span><br><span class=\"line\">    name: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(..., description=<span class=\"string\">&quot;The name of the person&quot;</span>)</span><br><span class=\"line\">    hair_color: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(</span><br><span class=\"line\">        ..., description=<span class=\"string\">&quot;The color of the peron&#x27;s hair if known&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    height_in_meters: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(</span><br><span class=\"line\">        ..., description=<span class=\"string\">&quot;Height measured in meters&quot;</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Data</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Extracted data about people.&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Creates a model so that we can extract multiple entities.</span></span><br><span class=\"line\">    people: <span class=\"type\">List</span>[Person]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-3-Schema-怎么用\"><a href=\"#3-3-Schema-怎么用\" class=\"headerlink\" title=\"3-3 Schema 怎么用\"></a>3-3 <strong>Schema 怎么用</strong></h2><p>langchain推荐：</p>\n<ul>\n<li><strong>提供一些例子给到大模型</strong>。</li>\n<li><strong>这些例子不通过提示词，而是通过伪造大模型的function call输出历史，反馈给大模型</strong></li>\n</ul>\n<p>比如我们想抽取文本中书的信息：</p>\n<p>文本内容是这样的：</p>\n<blockquote>\n<p>《美棠来信：我们一家人》 作者：饶平如 出品方/出版社：小阅读Random 预计出版时间：2023年6月 （书封待定，图为作者饶平如） 继《平如美棠》后，《美棠来信》更加细致地呈现出家书中一个中国普通家庭的记忆。1973年至1979年，饶平如下放安徽，毛美棠留在上海照顾家庭。不久，家中年长的孩子们也响应知识青年上山下乡，去安徽、江西等地下乡。分散在各地的家庭成员，唯一连接他们亲情的，是一封封往来两地的家书。</p>\n</blockquote>\n<p>本书收录了饶平如在1973年到1979年之间收到的来自妻子美棠和孩子的近两百封家书。在那个通讯不便的年代，在这些家书里，他们互相汇报生活近况，通报生活上遇到的困难，给对方出谋划策，嘘寒问暖，这些家书支撑他们度过了两地分散的艰难时期，同时也是那个年代一个普通中国家庭生活的真实侧写。</p>\n<p>定义<strong>Schema</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Book</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">    book_name: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(..., description=<span class=\"string\">&quot;书的名称&quot;</span>)</span><br><span class=\"line\">    writer: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field( ..., description=<span class=\"string\">&quot;书的作者&quot;</span>)</span><br><span class=\"line\">    content:<span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field( ..., description=<span class=\"string\">&quot;书大概内容介绍&quot;</span>)</span><br><span class=\"line\">    date :<span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field( ..., description=<span class=\"string\">&quot;预计出版时间&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Data</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">    books: <span class=\"type\">List</span>[Book]</span><br></pre></td></tr></table></figure>\n\n<p>制作一个假的function call记录（把一个真实例子，放到Book类对象中）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">examples = [</span><br><span class=\"line\">        (</span><br><span class=\"line\">            <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            《美棠来信：我们一家人》</span></span><br><span class=\"line\"><span class=\"string\">作者：饶平如</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：小阅读Random</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年6月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者饶平如）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">继《平如美棠》后，《美棠来信》更加细致地呈现出家书中一个中国普通家庭的记忆。1973年至1979年，饶平如下放安徽，毛美棠留在上海照顾家庭。不久，家中年长的孩子们也响应知识青年上山下乡，去安徽、江西等地下乡。分散在各地的家庭成员，唯一连接他们亲情的，是一封封往来两地的家书。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">本书收录了饶平如在1973年到1979年之间收到的来自妻子美棠和孩子的近两百封家书。在那个通讯不便的年代，在这些家书里，他们互相汇报生活近况，通报生活上遇到的困难，给对方出谋划策，嘘寒问暖，这些家书支撑他们度过了两地分散的艰难时期，同时也是那个年代一个普通中国家庭生活的真实侧写。</span></span><br><span class=\"line\"><span class=\"string\">            &quot;&quot;&quot;</span>,</span><br><span class=\"line\">            Book(book_name=<span class=\"string\">&#x27;美棠来信：我们一家人&#x27;</span>, writer=<span class=\"string\">&#x27;饶平如&#x27;</span>, content=<span class=\"string\">&quot;&quot;&quot;继《平如美棠》后，《美棠来信》更加细致地呈现出家书中一个中国普通家庭的记忆。1973年至1979年，饶平如下放安徽，毛美棠留在上海照顾家庭。不久，家中年长的孩子们也响应知识青年上山下乡，去安徽、江西等地下乡。分散在各地的家庭成员，唯一连接他们亲情的，是一封封往来两地的家书。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">本书收录了饶平如在1973年到1979年之间收到的来自妻子美棠和孩子的近两百封家书。在那个通讯不便的年代，在这些家书里，他们互相汇报生活近况，通报生活上遇到的困难，给对方出谋划策，嘘寒问暖，这些家书支撑他们度过了两地分散的艰难时期，同时也是那个年代一个普通中国家庭生活的真实侧写&quot;&quot;&quot;</span>,date=<span class=\"string\">&#x27;2023年6月&#x27;</span>),</span><br><span class=\"line\">        ),</span><br><span class=\"line\"></span><br><span class=\"line\">    ]</span><br></pre></td></tr></table></figure>\n\n<p><strong>example</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-19-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-langserve%E6%9C%8D%E5%8A%A1%E7%AB%AF.assets/image-20240627101340476.png\" alt=\"image-20240627101340476\"></p>\n<p><strong>tool_calls</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;<span class=\"string\">&#x27;id&#x27;</span>: <span class=\"string\">&#x27;932e3864-db6b-4888-a1ba-566609d6530d&#x27;</span>, <span class=\"string\">&#x27;type&#x27;</span>: <span class=\"string\">&#x27;function&#x27;</span>, <span class=\"string\">&#x27;function&#x27;</span>: &#123;<span class=\"string\">&#x27;name&#x27;</span>: <span class=\"string\">&#x27;Book&#x27;</span>, <span class=\"string\">&#x27;arguments&#x27;</span>: <span class=\"string\">&#x27;&#123;&quot;book_name&quot;: &quot;美棠来信：我们一家人&quot;, &quot;writer&quot;: &quot;饶平如&quot;, &quot;content&quot;: &quot;继《平如美棠》后，《美棠来信》更加细致..&quot;, &quot;date&quot;: &quot;2023年6月&quot;&#125;&#x27;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>伪造的消息列表</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-19-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-langserve%E6%9C%8D%E5%8A%A1%E7%AB%AF.assets/image-20240627101348752.png\" alt=\"image-20240627101348752\"></p>\n<p>把这个假消息放到消息列表</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">messages = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> text, tool_call <span class=\"keyword\">in</span> examples:</span><br><span class=\"line\">    messages.extend(</span><br><span class=\"line\">        tool_example_to_messages(&#123;<span class=\"string\">&quot;input&quot;</span>: text, <span class=\"string\">&quot;tool_calls&quot;</span>: [tool_call]&#125;)</span><br><span class=\"line\">    )</span><br></pre></td></tr></table></figure>\n\n<p>建立一个 提取 chain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">  prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">    [</span><br><span class=\"line\">        (</span><br><span class=\"line\">            <span class=\"string\">&quot;system&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;您是一个专业的提取信息专家。 &quot;</span></span><br><span class=\"line\">            <span class=\"string\">&quot;只从文本中提取相关信息。&quot;</span></span><br><span class=\"line\">            <span class=\"string\">&quot;如果你不知道请求提取的属性值，请将该属性值返回为null。&quot;</span>,</span><br><span class=\"line\">        ),</span><br><span class=\"line\">        <span class=\"comment\"># ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓</span></span><br><span class=\"line\">        MessagesPlaceholder(<span class=\"string\">&quot;examples&quot;</span>),  <span class=\"comment\"># &lt;-- EXAMPLES!</span></span><br><span class=\"line\">        <span class=\"comment\"># ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑</span></span><br><span class=\"line\">        (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;text&#125;&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\">)  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">llm = AzureChatOpenAI(</span><br><span class=\"line\">    openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">    azure_deployment=os.getenv(<span class=\"string\">&#x27;DEPLOYMENT_NAME_GPT3_4K_JP&#x27;</span>),</span><br><span class=\"line\">    temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">runnable = prompt | llm.with_structured_output(</span><br><span class=\"line\">    schema=Data,</span><br><span class=\"line\">    method=<span class=\"string\">&quot;function_calling&quot;</span>,</span><br><span class=\"line\">    include_raw=<span class=\"literal\">False</span>,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<p>提取真实文本信息</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">        text = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">《浮生余情》（暂名）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者：格非</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：译林出版社</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年8月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者格非）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《浮生余情》是格非时隔四年推出的最新重磅长篇小说，叙写了1980年代至今四十余年的漫长时间里，四个彼此关联的人物的命运流转。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">四个故事的主人公分别从江浙、北京、甘肃和天津四个地方来到北京的春台路21号——位于后厂村的中关村软件园。他们均供职于同一家现代物联网企业，彼此在生活中多有交集。四个故事由亲情、爱情的本能情感走向对自我与他者关系建构的哲学思考，进而关注现代人当下的存在方式与情感命题。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《大地上的家乡》</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者：刘亮程</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：译林出版社</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年6月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者刘亮程）</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(runnable.invoke(&#123;<span class=\"string\">&quot;text&quot;</span>: text, <span class=\"string\">&quot;examples&quot;</span>: messages&#125;))</span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">books=[Book(book_name=<span class=\"string\">&#x27;浮生余情&#x27;</span>, writer=<span class=\"string\">&#x27;格非&#x27;</span>, content=<span class=\"string\">&#x27;《浮生余情》是格非时隔四年推出的最新重磅长篇小说，叙写了1980年代至今四十余年的漫长时间里，四个彼此关联的人物的命运流转。&#x27;</span>, date=<span class=\"string\">&#x27;2023年8月&#x27;</span>), Book(book_name=<span class=\"string\">&#x27;大地上的家乡&#x27;</span>, writer=<span class=\"string\">&#x27;刘亮程&#x27;</span>, content=<span class=\"string\">&#x27;1998年，刘亮程站在乌鲁木齐的夕阳中，回望自己的家乡黄沙梁，写就《一个人的村庄》。此后，他在城市结婚、生子、写作、生活。2013年，刘亮程入住新疆木垒书院菜籽沟村落，重返晴耕雨读的田园生活，仿佛又回到早年的鸡鸣狗吠、虫鸣鸟语、风声落叶中，进入写作《一个人的村庄》时的状态。&#x27;</span>, date=<span class=\"string\">&#x27;2023年6月&#x27;</span>), Book(book_name=<span class=\"string\">&#x27;俗世奇人新增本&#x27;</span>, writer=<span class=\"string\">&#x27;冯骥才&#x27;</span>, content=<span class=\"string\">&#x27;“俗世奇人”系列是当代文化大家冯骥才先生的代表作，也是当代文学的重要收获之一。天津卫本是水陆码头，居民五方杂处，冯骥才随想随记，每人一篇，冠之总名《俗世奇人》耳。\\n\\n2022年末，冯先生又创作了18篇“俗世奇人”系列新作，包括《欢喜》《小尊王五》《田大头》《谢二虎》等精彩作品，还专程为书中人物绘制了20余幅精美人物插画。18篇新作延续了之前一贯的写作手法、传奇风格和创作水准，艺术性层面更为灵动丰富，令人不忍释卷。&#x27;</span>, date=<span class=\"string\">&#x27;2023年1月&#x27;</span>), Book(book_name=<span class=\"string\">&#x27;四&#x27;</span>, writer=<span class=\"string\">&#x27;杨本芬&#x27;</span>, content=<span class=\"string\">&#x27;杨本芬奶奶的第四本书，收入四个中短篇，写四个不同的人。对妈妈的回忆，对哥哥的眷恋，以及，哪怕是一位农妇，一个捡垃圾的老太太，依然拥有的，身为女性的，骄傲。也许，这本书可以叫《我的思念，她的骄傲》。&#x27;</span>, date=<span class=\"string\">&#x27;2023年7月&#x27;</span>), Book(book_name=<span class=\"string\">&#x27;木星时刻&#x27;</span>, writer=<span class=\"string\">&#x27;李静睿&#x27;</span>, content=<span class=\"string\">&#x27;李静睿的最新短篇小说集，收录具有科幻风格的《木星时刻》、充满粗粝现实感的《温榆河》等8部短篇小说。\\n\\n李静睿在《木星时刻》里构建了一个依法由AI治理的未来社会，人们在其中享有健康的饮食和生活方式、绝对安全的生存环境，以及完美的AI管家，唯独没有自由。于是，作为“最后一代上学还能逃课的人类”的主人公夫妻二人，决心踏上一场“肖申克”式的逃亡之旅……&#x27;</span>, date=<span class=\"string\">&#x27;2023年5月&#x27;</span>)]</span><br></pre></td></tr></table></figure>\n\n<p><strong>信息抽取时，注意点 ：</strong></p>\n<ul>\n<li>将模型温度设置为<strong>0</strong>。</li>\n<li>改进提示。提示应精确且切中要害。</li>\n<li>schema 中正确描述参数内容。</li>\n<li><strong>提供参考示例</strong>！多样化的示例有助于提高性能，包括不应提取任何内容的示例。</li>\n<li>如果您有很多示例，请使用检索器获取最相关的示例。</li>\n<li><strong>使用最佳可用的LLM/聊天模型（例如，gpt-4、claude-3等）</strong>进行基准测试。</li>\n<li>如果模式非常大，尝试将其拆分为多个较小的模式，分别运行提取并合并结果。</li>\n<li>确保模式允许模型拒绝提取信息。</li>\n<li>添加验证/更正步骤（要求LLM纠正或验证提取结果）。</li>\n</ul>\n<p>完整代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">List</span>, <span class=\"type\">Optional</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.pydantic_v1 <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_openai <span class=\"keyword\">import</span> ChatOpenAI, AzureChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">import</span> uuid</span><br><span class=\"line\"><span class=\"keyword\">from</span> typing <span class=\"keyword\">import</span> <span class=\"type\">Dict</span>, <span class=\"type\">List</span>, TypedDict</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> (</span><br><span class=\"line\">    AIMessage,</span><br><span class=\"line\">    BaseMessage,</span><br><span class=\"line\">    HumanMessage,</span><br><span class=\"line\">    SystemMessage,</span><br><span class=\"line\">    ToolMessage,</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.pydantic_v1 <span class=\"keyword\">import</span> BaseModel, Field</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_messages(</span><br><span class=\"line\">        [</span><br><span class=\"line\">            (</span><br><span class=\"line\">                <span class=\"string\">&quot;system&quot;</span>,</span><br><span class=\"line\">                <span class=\"string\">&quot;您是一个专业的提取信息专家。 &quot;</span></span><br><span class=\"line\">                <span class=\"string\">&quot;只从文本中提取相关信息。&quot;</span></span><br><span class=\"line\">                <span class=\"string\">&quot;如果你不知道请求提取的属性值，请将该属性值返回为null。&quot;</span>,</span><br><span class=\"line\">            ),</span><br><span class=\"line\">            <span class=\"comment\"># ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓</span></span><br><span class=\"line\">            MessagesPlaceholder(<span class=\"string\">&quot;examples&quot;</span>),  <span class=\"comment\"># &lt;-- EXAMPLES!</span></span><br><span class=\"line\">            <span class=\"comment\"># ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑</span></span><br><span class=\"line\">            (<span class=\"string\">&quot;human&quot;</span>, <span class=\"string\">&quot;&#123;text&#125;&quot;</span>),</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">class</span> <span class=\"title class_\">Book</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">        book_name: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(..., description=<span class=\"string\">&quot;书的名称&quot;</span>)</span><br><span class=\"line\">        writer: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field( ..., description=<span class=\"string\">&quot;书的作者&quot;</span>)</span><br><span class=\"line\">        content:<span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field( ..., description=<span class=\"string\">&quot;书大概内容介绍&quot;</span>)</span><br><span class=\"line\">        date :<span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field( ..., description=<span class=\"string\">&quot;预计出版时间&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">class</span> <span class=\"title class_\">Data</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">        books: <span class=\"type\">List</span>[Book]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">class</span> <span class=\"title class_\">Example</span>(<span class=\"title class_ inherited__\">TypedDict</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;A representation of an example consisting of text input and expected tool calls.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">        For extraction, the tool calls are represented as instances of pydantic model.</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">input</span>: <span class=\"built_in\">str</span>  <span class=\"comment\"># This is the example text</span></span><br><span class=\"line\">        tool_calls: <span class=\"type\">List</span>[BaseModel]  <span class=\"comment\"># Instances of pydantic model that should be extracted</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">tool_example_to_messages</span>(<span class=\"params\">example: Example</span>) -&gt; <span class=\"type\">List</span>[BaseMessage]:</span><br><span class=\"line\">        messages: <span class=\"type\">List</span>[BaseMessage] = [HumanMessage(content=example[<span class=\"string\">&quot;input&quot;</span>])]</span><br><span class=\"line\">        openai_tool_calls = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tool_call <span class=\"keyword\">in</span> example[<span class=\"string\">&quot;tool_calls&quot;</span>]:</span><br><span class=\"line\">            openai_tool_calls.append(</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"string\">&quot;id&quot;</span>: <span class=\"built_in\">str</span>(uuid.uuid4()),</span><br><span class=\"line\">                    <span class=\"string\">&quot;type&quot;</span>: <span class=\"string\">&quot;function&quot;</span>,</span><br><span class=\"line\">                    <span class=\"string\">&quot;function&quot;</span>: &#123;</span><br><span class=\"line\">                        <span class=\"string\">&quot;name&quot;</span>: tool_call.__class__.__name__,</span><br><span class=\"line\">                        <span class=\"string\">&quot;arguments&quot;</span>: tool_call.json(),</span><br><span class=\"line\">                    &#125;,</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            )</span><br><span class=\"line\">        messages.append(</span><br><span class=\"line\">            AIMessage(content=<span class=\"string\">&quot;&quot;</span>, additional_kwargs=&#123;<span class=\"string\">&quot;tool_calls&quot;</span>: openai_tool_calls&#125;)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        tool_outputs = example.get(<span class=\"string\">&quot;tool_outputs&quot;</span>) <span class=\"keyword\">or</span> [</span><br><span class=\"line\">            <span class=\"string\">&quot;You have correctly called this tool.&quot;</span></span><br><span class=\"line\">        ] * <span class=\"built_in\">len</span>(openai_tool_calls)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> output, tool_call <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(tool_outputs, openai_tool_calls):</span><br><span class=\"line\">            messages.append(ToolMessage(content=output, tool_call_id=tool_call[<span class=\"string\">&quot;id&quot;</span>]))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> messages</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    examples = [</span><br><span class=\"line\">        (</span><br><span class=\"line\">            <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            《美棠来信：我们一家人》</span></span><br><span class=\"line\"><span class=\"string\">作者：饶平如</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：小阅读Random</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年6月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者饶平如）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">继《平如美棠》后，《美棠来信》更加细致地呈现出家书中一个中国普通家庭的记忆。1973年至1979年，饶平如下放安徽，毛美棠留在上海照顾家庭。不久，家中年长的孩子们也响应知识青年上山下乡，去安徽、江西等地下乡。分散在各地的家庭成员，唯一连接他们亲情的，是一封封往来两地的家书。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">本书收录了饶平如在1973年到1979年之间收到的来自妻子美棠和孩子的近两百封家书。在那个通讯不便的年代，在这些家书里，他们互相汇报生活近况，通报生活上遇到的困难，给对方出谋划策，嘘寒问暖，这些家书支撑他们度过了两地分散的艰难时期，同时也是那个年代一个普通中国家庭生活的真实侧写。</span></span><br><span class=\"line\"><span class=\"string\">            &quot;&quot;&quot;</span>,</span><br><span class=\"line\">            Book(book_name=<span class=\"string\">&#x27;美棠来信：我们一家人&#x27;</span>, writer=<span class=\"string\">&#x27;饶平如&#x27;</span>, content=<span class=\"string\">&quot;&quot;&quot;继《平如美棠》后，《美棠来信》更加细致地呈现出家书中一个中国普通家庭的记忆。1973年至1979年，饶平如下放安徽，毛美棠留在上海照顾家庭。不久，家中年长的孩子们也响应知识青年上山下乡，去安徽、江西等地下乡。分散在各地的家庭成员，唯一连接他们亲情的，是一封封往来两地的家书。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">本书收录了饶平如在1973年到1979年之间收到的来自妻子美棠和孩子的近两百封家书。在那个通讯不便的年代，在这些家书里，他们互相汇报生活近况，通报生活上遇到的困难，给对方出谋划策，嘘寒问暖，这些家书支撑他们度过了两地分散的艰难时期，同时也是那个年代一个普通中国家庭生活的真实侧写&quot;&quot;&quot;</span>,date=<span class=\"string\">&#x27;2023年6月&#x27;</span>),</span><br><span class=\"line\">        ),</span><br><span class=\"line\"></span><br><span class=\"line\">    ]</span><br><span class=\"line\"></span><br><span class=\"line\">    messages = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> text, tool_call <span class=\"keyword\">in</span> examples:</span><br><span class=\"line\">        messages.extend(</span><br><span class=\"line\">            tool_example_to_messages(&#123;<span class=\"string\">&quot;input&quot;</span>: text, <span class=\"string\">&quot;tool_calls&quot;</span>: [tool_call]&#125;)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Azure Openai</span></span><br><span class=\"line\">    llm = AzureChatOpenAI(</span><br><span class=\"line\">        openai_api_version=<span class=\"string\">&quot;2024-02-15-preview&quot;</span>,</span><br><span class=\"line\">        azure_deployment=os.getenv(<span class=\"string\">&#x27;DEPLOYMENT_NAME_GPT3_4K_JP&#x27;</span>),</span><br><span class=\"line\">        temperature=<span class=\"number\">0</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    runnable = prompt | llm.with_structured_output(</span><br><span class=\"line\">        schema=Data,</span><br><span class=\"line\">        method=<span class=\"string\">&quot;function_calling&quot;</span>,</span><br><span class=\"line\">        include_raw=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">5</span>):</span><br><span class=\"line\">        text = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">《浮生余情》（暂名）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者：格非</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：译林出版社</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年8月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者格非）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《浮生余情》是格非时隔四年推出的最新重磅长篇小说，叙写了1980年代至今四十余年的漫长时间里，四个彼此关联的人物的命运流转。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">四个故事的主人公分别从江浙、北京、甘肃和天津四个地方来到北京的春台路21号——位于后厂村的中关村软件园。他们均供职于同一家现代物联网企业，彼此在生活中多有交集。四个故事由亲情、爱情的本能情感走向对自我与他者关系建构的哲学思考，进而关注现代人当下的存在方式与情感命题。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《大地上的家乡》</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者：刘亮程</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：译林出版社</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年6月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者刘亮程）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">1998年，刘亮程站在乌鲁木齐的夕阳中，回望自己的家乡黄沙梁，写就《一个人的村庄》。此后，他在城市结婚、生子、写作、生活。2013年，刘亮程入住新疆木垒书院菜籽沟村落，重返晴耕雨读的田园生活，仿佛又回到早年的鸡鸣狗吠、虫鸣鸟语、风声落叶中，进入写作《一个人的村庄》时的状态。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">菜籽沟村堆满故事，早晨做梦的气味被一只狗闻见，在一棵大树下慢慢变老，散步于开满窗户的山坡，看从天坑外背土豆的人……这些飘在空中被人视若寻常的故事，均收在了新书《大地上的家乡》里。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《俗世奇人新增本》</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者: 冯骥才</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社: 人民文学出版社</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年1月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">“俗世奇人”系列是当代文化大家冯骥才先生的代表作，也是当代文学的重要收获之一。天津卫本是水陆码头，居民五方杂处，性格迥然相异，冯骥才随想随记，每人一篇，冠之总名《俗世奇人》耳。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">2022年末，冯先生又创作了18篇“俗世奇人”系列新作，包括《欢喜》《小尊王五》《田大头》《谢二虎》等精彩作品，还专程为书中人物绘制了20余幅精美人物插画。18篇新作延续了之前一贯的写作手法、传奇风格和创作水准，艺术性层面更为灵动丰富，令人不忍释卷。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《四》（书名待定）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者：杨本芬</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：乐府文化</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年7月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，图为作者杨本芬）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">杨本芬奶奶的第四本书，收入四个中短篇，写四个不同的人。对妈妈的回忆，对哥哥的眷恋，以及，哪怕是一位农妇，一个捡垃圾的老太太，依然拥有的，身为女性的，骄傲。也许，这本书可以叫《我的思念，她的骄傲》。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">《木星时刻》</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">作者：李静睿</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">出品方/出版社：小阅读Random</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">预计出版时间：2023年5月</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">（书封待定，上图为作者李静睿）</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">李静睿的最新短篇小说集，收录具有科幻风格的《木星时刻》、充满粗粝现实感的《温榆河》等8部短篇小说。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">李静睿在《木星时刻》里构建了一个依法由AI治理的未来社会，人们在其中享有健康的饮食和生活方式、绝对安全的生存环境，以及完美的AI管家，唯独没有自由。于是，作为“最后一代上学还能逃课的人类”的主人公夫妻二人，决心踏上一场“肖申克”式的逃亡之旅……</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(runnable.invoke(&#123;<span class=\"string\">&quot;text&quot;</span>: text, <span class=\"string\">&quot;examples&quot;</span>: messages&#125;))</span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>提示词提取内容</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.chains.llm <span class=\"keyword\">import</span> LLMChain</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models.baidu_qianfan_endpoint <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> PromptTemplate, ChatPromptTemplate</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">parse_or_fix</span>(<span class=\"params\">text: <span class=\"built_in\">str</span>,chat</span>):</span><br><span class=\"line\">    fixing_chain = (</span><br><span class=\"line\"></span><br><span class=\"line\">            ChatPromptTemplate.from_template(</span><br><span class=\"line\">                <span class=\"string\">&quot;根据错误修改text中的文本内容:\\n\\n```text\\n&#123;input&#125;\\n```\\n错误: &#123;error&#125;&quot;</span></span><br><span class=\"line\">                <span class=\"string\">&quot;只返回修改后的text，千万不要解释，不要说明，不要添加```json&quot;</span></span><br><span class=\"line\">            )</span><br><span class=\"line\"></span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">        <span class=\"keyword\">try</span>:</span><br><span class=\"line\">            filtered_text = text.replace(<span class=\"string\">&#x27;```json\\n&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>).replace(<span class=\"string\">&#x27;```&#x27;</span>, <span class=\"string\">&#x27;&#x27;</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> json.loads(filtered_text)</span><br><span class=\"line\">        <span class=\"keyword\">except</span> Exception <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">            text = fixing_chain.invoke(&#123;<span class=\"string\">&quot;input&quot;</span>: filtered_text, <span class=\"string\">&quot;error&quot;</span>: e&#125;)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;百度修正结果： = [&#123;&#125;]&quot;</span>.<span class=\"built_in\">format</span>(text))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;百度修正失败！&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    </span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_ACCESS_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_ACCESS_KEY&#x27;</span>)</span><br><span class=\"line\">    os.environ[<span class=\"string\">&quot;QIANFAN_SECRET_KEY&quot;</span>] = os.getenv(<span class=\"string\">&#x27;MY_QIANFAN_SECRET_KEY&#x27;</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    chat = QianfanChatEndpoint(model=<span class=\"string\">&quot;ERNIE-Bot-4&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    examples = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">            &lt;&lt;曾国藩传&gt;&gt;</span></span><br><span class=\"line\"><span class=\"string\">            作者:AAA</span></span><br><span class=\"line\"><span class=\"string\">            出版时间:2000年11月3日</span></span><br><span class=\"line\"><span class=\"string\">            内容:曾国藩（1811-1872年），湖南湘乡人，初名子城，字伯函，号涤生，是中国历史上最有影响的人物之一。</span></span><br><span class=\"line\"><span class=\"string\">    他的人生，他的智慧，他的思想，深深地影响了几代中国人，以至他虽已去世一百余年，提起曾国藩，人们仍然津津乐道。</span></span><br><span class=\"line\"><span class=\"string\">    有的评论者说：如果以人物断代的话，曾国藩是中国古代历史上的最后一人，近代历史上的第一人。</span></span><br><span class=\"line\"><span class=\"string\">    这句话从某一角度，概括了曾国藩的个人作用和影响。</span></span><br><span class=\"line\"><span class=\"string\">    曾国藩出生于晚清一个地主家庭，自幼勤奋好学，6岁入塾读书。8岁能读八股文、诵五经，14岁能读《周礼》《史记》文选，</span></span><br><span class=\"line\"><span class=\"string\">    同年参加长沙的童子试，成绩列为优等。父麟书，有田产，不事耕种，醉心功名，然童试17次皆不第，父设馆授徒。</span></span><br><span class=\"line\"><span class=\"string\">    曾国藩幼从父学。道光十三年（1833）入县学为秀才。翌年就读于长沙岳麓书院，同年中举人。</span></span><br><span class=\"line\"><span class=\"string\">    此后赴京会试，一再落榜。十八年，始中第三十八名贡士，旋赴殿试，中三甲第四十二名，赐同进士出身。</span></span><br><span class=\"line\"><span class=\"string\">    朝考选翰林院庶吉士。自此供职京师，结交穆彰阿、倭仁及唐鉴等。二十七年任四川乡试正考官，二十八年升侍读，</span></span><br><span class=\"line\"><span class=\"string\">    后年升侍讲学士。二十七年授内阁学士，兼礼部侍郎衔。二十九年任礼部右侍郎，旋兼兵部右侍郎。</span></span><br><span class=\"line\"><span class=\"string\">    三十年兼署工部右侍郎。咸丰二年（1852）兼署吏部左侍郎。</span></span><br><span class=\"line\"><span class=\"string\">    后丁忧在湘乡老家，此时奉诏以礼部侍郎身份帮同湖南巡抚督办团练，创建湘军。</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 摘要提示词</span></span><br><span class=\"line\">    prompt_template = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        你是一个文本分析专家,你抽取文本中的书籍信息。</span></span><br><span class=\"line\"><span class=\"string\">        抽取的内容包括书名，作者，出版时间，内容评述。</span></span><br><span class=\"line\"><span class=\"string\">        你需要按照下面的格式输出，输出格式为JSON：</span></span><br><span class=\"line\"><span class=\"string\">        不要返回```json 和 多余内容。</span></span><br><span class=\"line\"><span class=\"string\">        book_name：</span></span><br><span class=\"line\"><span class=\"string\">        writer：</span></span><br><span class=\"line\"><span class=\"string\">        time：</span></span><br><span class=\"line\"><span class=\"string\">        content：</span></span><br><span class=\"line\"><span class=\"string\">        comments:</span></span><br><span class=\"line\"><span class=\"string\">        &#123;text&#125;</span></span><br><span class=\"line\"><span class=\"string\">        你的结果:&quot;&quot;&quot;</span></span><br><span class=\"line\">    edit_prompt = PromptTemplate.from_template(prompt_template)</span><br><span class=\"line\">    edit_chain = LLMChain(llm=chat, prompt=edit_prompt)</span><br><span class=\"line\">    result = edit_chain.run(text=examples)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 字符串转JSON</span></span><br><span class=\"line\">    json_obj = parse_or_fix(result,chat)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> json_obj:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;解析成功&#x27;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(json_obj)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;解析失败&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>信息抽取服务端：</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-19-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-langserve%E6%9C%8D%E5%8A%A1%E7%AB%AF.assets/image-20240627101412585.png\" alt=\"image-20240627101412585\"></p>\n<p>“这项服务是一个基础框架的网页应用，可以扩展其功能，为贵组织中的非技术用户创建一个数据提取应用。”</p>\n<blockquote>\n<p><strong><a href=\"https://github.com/langchain-ai/langchain-extract?ref=blog.langchain.dev\">https://github.com/langchain-ai/langchain-extract?ref=blog.langchain.dev</a></strong></p>\n</blockquote>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-19-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-langserve%E6%9C%8D%E5%8A%A1%E7%AB%AF.assets/image-20240627101436417.png\" alt=\"image-20240627101436417\"></p>\n<p>客户端：只需要设定一个 Schema，直接请求服务端即可</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Schema</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span>(<span class=\"title class_ inherited__\">BaseModel</span>):</span><br><span class=\"line\">    age: <span class=\"type\">Optional</span>[<span class=\"built_in\">int</span>] = Field(<span class=\"literal\">None</span>, description=<span class=\"string\">&quot;The age of the person in years.&quot;</span>)</span><br><span class=\"line\">    name: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(<span class=\"literal\">None</span>, description=<span class=\"string\">&quot;The name of the person.&quot;</span>)</span><br><span class=\"line\">    nick_name: <span class=\"type\">Optional</span>[<span class=\"built_in\">str</span>] = Field(<span class=\"literal\">None</span>, description=<span class=\"string\">&quot;Alias, if any.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">runnable = RemoteRunnable(<span class=\"string\">&quot;http://localhost:8000/extract_text/&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">text = <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">My name is Chester. i am 42 years old. My friend Jane is a year older than me.</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">response = runnable.invoke(&#123;<span class=\"string\">&quot;text&quot;</span>: text, <span class=\"string\">&quot;schema&quot;</span>: Person.schema()&#125;)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response)</span><br></pre></td></tr></table></figure>\n\n<hr>\n<p>🦜⛏️ <strong>LangChain Extract Server 启动关键步骤</strong></p>\n<p>1.2.0 <a href=\"https://www.postgresql.org/\">Postgresql</a> 安装配置：<a href=\"https://zhuanlan.zhihu.com/p/646870620\">传送门</a></p>\n<p><strong>1.2.1 确保</strong><a href=\"https://www.postgresql.org/\">Postgresql</a><strong>数据库可以登录</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-19-%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-langserve%E6%9C%8D%E5%8A%A1%E7%AB%AF.assets/image-20240627101448879.png\" alt=\"image-20240627101448879\"></p>\n<p>1.2.2 确保 <strong>Postgresql</strong> 相关表格正确创建 (<strong>需要先修改1.2.3中的数据库配置</strong>)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">python -m scripts.run_migrations create </span><br><span class=\"line\">All tables created successfully.</span><br></pre></td></tr></table></figure>\n\n<p>1.2.3 替换源代码中的 sql配置、向量模型、llm</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_postgres_url</span>() -&gt; URL:</span><br><span class=\"line\">    url = URL.create(</span><br><span class=\"line\">        drivername=<span class=\"string\">&quot;postgresql&quot;</span>,</span><br><span class=\"line\">        username=<span class=\"string\">&quot;xxxx&quot;</span>, <span class=\"comment\"># 修改</span></span><br><span class=\"line\">        password=<span class=\"string\">&quot;xxxxx&quot;</span>, <span class=\"comment\"># 修改</span></span><br><span class=\"line\">        host=os.environ.get(<span class=\"string\">&quot;PG_HOST&quot;</span>, <span class=\"string\">&quot;localhost&quot;</span>),</span><br><span class=\"line\">        database=<span class=\"string\">&quot;langchain&quot;</span>,</span><br><span class=\"line\">        port=<span class=\"number\">5432</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"keyword\">return</span> url</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">def</span> <span class=\"title function_\">get_model</span>() -&gt; ChatOpenAI:</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Get the model.&quot;&quot;&quot;</span></span><br><span class=\"line\">    model = xxxx <span class=\"comment\"># 修改</span></span><br><span class=\"line\">    <span class=\"comment\"># return ChatOpenAI(model=MODEL_NAME, temperature=0)</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">async</span> <span class=\"keyword\">def</span> <span class=\"title function_\">extract_from_content</span>()</span><br><span class=\"line\">    <span class=\"comment\"># 修改</span></span><br><span class=\"line\">    <span class=\"comment\"># vectorstore = FAISS.from_texts(doc_contents, embedding=OpenAIEmbeddings())</span></span><br><span class=\"line\">    <span class=\"comment\"># retriever = vectorstore.as_retriever()</span></span><br></pre></td></tr></table></figure>\n\n<p>1.2.4 启动</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 我的环境里已经设置相关 环境变量</span></span><br><span class=\"line\">python -m server.main </span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[03]聊天机器人 Chatbot","url":"/forward/53b4c1f8.html","content":"<p>目标</p>\n<p>我们将建立一个带有对话历史的聊天机器人。</p>\n<p>以下是我们将要使用的一些组件：</p>\n<ol>\n<li>聊天模型（Chat Models）：聊天机器人的界面是基于消息传递而不是原始文本，因此它更适合使用聊天模型而不是文本型的 LLM。</li>\n<li>提示模板（Prompt Templates）：这些模板简化了组装提示的过程，可以结合默认消息、用户输入、聊天历史以及（可选的）额外检索到的上下文。</li>\n<li>聊天历史（Chat History）：聊天历史允许聊天机器人“记住”过去的交互，并在回应后续问题时考虑这些历史。</li>\n<li>使用 LangSmith 调试和跟踪你的应用程序（<strong>非必须</strong>）。</li>\n</ol>\n<hr>\n<h3 id=\"聊天历史\"><a href=\"#聊天历史\" class=\"headerlink\" title=\"聊天历史\"></a>聊天历史</h3><p>在[Vol][2]中，我们使用了一个 messages[]来保存和传递消息，它是这个样子</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">      SystemMessage(content=<span class=\"string\">&quot;Translate the following from English into Italian&quot;</span>),</span><br><span class=\"line\">      HumanMessage(content=<span class=\"string\">&quot;hi!&quot;</span>),</span><br><span class=\"line\">      ...</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p>其实，随着对话的增长，我们可以把AI消息和我们自己的消息一起添加到这个列表里</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">      SystemMessage(content=<span class=\"string\">&quot;Translate the following from English into Italian&quot;</span>),</span><br><span class=\"line\">      HumanMessage(content=<span class=\"string\">&quot;hi!&quot;</span>),</span><br><span class=\"line\">      AIMessage(content=<span class=\"string\">&quot;...&quot;</span>)</span><br><span class=\"line\">      HumanMessage(content=<span class=\"string\">&quot;...&quot;</span>),</span><br><span class=\"line\">      AIMessage(content=<span class=\"string\">&quot;...&quot;</span>)</span><br><span class=\"line\">      HumanMessage(content=<span class=\"string\">&quot;...&quot;</span>),</span><br><span class=\"line\">      AIMessage(content=<span class=\"string\">&quot;...&quot;</span>)</span><br><span class=\"line\">      HumanMessage(content=<span class=\"string\">&quot;...&quot;</span>),</span><br><span class=\"line\">      ...</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p>上面[]的内容，就是对话历史…</p>\n<p>我们先不看官方的例子，简单的事非得搞复杂…</p>\n<p>我们先自己维护一下对话历史，感受一下最底层的对话历史逻辑~</p>\n<p>这里我们用通义千问做演示</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用通义千问</span></span><br><span class=\"line\"><span class=\"comment\"># DASHSCOPE_API_KEY 需要在阿里云里面申请相关Key</span></span><br><span class=\"line\">api_key = DASHSCOPE_API_KEY</span><br><span class=\"line\">qwen_chat = ChatOpenAI(</span><br><span class=\"line\">    model_name=<span class=\"string\">&quot;qwen-max&quot;</span>,</span><br><span class=\"line\">    openai_api_base=<span class=\"string\">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class=\"line\">    openai_api_key=api_key,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出解析</span></span><br><span class=\"line\">parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 提示词</span></span><br><span class=\"line\">system_template = <span class=\"string\">&quot;你是一个AI助手。&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成系统提示词 obj</span></span><br><span class=\"line\">sys_msg = SystemMessage(content=system_template)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对话历史，手工添加</span></span><br><span class=\"line\">messages = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 先添加系统消息</span></span><br><span class=\"line\">messages.append(sys_msg)</span><br><span class=\"line\"></span><br><span class=\"line\">res = qwen_chat.invoke(<span class=\"string\">&quot;hi,你好，我是粥~&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加我们的输入</span></span><br><span class=\"line\">messages.append(HumanMessage(content=<span class=\"string\">&quot;hi,你好，我是粥~&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加Ai的回答</span></span><br><span class=\"line\"><span class=\"comment\"># 注意： 大模型输出是一个 AIMessage， 所以我们可以这样添加</span></span><br><span class=\"line\">messages.append(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 我们验证一下，对话历史是否 有效果, 用模型直接根据历史回答</span></span><br><span class=\"line\">messages.append(HumanMessage(content=<span class=\"string\">&quot;我是谁？&quot;</span>))</span><br><span class=\"line\">res = qwen_chat.invoke(messages)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(res.content)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>在res = qwen_chat.invoke(messages) 调用前，对话历史是这样的</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">   SystemMessage(content=<span class=\"string\">&#x27;你是一个AI助手。&#x27;</span>), </span><br><span class=\"line\">   HumanMessage(content=<span class=\"string\">&#x27;hi,你好，我是粥~&#x27;</span>), </span><br><span class=\"line\">   AIMessage(content=<span class=\"string\">&#x27;你好，粥~！很高兴能与你交流。有什么可以帮助你的吗？&#x27;</span>, response_metadata=&#123;<span class=\"string\">&#x27;token_usage&#x27;</span>: &#123;<span class=\"string\">&#x27;completion_tokens&#x27;</span>: <span class=\"number\">16</span>, <span class=\"string\">&#x27;prompt_tokens&#x27;</span>: <span class=\"number\">15</span>, <span class=\"string\">&#x27;total_tokens&#x27;</span>: <span class=\"number\">31</span>&#125;, <span class=\"string\">&#x27;model_name&#x27;</span>: <span class=\"string\">&#x27;qwen-max&#x27;</span>, <span class=\"string\">&#x27;system_fingerprint&#x27;</span>: <span class=\"literal\">None</span>, <span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;stop&#x27;</span>, <span class=\"string\">&#x27;logprobs&#x27;</span>: <span class=\"literal\">None</span>&#125;, <span class=\"built_in\">id</span>=<span class=\"string\">&#x27;run-ae2d37f0-287f-4c37-a0cd-bc0a8cc2114f-0&#x27;</span>), </span><br><span class=\"line\">   HumanMessage(content=<span class=\"string\">&#x27;我是谁？&#x27;</span>)</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p>AI最后的回答</p>\n<p>可以看到，AI还记得我是粥<del>，这个效果是因为我们在messages里有对话历史</del></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">content=<span class=\"string\">&#x27;你是卷儿，刚刚你自己介绍过了哦。如果有什么想聊的或者需要帮助的，尽管告诉我！&#x27;</span> response_metadata=&#123;<span class=\"string\">&#x27;token_usage&#x27;</span>: &#123;<span class=\"string\">&#x27;completion_tokens&#x27;</span>: <span class=\"number\">23</span>, <span class=\"string\">&#x27;prompt_tokens&#x27;</span>: <span class=\"number\">54</span>, <span class=\"string\">&#x27;total_tokens&#x27;</span>: <span class=\"number\">77</span>&#125;, <span class=\"string\">&#x27;model_name&#x27;</span>: <span class=\"string\">&#x27;qwen-max&#x27;</span>, <span class=\"string\">&#x27;system_fingerprint&#x27;</span>: <span class=\"literal\">None</span>, <span class=\"string\">&#x27;finish_reason&#x27;</span>: <span class=\"string\">&#x27;stop&#x27;</span>, <span class=\"string\">&#x27;logprobs&#x27;</span>: <span class=\"literal\">None</span>&#125; <span class=\"built_in\">id</span>=<span class=\"string\">&#x27;run-979eb2bb-fa93-4d18-bda0-288d6d0a11b5-0&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Message-History\"><a href=\"#Message-History\" class=\"headerlink\" title=\"Message History\"></a>Message History</h3><p>这是langchain 实现的一个对话历史的方法，不是那么重要，但是其中提到的 <strong>通过config结构获取对话历史</strong>，这种</p>\n<p>模式比较重要~</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc2&quot;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在代码中讲解</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_message_histories <span class=\"keyword\">import</span> ChatMessageHistory</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.chat_history <span class=\"keyword\">import</span> BaseChatMessageHistory</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables.history <span class=\"keyword\">import</span> RunnableWithMessageHistory</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 通过ID 返回一个ChatMessageHistory</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_session_history</span>(<span class=\"params\">session_id: <span class=\"built_in\">str</span></span>) -&gt; BaseChatMessageHistory:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> session_id <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> store:</span><br><span class=\"line\">        store[session_id] = ChatMessageHistory()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> store[session_id]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用通义千问</span></span><br><span class=\"line\">model = qwen_chat</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># langchain 的RunnableWithMessageHistory</span></span><br><span class=\"line\"><span class=\"comment\"># 需要传递一个runnable，一个 获得历史的方法 ：get_session_history</span></span><br><span class=\"line\">with_message_history = RunnableWithMessageHistory(model, get_session_history)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># session_id 是一个 TAG， 一个记录，表示不同的配置，比如你有很多对话，用不同的tag 表示不同的对话历史</span></span><br><span class=\"line\">config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc2&quot;</span>&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 自动保存历史，不用我们手动保存了</span></span><br><span class=\"line\">response = with_message_history.invoke(</span><br><span class=\"line\">    [HumanMessage(content=<span class=\"string\">&quot;Hi! I&#x27;m Bob&quot;</span>)],</span><br><span class=\"line\">    config=config,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 同样的config， 同样的对话历史，AI记得我们是谁</span></span><br><span class=\"line\">response = with_message_history.invoke(</span><br><span class=\"line\">    [HumanMessage(content=<span class=\"string\">&quot;What&#x27;s my name?&quot;</span>)],</span><br><span class=\"line\">    config=config,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用不同TAG，abc3， 即不同的历史，AI不记得我们是谁</span></span><br><span class=\"line\">config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc3&quot;</span>&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">response = with_message_history.invoke(</span><br><span class=\"line\">    [HumanMessage(content=<span class=\"string\">&quot;What&#x27;s my name?&quot;</span>)],</span><br><span class=\"line\">    config=config,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用之间的TAG，就可以识别了~</span></span><br><span class=\"line\">config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc2&quot;</span>&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">response = with_message_history.invoke(</span><br><span class=\"line\">    [HumanMessage(content=<span class=\"string\">&quot;What&#x27;s my name?&quot;</span>)],</span><br><span class=\"line\">    config=config,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.content)</span><br></pre></td></tr></table></figure>\n\n<p><strong>Streaming</strong></p>\n<p>langchain提供了很多方法， 流式输出是其中的一个例子，还包括 批处理（batch）,异步调用 等等。</p>\n<p>一个chain 定义之后，我们想用哪种方法调用都可以，只需要换一个方法即可~</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 流式输出</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> with_message_history.stream([HumanMessage(content=<span class=\"string\">&quot;hi! tell me a joke&quot;</span>)],</span><br><span class=\"line\">       config=config,</span><br><span class=\"line\">):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(r.content, end=<span class=\"string\">&quot;|&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>输出</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">|Sure|,| here|<span class=\"string\">&#x27;s a joke for you|, Bob: &lt;--AI 还记得我们</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Why don&#x27;</span>t scientists trust| atoms?</span><br><span class=\"line\"></span><br><span class=\"line\">Because they make up everything!||</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"参考代码\"><a href=\"#参考代码\" class=\"headerlink\" title=\"参考代码\"></a>参考代码</h3><figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.chat_models <span class=\"keyword\">import</span> QianfanChatEndpoint</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_openai <span class=\"keyword\">import</span> AzureChatOpenAI, ChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage, SystemMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> llm_cfg <span class=\"keyword\">import</span> AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, DEPLOYMENT_NAME_GPT3P5, MY_QIANFAN_AK, MY_QIANFAN_SK, \\</span><br><span class=\"line\">    DASHSCOPE_API_KEY</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用 通义千问</span></span><br><span class=\"line\">    api_key = DASHSCOPE_API_KEY</span><br><span class=\"line\">    qwen_chat = ChatOpenAI(</span><br><span class=\"line\">        model_name=<span class=\"string\">&quot;qwen-max&quot;</span>,</span><br><span class=\"line\">        openai_api_base=<span class=\"string\">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class=\"line\">        openai_api_key=api_key,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用 Azure OpenAi</span></span><br><span class=\"line\">    <span class=\"comment\"># os.environ[&quot;AZURE_OPENAI_API_KEY&quot;] =AZURE_OPENAI_API_KEY</span></span><br><span class=\"line\">    <span class=\"comment\"># os.environ[&quot;AZURE_OPENAI_ENDPOINT&quot;] =AZURE_OPENAI_ENDPOINT</span></span><br><span class=\"line\">    <span class=\"comment\"># gpt3p5_model = AzureChatOpenAI(</span></span><br><span class=\"line\">    <span class=\"comment\">#     openai_api_version=&quot;2024-02-15-preview&quot;,</span></span><br><span class=\"line\">    <span class=\"comment\">#     azure_deployment=DEPLOYMENT_NAME_GPT3P5,</span></span><br><span class=\"line\">    <span class=\"comment\"># )</span></span><br><span class=\"line\"></span><br><span class=\"line\">    parser = StrOutputParser()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 提示词</span></span><br><span class=\"line\">    system_template = <span class=\"string\">&quot;你是一个AI助手。&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成系统提示词 obj</span></span><br><span class=\"line\">    sys_msg = SystemMessage(content=system_template)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 对话历史，手工添加</span></span><br><span class=\"line\">    messages = []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 先添加系统消息</span></span><br><span class=\"line\">    messages.append(sys_msg)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># res = qwen_chat.invoke(&quot;hi,你好，我是卷儿&quot;)</span></span><br><span class=\"line\">    <span class=\"comment\"># print(res)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 添加我们的输入</span></span><br><span class=\"line\">    messages.append(HumanMessage(content=<span class=\"string\">&quot;hi,你好，我是卷儿&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 添加Ai的回答</span></span><br><span class=\"line\">    <span class=\"comment\"># 注意： 大模型输出是一个 AIMessage， 所以我们可以这样添加</span></span><br><span class=\"line\">    <span class=\"comment\"># messages.append(res)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 我们验证一下，对话历史是否 有效果, 用模型直接根据历史回答</span></span><br><span class=\"line\">    messages.append(HumanMessage(content=<span class=\"string\">&quot;我是谁？&quot;</span>))</span><br><span class=\"line\">    <span class=\"comment\"># res = qwen_chat.invoke(messages)</span></span><br><span class=\"line\">    <span class=\"comment\"># print(res.content)</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    store = &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#Message History</span></span><br><span class=\"line\">    <span class=\"keyword\">from</span> langchain_community.chat_message_histories <span class=\"keyword\">import</span> ChatMessageHistory</span><br><span class=\"line\">    <span class=\"keyword\">from</span> langchain_core.chat_history <span class=\"keyword\">import</span> BaseChatMessageHistory</span><br><span class=\"line\">    <span class=\"keyword\">from</span> langchain_core.runnables.history <span class=\"keyword\">import</span> RunnableWithMessageHistory</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_session_history</span>(<span class=\"params\">session_id: <span class=\"built_in\">str</span></span>) -&gt; BaseChatMessageHistory:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> session_id <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> store:</span><br><span class=\"line\">            store[session_id] = ChatMessageHistory()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> store[session_id]</span><br><span class=\"line\"></span><br><span class=\"line\">    model = qwen_chat</span><br><span class=\"line\">    with_message_history = RunnableWithMessageHistory(model, get_session_history)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># session_id 是一个 TAG， 一个记录，表示不同的配置，比如你有很多对话，用不同的tag 表示不同的对话历史</span></span><br><span class=\"line\">    config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc2&quot;</span>&#125;&#125;</span><br><span class=\"line\">    response = with_message_history.invoke(</span><br><span class=\"line\">        [HumanMessage(content=<span class=\"string\">&quot;Hi! I&#x27;m Bob&quot;</span>)],</span><br><span class=\"line\">        config=config,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 同样的config， 同样的对话历史</span></span><br><span class=\"line\">    response = with_message_history.invoke(</span><br><span class=\"line\">        [HumanMessage(content=<span class=\"string\">&quot;What&#x27;s my name?&quot;</span>)],</span><br><span class=\"line\">        config=config,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用不同TAG，abc3， 即不同的历史</span></span><br><span class=\"line\">    config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc3&quot;</span>&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    response = with_message_history.invoke(</span><br><span class=\"line\">        [HumanMessage(content=<span class=\"string\">&quot;What&#x27;s my name?&quot;</span>)],</span><br><span class=\"line\">        config=config,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 不认识之前提到的名字</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 用之间的TAG，就可以识别了~</span></span><br><span class=\"line\">    config = &#123;<span class=\"string\">&quot;configurable&quot;</span>: &#123;<span class=\"string\">&quot;session_id&quot;</span>: <span class=\"string\">&quot;abc2&quot;</span>&#125;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    response = with_message_history.invoke(</span><br><span class=\"line\">        [HumanMessage(content=<span class=\"string\">&quot;What&#x27;s my name?&quot;</span>)],</span><br><span class=\"line\">        config=config,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(response.content)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> with_message_history.stream([HumanMessage(content=<span class=\"string\">&quot;hi! tell me a joke&quot;</span>)],</span><br><span class=\"line\">           config=config,</span><br><span class=\"line\">    ):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(r.content, end=<span class=\"string\">&quot;|&quot;</span>)</span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"Langchain系列[20]与SQL数据库进行聊天","url":"/forward/d9fa438e.html","content":"<p>使用Python和LangChain与MySQL（或SQLite）数据库进行聊天。</p>\n<ul>\n<li>text2Sql chain</li>\n<li>text2Sql Agent</li>\n<li>Sql 操作封装</li>\n</ul>\n<p>我们将使用sqlalchemy的LangChain包装器与数据库交互。我们还将使用langchain包创建一个自定义链/Agent，使我们能够使用自然语言与数据库进行聊天。</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627100730128.png\" alt=\"image-20240627100730128\"></p>\n<p>使用到的工具</p>\n<ul>\n<li><p><a href=\"https://www.python.org/downloads/\">Python 3.9 or later</a></p>\n</li>\n<li><p><a href=\"https://www.mysql.com/downloads/\">MySQL</a></p>\n<blockquote>\n<p>Mysql 安装配置 →<a href=\"https://zhuanlan.zhihu.com/p/338149747\">https://zhuanlan.zhihu.com/p/338149747</a></p>\n</blockquote>\n</li>\n<li><p><a href=\"https://www.sqlite.org/download.html\">SQLite</a></p>\n</li>\n</ul>\n<hr>\n<p><strong>[1] sqlite 使用</strong></p>\n<p>1-1 下载dll 和 tools 2个zip</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627100739631.png\" alt=\"image-20240627100739631\"></p>\n<p>1-2  将解压后的文件，放到系统环境变量可以识别的Path下面</p>\n<img src=\"/images/Langchain系列-20-与SQL数据库进行聊天.assets/image-20240627100747184.png\" alt=\"image-20240627100747184\" style=\"zoom:33%;\" />\n\n<p>1-3 任意打开命令行，验证一下，运行： sqlite3</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627100828820.png\" alt=\"image-20240627100828820\"></p>\n<p>1-4 模拟数据：Chinook Database</p>\n<p><a href=\"https://github.com/lerocha/chinook-database\">https://github.com/lerocha/chinook-database</a></p>\n<p>Chinook是一个适用于SQL Server、Oracle、MySQL等的示例数据库。Chinook数据库是Northwind数据库的替代品，非常适合用于演示和测试针对单个和多个数据库服务器的ORM工具。</p>\n<p>我们使用这里面的数据来练习~</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101004596.png\" alt=\"image-20240627101004596\"></p>\n<p><a href=\"https://github.com/lerocha/chinook-database/blob/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\">https://github.com/lerocha/chinook-database/blob/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql</a></p>\n<p>1-5 安装数据库</p>\n<p><strong>新建数据库</strong></p>\n<blockquote>\n<p>sqlite3 chinook.db</p>\n</blockquote>\n<p><strong>将Chinook_Sqlite.sql 放到包含 chinook.db的同级目录</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101023676.png\" alt=\"image-20240627101023676\"></p>\n<p><strong>执行sql命令</strong></p>\n<blockquote>\n<p>.read Chinook_Sqlite.sql</p>\n</blockquote>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101040258.png\" alt=\"image-20240627101040258\"></p>\n<p><strong>测试数据库</strong></p>\n<blockquote>\n<p>SELECT * FROM album;</p>\n</blockquote>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101051529.png\" alt=\"image-20240627101051529\"></p>\n<p><strong>【2】Mysql 使用（假设你已经安装好了Mysql）</strong></p>\n<p><strong>2-1 搜索</strong>中输出Mysql, 找到MySQL xx Command Line Client</p>\n<p>2-2 打开 mysql（左键单击 2-1 中应用）</p>\n<p>输入密码后进入mysql</p>\n<p>2-3 导入测试数据</p>\n<p>CREATE DATABASE chinook;</p>\n<p>USE chinook;</p>\n<p>SOURCE D:\\LLM\\my_projects\\leanr_django_rag\\sql\\Chinook_MySql.sql</p>\n<p>2-4 验证</p>\n<p>SELECT * FROM album LIMIT 10;</p>\n<hr>\n<p>安装 pip install langchain mysql-connector-python</p>\n<hr>\n<p><strong>[3] Text to Sql in chain</strong></p>\n<ul>\n<li>数据库的schema信息（表格信息）</li>\n<li>文本转SQL 查询语句</li>\n<li>Sql 查询</li>\n</ul>\n<hr>\n<p><strong>3-1 数据库的schema信息（表格信息）</strong></p>\n<p>通过get_table_info 获得数据库表格信息（schema）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># SQLite 配置 (.py 跟 chinook.db 在一个目录)</span></span><br><span class=\"line\">sqlite_uri = <span class=\"string\">&#x27;sqlite:///./chinook.db&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">sqlite_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">sqlite_db_schema = sqlite_db.get_table_info()</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># MySQL 配置</span></span><br><span class=\"line\">mysql_uri = <span class=\"string\">&#x27;mysql+mysqlconnector://root:admin@localhost:3306/chinook&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">mysql_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">mysql_db_schema = mysql_db.get_table_info()</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>schema</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">CREATE TABLE <span class=\"string\">&quot;Album&quot;</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;AlbumId&quot;</span> INTEGER NOT NULL, </span><br><span class=\"line\">\t<span class=\"string\">&quot;Title&quot;</span> NVARCHAR(<span class=\"number\">160</span>) NOT NULL, </span><br><span class=\"line\">\t<span class=\"string\">&quot;ArtistId&quot;</span> INTEGER NOT NULL, </span><br><span class=\"line\">\tPRIMARY KEY (<span class=\"string\">&quot;AlbumId&quot;</span>), </span><br><span class=\"line\">\tFOREIGN KEY(<span class=\"string\">&quot;ArtistId&quot;</span>) REFERENCES <span class=\"string\">&quot;Artist&quot;</span> (<span class=\"string\">&quot;ArtistId&quot;</span>)</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">/*</span><br><span class=\"line\"><span class=\"number\">3</span> rows <span class=\"keyword\">from</span> Album table:</span><br><span class=\"line\">AlbumId\tTitle\tArtistId</span><br><span class=\"line\"><span class=\"number\">1</span>\tFor Those About To Rock We Salute You\t<span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span>\tBalls to the Wall\t<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">3</span>\tRestless <span class=\"keyword\">and</span> Wild\t<span class=\"number\">2</span></span><br><span class=\"line\">*/</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n<p><strong>3-2 文本→ Sql chain</strong></p>\n<p>实现数据库内容访问接口</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># SQLite 配置 (.py 跟 chinook.db 在一个目录)</span></span><br><span class=\"line\">sqlite_uri = <span class=\"string\">&#x27;sqlite:///./chinook.db&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">sqlite_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">sqlite_db_schema = sqlite_db.get_table_info()</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用mysql</span></span><br><span class=\"line\">db = sqlite_db</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试一下</span></span><br><span class=\"line\">res = db.run(<span class=\"string\">&#x27;SELECT COUNT(*) FROM Album;&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 运行查询命令</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">run_query</span>(<span class=\"params\">query</span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> db</span><br><span class=\"line\">    res = db.run(query)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># 获得schema</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_schema</span>(<span class=\"params\">_</span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> db</span><br><span class=\"line\">    schema = db.get_table_info()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> schema</span><br></pre></td></tr></table></figure>\n\n<p>用质谱清言Glm4 作为llm</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Based on the table schema below, write a SQL query that would answer the user&#x27;s question:</span></span><br><span class=\"line\"><span class=\"string\">&#123;schema&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">Return SQL Query Only, do not explain:&quot;&quot;&quot;</span></span><br><span class=\"line\">prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">zhipuai_key = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">generate_token</span>(<span class=\"params\">apiKey: <span class=\"built_in\">str</span>, exp_seconds: <span class=\"built_in\">int</span></span>):</span><br><span class=\"line\">    <span class=\"built_in\">id</span>, secret = apiKey.split(<span class=\"string\">&quot;.&quot;</span>)</span><br><span class=\"line\">    payload = &#123;</span><br><span class=\"line\">        <span class=\"string\">&quot;api_key&quot;</span>: <span class=\"built_in\">id</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;exp&quot;</span>: <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time.time()) * <span class=\"number\">1000</span>) + exp_seconds * <span class=\"number\">1000</span>,</span><br><span class=\"line\">        <span class=\"string\">&quot;timestamp&quot;</span>: <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time.time()) * <span class=\"number\">1000</span>),</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> jwt.encode(</span><br><span class=\"line\">        payload,</span><br><span class=\"line\">        secret,</span><br><span class=\"line\">        algorithm=<span class=\"string\">&quot;HS256&quot;</span>,</span><br><span class=\"line\">        headers=&#123;<span class=\"string\">&quot;alg&quot;</span>: <span class=\"string\">&quot;HS256&quot;</span>, <span class=\"string\">&quot;sign_type&quot;</span>: <span class=\"string\">&quot;SIGN&quot;</span>&#125;,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">chat = ChatOpenAI(</span><br><span class=\"line\">    model_name=<span class=\"string\">&quot;gLm-4&quot;</span>,</span><br><span class=\"line\">    openai_api_base=<span class=\"string\">&quot;https://open.bigmodel.cn/api/paas/v4&quot;</span>,</span><br><span class=\"line\">    openai_api_key=generate_token(zhipuai_key, exp_seconds=<span class=\"number\">60</span>*<span class=\"number\">10</span>),</span><br><span class=\"line\">    streaming=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    verbose=<span class=\"literal\">True</span>,</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">text_2_sql_chain = (</span><br><span class=\"line\">        RunnablePassthrough.assign(schema=get_schema)</span><br><span class=\"line\">        | prompt</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">        | StrOutputParser()</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">user_question = <span class=\"string\">&#x27;how many albums are there in the database?&#x27;</span></span><br><span class=\"line\">res = text_2_sql_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: user_question&#125;)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">&#123;<span class=\"string\">&quot;question&quot;</span>: user_question&#125; -&gt;&#123;<span class=\"string\">&quot;question&quot;</span>: user_question,<span class=\"string\">&#x27;schema&#x27;</span>=<span class=\"string\">&#x27;...&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>\n\n<p>输出</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101204132.png\" alt=\"image-20240627101204132\"></p>\n<p><strong>3-3 文本→ Sql →sql执行→llm总结</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">template = <span class=\"string\">&quot;&quot;&quot;Based on the table schema below, question, sql query, and sql response, write a natural language response:</span></span><br><span class=\"line\"><span class=\"string\">&#123;schema&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">SQL Query: &#123;query&#125;</span></span><br><span class=\"line\"><span class=\"string\">SQL Response: &#123;response&#125;&quot;&quot;&quot;</span></span><br><span class=\"line\">prompt_response = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">full_chain = (</span><br><span class=\"line\">        RunnablePassthrough.assign(query=text_2_sql_chain).assign(</span><br><span class=\"line\">            schema=get_schema,</span><br><span class=\"line\">            response=<span class=\"keyword\">lambda</span> x: run_query(x[<span class=\"string\">&quot;query&quot;</span>]),</span><br><span class=\"line\">        )</span><br><span class=\"line\">        | prompt_response</span><br><span class=\"line\">        | chat</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">user_question = <span class=\"string\">&#x27;how many albums are there in the database?&#x27;</span></span><br><span class=\"line\">res = full_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: user_question&#125;)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">&#123;<span class=\"string\">&quot;question&quot;</span>: user_question&#125; -&gt;</span><br><span class=\"line\">  &#123;<span class=\"string\">&quot;question&quot;</span>: user_question,</span><br><span class=\"line\">   <span class=\"string\">&#x27;query&#x27;</span>:<span class=\"string\">&#x27;SELECT COUNT(*) FROM Album;&#x27;</span>，</span><br><span class=\"line\">    <span class=\"string\">&#x27;schema&#x27;</span>:<span class=\"string\">&#x27;数据库的表结构...&#x27;</span>,</span><br><span class=\"line\">      <span class=\"string\">&#x27;response&#x27;</span>:<span class=\"string\">&#x27;run_query 的调用结果&#x27;</span>&#125;  -&gt; prompt_response</span><br></pre></td></tr></table></figure>\n\n<p>结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&#x27;There are 347 albums in the database.&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<hr>\n<p><strong>[4] Agent 调用</strong></p>\n<p>描述工具</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@tool</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">run_query</span>(<span class=\"params\">query</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Accept an SQL command and execute the command in mojuan SQL database.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> db</span><br><span class=\"line\">    res = db.run(query)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@tool</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_schema</span>(<span class=\"params\">nothing</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    return the schema of mojuan SQL database.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> db</span><br><span class=\"line\">    schema = db.get_table_info()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> schema</span><br></pre></td></tr></table></figure>\n\n<p>Agent 核心定义</p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101226358.png\" alt=\"image-20240627101226358\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">tools=[run_query,get_schema]</span><br><span class=\"line\"></span><br><span class=\"line\">prompt=hub.pull(<span class=\"string\">&quot;hwchase17/openai-functions-agent&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">app = chat_agent_executor.create_tool_calling_executor(model, tools)</span><br><span class=\"line\"><span class=\"comment\"># inputs = &#123;&quot;messages&quot;: [HumanMessage(content=&quot;how many album are there in the mojuan database?&quot;)]&#125;</span></span><br><span class=\"line\">inputs = &#123;<span class=\"string\">&quot;messages&quot;</span>: [HumanMessage(content=<span class=\"string\">&quot;how many album are there in the mojuan database? you must check schema of mojuan first&quot;</span>)]&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> app.stream(inputs):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"built_in\">list</span>(s.values())[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;----&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>结果</strong></p>\n<p><img src=\"/images/Langchain%E7%B3%BB%E5%88%97-20-%E4%B8%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E8%81%8A%E5%A4%A9.assets/image-20240627101242033.png\" alt=\"image-20240627101242033\"></p>\n<p><strong>how many album are there in the mojuan database?</strong></p>\n<p>→ 直接调用run_query， 生成的sql 命令有错：’SELECT COUNT(*) FROM <strong>albums</strong>‘</p>\n<p><strong>how many album are there in the mojuan database? you must check schema of mojuan first</strong></p>\n<p>→先调用get_schema 再调用 run_query，生成的sql 命令 <strong>正确</strong></p>\n<hr>\n<p>代码</p>\n<p>chain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.utilities <span class=\"keyword\">import</span> SQLDatabase</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.output_parsers <span class=\"keyword\">import</span> StrOutputParser</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.runnables <span class=\"keyword\">import</span> RunnablePassthrough</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_openai <span class=\"keyword\">import</span> ChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">import</span> jwt, time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># SQLite 配置 (.py 跟 chinook.db 在一个目录)</span></span><br><span class=\"line\">    sqlite_uri = <span class=\"string\">&#x27;sqlite:///./chinook.db&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">    sqlite_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">    sqlite_db_schema = sqlite_db.get_table_info()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># MySQL 配置</span></span><br><span class=\"line\">    mysql_uri = <span class=\"string\">&#x27;mysql+mysqlconnector://root:admin@localhost:3306/chinook&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">    mysql_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">    mysql_db_schema = mysql_db.get_table_info()</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;Based on the table schema below, write a SQL query that would answer the user&#x27;s question:</span></span><br><span class=\"line\"><span class=\"string\">    &#123;schema&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">    Return SQL Query Only, do not explain:&quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 选择你要测试的数据库</span></span><br><span class=\"line\">    <span class=\"comment\"># 使用sqlite</span></span><br><span class=\"line\">    <span class=\"comment\">#db = sqlite_db</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 使用mysql</span></span><br><span class=\"line\">    db = mysql_db</span><br><span class=\"line\"></span><br><span class=\"line\">    res = db.run(<span class=\"string\">&#x27;SELECT COUNT(*) FROM Album;&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">run_query</span>(<span class=\"params\">query</span>):</span><br><span class=\"line\">        <span class=\"keyword\">global</span> db</span><br><span class=\"line\">        res = db.run(query)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_schema</span>(<span class=\"params\">_</span>):</span><br><span class=\"line\">        <span class=\"keyword\">global</span> db</span><br><span class=\"line\">        schema = db.get_table_info()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> schema</span><br><span class=\"line\"></span><br><span class=\"line\">    zhipuai_key = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">generate_token</span>(<span class=\"params\">apiKey: <span class=\"built_in\">str</span>, exp_seconds: <span class=\"built_in\">int</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">id</span>, secret = apiKey.split(<span class=\"string\">&quot;.&quot;</span>)</span><br><span class=\"line\">        payload = &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;api_key&quot;</span>: <span class=\"built_in\">id</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;exp&quot;</span>: <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time.time()) * <span class=\"number\">1000</span>) + exp_seconds * <span class=\"number\">1000</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;timestamp&quot;</span>: <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time.time()) * <span class=\"number\">1000</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> jwt.encode(</span><br><span class=\"line\">            payload,</span><br><span class=\"line\">            secret,</span><br><span class=\"line\">            algorithm=<span class=\"string\">&quot;HS256&quot;</span>,</span><br><span class=\"line\">            headers=&#123;<span class=\"string\">&quot;alg&quot;</span>: <span class=\"string\">&quot;HS256&quot;</span>, <span class=\"string\">&quot;sign_type&quot;</span>: <span class=\"string\">&quot;SIGN&quot;</span>&#125;,</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    chat = ChatOpenAI(</span><br><span class=\"line\">        model_name=<span class=\"string\">&quot;gLm-4&quot;</span>,</span><br><span class=\"line\">        openai_api_base=<span class=\"string\">&quot;https://open.bigmodel.cn/api/paas/v4&quot;</span>,</span><br><span class=\"line\">        openai_api_key=generate_token(zhipuai_key, exp_seconds=<span class=\"number\">60</span>*<span class=\"number\">10</span>),</span><br><span class=\"line\">        streaming=<span class=\"literal\">False</span>,</span><br><span class=\"line\">        verbose=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    text_2_sql_chain = (</span><br><span class=\"line\">            RunnablePassthrough.assign(schema=get_schema)</span><br><span class=\"line\">            | prompt</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">            | StrOutputParser()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 测试</span></span><br><span class=\"line\">    user_question = <span class=\"string\">&#x27;how many albums are there in the database?&#x27;</span></span><br><span class=\"line\">    res = text_2_sql_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: user_question&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    template = <span class=\"string\">&quot;&quot;&quot;Based on the table schema below, question, sql query, and sql response, write a natural language response:</span></span><br><span class=\"line\"><span class=\"string\">    &#123;schema&#125;</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Question: &#123;question&#125;</span></span><br><span class=\"line\"><span class=\"string\">    SQL Query: &#123;query&#125;</span></span><br><span class=\"line\"><span class=\"string\">    SQL Response: &#123;response&#125;&quot;&quot;&quot;</span></span><br><span class=\"line\">    prompt_response = ChatPromptTemplate.from_template(template)</span><br><span class=\"line\"></span><br><span class=\"line\">    full_chain = (</span><br><span class=\"line\">            RunnablePassthrough.assign(query=text_2_sql_chain).assign(</span><br><span class=\"line\">                schema=get_schema,</span><br><span class=\"line\">                response=<span class=\"keyword\">lambda</span> x: run_query(x[<span class=\"string\">&quot;query&quot;</span>]),</span><br><span class=\"line\">            )</span><br><span class=\"line\">            | prompt_response</span><br><span class=\"line\">            | chat</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    user_question = <span class=\"string\">&#x27;how many albums are there in the database?&#x27;</span></span><br><span class=\"line\">    res = full_chain.invoke(&#123;<span class=\"string\">&quot;question&quot;</span>: user_question&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>Agent</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain <span class=\"keyword\">import</span> hub</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.agents <span class=\"keyword\">import</span> AgentExecutor</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.messages <span class=\"keyword\">import</span> HumanMessage</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.prompts <span class=\"keyword\">import</span> ChatPromptTemplate</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_openai <span class=\"keyword\">import</span> ChatOpenAI</span><br><span class=\"line\"><span class=\"keyword\">import</span> jwt, time</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_core.tools <span class=\"keyword\">import</span> tool</span><br><span class=\"line\"><span class=\"keyword\">from</span> langgraph.prebuilt <span class=\"keyword\">import</span> chat_agent_executor</span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain_community.utilities <span class=\"keyword\">import</span> SQLDatabase</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 数据库配置</span></span><br><span class=\"line\">    <span class=\"comment\"># SQLite 配置 (.py 跟 chinook.db 在一个目录)</span></span><br><span class=\"line\">    sqlite_uri = <span class=\"string\">&#x27;sqlite:///./chinook.db&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">    sqlite_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">    sqlite_db_schema = sqlite_db.get_table_info()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># MySQL 配置</span></span><br><span class=\"line\">    mysql_uri = <span class=\"string\">&#x27;mysql+mysqlconnector://root:admin@localhost:3306/chinook&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 获得 数据库中表的信息</span></span><br><span class=\"line\">    mysql_db = SQLDatabase.from_uri(sqlite_uri)</span><br><span class=\"line\">    mysql_db_schema = mysql_db.get_table_info()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 设置你要测试的数据库</span></span><br><span class=\"line\">    db = sqlite_db</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @tool</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">run_query</span>(<span class=\"params\">query</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        Accept an SQL command and execute the command in mojuan SQL database.</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">global</span> db</span><br><span class=\"line\">        res = db.run(query)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @tool</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_schema</span>(<span class=\"params\">nothing</span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        return the schema of mojuan SQL database.</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">global</span> db</span><br><span class=\"line\">        schema = db.get_table_info()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> schema</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    zhipuai_key = os.getenv(<span class=\"string\">&#x27;MY_ZHIPUAI_API_KEY&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">generate_token</span>(<span class=\"params\">apiKey: <span class=\"built_in\">str</span>, exp_seconds: <span class=\"built_in\">int</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">id</span>, secret = apiKey.split(<span class=\"string\">&quot;.&quot;</span>)</span><br><span class=\"line\">        payload = &#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;api_key&quot;</span>: <span class=\"built_in\">id</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;exp&quot;</span>: <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time.time()) * <span class=\"number\">1000</span>) + exp_seconds * <span class=\"number\">1000</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;timestamp&quot;</span>: <span class=\"built_in\">int</span>(<span class=\"built_in\">round</span>(time.time()) * <span class=\"number\">1000</span>),</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> jwt.encode(</span><br><span class=\"line\">            payload,</span><br><span class=\"line\">            secret,</span><br><span class=\"line\">            algorithm=<span class=\"string\">&quot;HS256&quot;</span>,</span><br><span class=\"line\">            headers=&#123;<span class=\"string\">&quot;alg&quot;</span>: <span class=\"string\">&quot;HS256&quot;</span>, <span class=\"string\">&quot;sign_type&quot;</span>: <span class=\"string\">&quot;SIGN&quot;</span>&#125;,</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    model = ChatOpenAI(</span><br><span class=\"line\">        model_name=<span class=\"string\">&quot;gLm-4&quot;</span>,</span><br><span class=\"line\">        openai_api_base=<span class=\"string\">&quot;https://open.bigmodel.cn/api/paas/v4&quot;</span>,</span><br><span class=\"line\">        openai_api_key=generate_token(zhipuai_key, exp_seconds=<span class=\"number\">60</span>*<span class=\"number\">5</span>),</span><br><span class=\"line\">        streaming=<span class=\"literal\">False</span>,</span><br><span class=\"line\">        verbose=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    tools=[run_query,get_schema]</span><br><span class=\"line\"></span><br><span class=\"line\">    prompt=hub.pull(<span class=\"string\">&quot;hwchase17/openai-functions-agent&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    app = chat_agent_executor.create_tool_calling_executor(model, tools)</span><br><span class=\"line\">    <span class=\"comment\"># inputs = &#123;&quot;messages&quot;: [HumanMessage(content=&quot;how many album are there in the mojuan database?&quot;)]&#125;</span></span><br><span class=\"line\">    inputs = &#123;<span class=\"string\">&quot;messages&quot;</span>: [HumanMessage(content=<span class=\"string\">&quot;How many albums are there in the mojuan database? &quot;</span>)]&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> app.stream(inputs):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"built_in\">list</span>(s.values())[<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;----&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>","tags":["langchain"]},{"title":"大白话系列之JavaScript原型及面向对象","url":"/forward/fc818087.html","content":"<h1 id=\"images-大白话系列之JavaScript原型及面向对象\"><a href=\"#images-大白话系列之JavaScript原型及面向对象\" class=\"headerlink\" title=\"/images/大白话系列之JavaScript原型及面向对象\"></a>/images/大白话系列之JavaScript原型及面向对象</h1><h2 id=\"对象\"><a href=\"#对象\" class=\"headerlink\" title=\"对象\"></a>对象</h2><h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>一开始就和Java一样整个new</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 1.创建一个空的对象</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Object</span>()</span><br><span class=\"line\">obj1.<span class=\"property\">name</span> = <span class=\"string\">&quot;xiaoyu&quot;</span></span><br><span class=\"line\">obj1.<span class=\"property\">age</span> = <span class=\"number\">18</span></span><br><span class=\"line\">obj1.<span class=\"property\">height</span> = <span class=\"number\">1.88</span></span><br><span class=\"line\">obj1.<span class=\"property\">eating</span> = <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">  <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;在吃东西&quot;</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>后来很多开发者为了方便期间，都是直接通过字面量的形式来创建对象：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">var obj2 = &#123;</span><br><span class=\"line\">  name: &quot;kobe&quot;,</span><br><span class=\"line\">  age: 40,</span><br><span class=\"line\">  height: 1.98,</span><br><span class=\"line\">  running: function() &#123;</span><br><span class=\"line\">    console.log(this.name + &quot;在跑步&quot;)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"对象属性描述\"><a href=\"#对象属性描述\" class=\"headerlink\" title=\"对象属性描述\"></a>对象属性描述</h3><p>如果使用字面量形式进行声明对象属性，我们就失去了对对象属性的精准控制。</p>\n<p>如：</p>\n<ul>\n<li>这个属性我能不能delete</li>\n<li>这个属性能不能在for in的时候被遍历</li>\n</ul>\n<p>为了实现如此控制我们可以使用<strong>Object.defineProperty</strong>来对属性进行添加或者修改</p>\n<p>而数据属性描述又分为两类</p>\n<ul>\n<li><p>数据属性描述</p>\n<ul>\n<li><p>[[Configurable]]：表示属性是否可以通过delete删除属性，是否可以修改它的特性。</p>\n<ul>\n<li>当我们在一个对象上定义了某个属性时，这个属性的Configurable为true</li>\n<li>当我们通过属性描述符（Object.defineProperty）定义一个属性时，这个值为false</li>\n</ul>\n</li>\n<li><p>[[Enumerable]]：表示属性是否可以通过for-in或者Object.keys()返回该属性；</p>\n<ul>\n<li>当我们直接在一个对象上定义某个属性时，这个属性的[[Enumerable]]为true；</li>\n<li>当我们通过属性描述符定义一个属性时，这个属性的[[Enumerable]]默认为false；</li>\n</ul>\n</li>\n<li><p>[[Writable]]：表示是否可以修改属性的值；</p>\n<ul>\n<li>当我们直接在一个对象上定义某个属性时，这个属性的[[Writable]]为true；</li>\n<li>当我们通过属性描述符定义一个属性时，这个属性的[[Writable]]默认为false；</li>\n</ul>\n</li>\n<li><p>[[value]]：属性的value值，读取属性时会返回该值，修改属性时，会对其进行修改；</p>\n<ul>\n<li>默认情况下这个值是undefined；</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>存取属性描述</p>\n<ul>\n<li>[[Configurable]] [[Enumerable]] 这两个似乎可以相互转换，功能是一样的。</li>\n<li>[[get]]：获取属性时会执行的函数。默认为undefined</li>\n<li>[[set]]：设置属性时会执行的函数。默认为undefined</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: <span class=\"number\">18</span>,</span><br><span class=\"line\">  <span class=\"attr\">height</span>: <span class=\"number\">1.88</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 默认是可以配置</span></span><br><span class=\"line\"><span class=\"comment\">// delete obj.name</span></span><br><span class=\"line\"><span class=\"comment\">// console.log(obj)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> key <span class=\"keyword\">in</span> obj) &#123;</span><br><span class=\"line\">  <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(key)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Object</span>.<span class=\"title function_\">keys</span>(obj))</span><br><span class=\"line\"></span><br><span class=\"line\">obj.<span class=\"property\">name</span> = <span class=\"string\">&quot;kobe&quot;</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj)\t\t</span><br></pre></td></tr></table></figure>\n\n\n\n<p>如果自己定义属性：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">// &quot;use strict&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">var obj = &#123;</span><br><span class=\"line\">  name: &quot;xiaoyu&quot;,</span><br><span class=\"line\">  age: 18,</span><br><span class=\"line\">  height: 1.88</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// 自己定义的属性</span><br><span class=\"line\">Object.defineProperty(obj, &quot;address&quot;, &#123;</span><br><span class=\"line\">  // configurable: false,</span><br><span class=\"line\">  // enumerable: false,</span><br><span class=\"line\">  // writable: false,</span><br><span class=\"line\">  value: &quot;北京市&quot;</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">// 1.测试enumerable为false</span><br><span class=\"line\">// 这种方式访问时看不到属性</span><br><span class=\"line\">console.log(obj)</span><br><span class=\"line\">console.log(Object.keys(obj))</span><br><span class=\"line\">for (var key in obj) &#123;</span><br><span class=\"line\">  console.log(key)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// 这种方式是可以访问的</span><br><span class=\"line\">console.log(&quot;address&quot; in obj)</span><br><span class=\"line\">console.log(obj.hasOwnProperty(&#x27;address&#x27;))</span><br><span class=\"line\">console.log(obj.address)</span><br><span class=\"line\"></span><br><span class=\"line\">// 2.测试writable, 修改address的值</span><br><span class=\"line\">obj.address = &quot;广州市&quot;</span><br><span class=\"line\">// 北京市, 并且在严格模式下会报错</span><br><span class=\"line\">console.log(obj.address)</span><br><span class=\"line\"></span><br><span class=\"line\">// 3.测试configurable</span><br><span class=\"line\">// 不可以删除</span><br><span class=\"line\">delete obj.address</span><br><span class=\"line\">// 不可以重新修改</span><br><span class=\"line\">Object.defineProperty(obj, &#x27;address&#x27;, &#123;</span><br><span class=\"line\">  configurable: true</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">console.log(obj.address)</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<p>…… 省略一把</p>\n<h2 id=\"构造函数创建对象\"><a href=\"#构造函数创建对象\" class=\"headerlink\" title=\"构造函数创建对象\"></a>构造函数创建对象</h2><p>什么是构造函数？</p>\n<ul>\n<li>就是在我们创建对象时会调用的函数。</li>\n<li>在其他面向的编程语言里面，构造函数是存在于类中的一个方法，称之为构造方法；</li>\n<li>但是JavaScript中的构造函数有点不太一样</li>\n</ul>\n<p>构造函数在js中就是一个普通函数，和别的函数没有区别</p>\n<p><strong>被new关键词调用的函数，就是构造函数</strong></p>\n<h3 id=\"什么是new？\"><a href=\"#什么是new？\" class=\"headerlink\" title=\"什么是new？\"></a>什么是new？</h3><p>如果一个函数被new操作符调用了就会有如下操作：</p>\n<ol>\n<li>内存中创建一个新的对象（空对象）</li>\n<li>这个对象内部的Property属性会被赋值为该函数的Property属性。</li>\n<li>构造函数内部的this会指向创建出来的新对象。</li>\n<li>执行函数的内部代码也就是函数体代码</li>\n<li>如果构造函数没有返回非空对象，那么返回新创造的对象。</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">Person</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"><span class=\"keyword\">var</span> p2 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">Person</span>(<span class=\"params\">name, age, height, address</span>) &#123;</span><br><span class=\"line\">  <span class=\"variable language_\">this</span>.<span class=\"property\">name</span> = name</span><br><span class=\"line\">  <span class=\"variable language_\">this</span>.<span class=\"property\">age</span> = age</span><br><span class=\"line\">  <span class=\"variable language_\">this</span>.<span class=\"property\">height</span> = height</span><br><span class=\"line\">  <span class=\"variable language_\">this</span>.<span class=\"property\">address</span> = address</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"variable language_\">this</span>.<span class=\"property\">eating</span> = <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;在吃东西~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"variable language_\">this</span>.<span class=\"property\">running</span> = <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;在跑步~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这个构造函数可以确保我们的对象是有Person的类型的（实际是constructor的属性，这个我们后续再探讨）；</p>\n<h2 id=\"认识原型\"><a href=\"#认识原型\" class=\"headerlink\" title=\"认识原型\"></a>认识原型</h2><p>JavaScript当中每个对象都有一个特殊的内置属性 [[prototype]]，这个特殊的对象可以指向另外一个对象。</p>\n<ul>\n<li>当我们通过引用对象的属性key来获取一个value时，它会触发 [[Get]]的操作；</li>\n<li>这个操作会先检查是否有对应的属性，有就用</li>\n<li>如果对象中没有改属性，那么会访问对象[[prototype]]内置属性指向的对象上的属性；</li>\n<li>这个 [[prototype]] 我们通常会将其称之为隐式原型；</li>\n</ul>\n<p>那么如果通过字面量直接创建一个对象，这个对象也会有这样的属性吗？如果有，应该如何获取这个属性呢？</p>\n<p>答案是有的</p>\n<ul>\n<li><p>方式一：通过对象的 <code>__proto__</code> 属性可以获取到（但是这个是早期浏览器自己添加的，存在一定的兼容性问题）；</p>\n</li>\n<li><p>方式二：通过 <code>Object.getPrototypeOf</code> 方法可以获取到；</p>\n</li>\n</ul>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 方式一: __proto__(有浏览器兼容问题)</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">__proto__</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 方式二: Object.getPrototypeOf</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Object</span>.<span class=\"title function_\">getPrototypeOf</span>(obj))</span><br></pre></td></tr></table></figure>\n\n\n\n<p>那么我们就可以进行如下的测试了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 定义一个obj对象</span><br><span class=\"line\">var obj = &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// 直接给对象添加address属性</span><br><span class=\"line\">// obj.address = &quot;北京市&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">// 直接给隐式原型上添加address属性</span><br><span class=\"line\">// 给__proto__上添加address属性</span><br><span class=\"line\">obj.__proto__.address = &quot;广州市&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">// 通过Object.setPrototypeOf来设置隐式原型</span><br><span class=\"line\">Object.setPrototypeOf(obj, &#123; address: &quot;上海市&quot;, name: &quot;setPrototypeOf&quot; &#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">console.log(obj.address)</span><br></pre></td></tr></table></figure>\n\n<p>结论，我们是可以直接这样子去添加的。</p>\n<h2 id=\"函数的原型\"><a href=\"#函数的原型\" class=\"headerlink\" title=\"函数的原型\"></a>函数的原型</h2><p>我们前面说了，通过构造函数创建对象时，对象的Property会是构造函数的Property</p>\n<h3 id=\"函数的prototype\"><a href=\"#函数的prototype\" class=\"headerlink\" title=\"函数的prototype\"></a>函数的prototype</h3><p>这里我们又要引入一个新的概念：<strong>所有的函数</strong>都有一个prototype的属性：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">foo</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 所有的函数都有一个属性, 名字是 prototype </span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(foo.<span class=\"property\"><span class=\"keyword\">prototype</span></span>)</span><br></pre></td></tr></table></figure>\n\n<p>不是因为函数是一个对象所以有prototype属性。</p>\n<p>而是因为是函数才有prototype属性。</p>\n<p><strong>对象没有prototype属性，有的是</strong> __proto__这个属性</p>\n<p>我们前面讲过new关键字的步骤如下：</p>\n<ul>\n<li>1.在内存中创建一个新的对象（空对象）；</li>\n<li>2.这个对象内部的[[prototype]]属性会被赋值为该构造函数的prototype属性；（后面详细讲）；</li>\n<li>3.构造函数内部的this，会指向创建出来的新对象；</li>\n<li>4.执行函数的内部代码（函数体代码）；</li>\n<li>5.如果构造函数没有返回非空对象，则返回创建出来的新对象；</li>\n</ul>\n<p>我们将重心放到步骤一和二中：</p>\n<ul>\n<li>在内存中创建一个对象；</li>\n<li>将对象的[[prototype]]属性赋值为该构造函数的prototype属性；</li>\n</ul>\n<p>那就意味着：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">Person</span>(<span class=\"params\"></span>)&#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> a = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 有一步操作是</span></span><br><span class=\"line\"></span><br><span class=\"line\">a.<span class=\"property\">__proto</span> = <span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<p>那么也就意味着我们通过Person构造函数创建出来的所有对象的[[prototype]]属性都指向Person.prototype：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">Person</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"><span class=\"keyword\">var</span> p2 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"><span class=\"keyword\">var</span> p3 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1.<span class=\"property\">__proto__</span> === p2.<span class=\"property\">__proto__</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1.<span class=\"property\">__proto__</span> === <span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>)</span><br></pre></td></tr></table></figure>\n\n\n\n<p>那么其实就是..Person函数有一个prototype属性指向 Person的原型。</p>\n<p>然后对象创建出来以后..对象的 __proto__和指向和Person函数一样。</p>\n<p><img src=\"/images/%E5%A4%A7%E7%99%BD%E8%AF%9D%E7%B3%BB%E5%88%97%E4%B9%8BJavaScript%E5%8E%9F%E5%9E%8B%E5%8F%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.assets/image-20240906162418938.png\" alt=\"image-20240906162418938\"></p>\n<p>那么如果在Person的prototype属性中创建属性，那么p的对象能不能访问到？</p>\n<p>当然可以</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">Person</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>.<span class=\"property\">name</span> = <span class=\"string\">&quot;xiaoyu&quot;</span></span><br><span class=\"line\"><span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>.<span class=\"property\">age</span> = <span class=\"number\">18</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"><span class=\"keyword\">var</span> p2 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1.<span class=\"property\">name</span>, p1.<span class=\"property\">age</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p2.<span class=\"property\">name</span>, p2.<span class=\"property\">age</span>)</span><br></pre></td></tr></table></figure>\n\n<p>值得一提的是，如果你中途来一个p1.name = xxx 那么此时会在你p1的对象里面创建一个name，并不会改变Person中的值</p>\n<h3 id=\"constructor属性\"><a href=\"#constructor属性\" class=\"headerlink\" title=\"constructor属性\"></a>constructor属性</h3><p>事实上原型对象（就是指函数的prototype属性指向的原型对象）上面是有一个属性：constructor。</p>\n<p>默认情况下原型上都会添加一个属性叫做constructor，这个constructor指向当前的函数对象（<strong>这里指的是函数的prototype指向的对象中的constructor的值又是该函数本身，也就是Person函数的prototype对象中的constructor的值指向的是Person函数【函数tm的在js的内存中是对象形式存在所以妈的这句话就很拗口】</strong>）；</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>.<span class=\"property\">constructor</span>) <span class=\"comment\">// [Function: Person]</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1.<span class=\"property\">__proto__</span>.<span class=\"property\">constructor</span>) <span class=\"comment\">// [Function: Person]</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1.<span class=\"property\">__proto__</span>.<span class=\"property\">constructor</span>.<span class=\"property\">name</span>) <span class=\"comment\">// Person</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"重写原型\"><a href=\"#重写原型\" class=\"headerlink\" title=\"重写原型\"></a>重写原型</h3><p>如果我们需要在原型上添加很多很多属性，通常就重写原型了。</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">Person</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span> = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: <span class=\"number\">18</span>,</span><br><span class=\"line\">  <span class=\"attr\">eating</span>: <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;在吃东西~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<p>我们说过..每创建一个函数就会生成一个函数对应的原型对象。而原型对象的constructor也会自动获取到函数对象（这里的函数对象其实也就是Person Fuction哈）。</p>\n<p>但是我们如果重写了函数的prototype，那么这个prototype就会默认指向Object构造函数了（Object Function）。</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>.<span class=\"property\">constructor</span>) <span class=\"comment\">// [Function: Object]</span></span><br><span class=\"line\"><span class=\"comment\">// 为什么是Object呢? 因为对象的字面量是由Object函数产生的</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;&#125;</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">constructor</span>) <span class=\"comment\">// // [Function: Object]</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p>如果要原型constructor指向回来，可以如下</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Person.prototype = &#123;</span><br><span class=\"line\">  constructor: Person,</span><br><span class=\"line\">  name: &quot;xiaoyu&quot;,</span><br><span class=\"line\">  age: 18,</span><br><span class=\"line\">  eating: function() &#123;</span><br><span class=\"line\">    console.log(this.name + &quot;在吃东西~&quot;)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>除了constructor属性一些特性被默认开启了如</p>\n<p>[[Enumerable]]为true了。</p>\n<p>不然就只能用Object.defineProperty啦</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span> = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: <span class=\"number\">18</span>,</span><br><span class=\"line\">  <span class=\"attr\">eating</span>: <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;在吃东西~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Object</span>.<span class=\"title function_\">defineProperty</span>(<span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>, <span class=\"string\">&quot;constructor&quot;</span>, &#123;</span><br><span class=\"line\">  <span class=\"attr\">enumerable</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">  <span class=\"attr\">value</span>: <span class=\"title class_\">Person</span></span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<h2 id=\"原型链\"><a href=\"#原型链\" class=\"headerlink\" title=\"原型链\"></a>原型链</h2><p>在真正实现继承之前，我们先来理解一个非常重要的概念：原型链。</p>\n<p>我们知道，从一个对象上获取属性，如果在当前对象中没有获取到就会去它的原型上面获取：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: <span class=\"number\">18</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">obj.<span class=\"property\">__proto__</span> = &#123;</span><br><span class=\"line\">  <span class=\"attr\">address</span>: <span class=\"string\">&quot;广州市&quot;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">address</span>)</span><br></pre></td></tr></table></figure>\n\n<p>但是如果obj的原型上也没有对应的address属性呢？必然还是获取不到的。</p>\n<p>那么如果我们配置的原型对象上，继续配置原型呢？</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: <span class=\"number\">18</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">obj.<span class=\"property\">__proto__</span> = &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">obj.<span class=\"property\">__proto__</span>.<span class=\"property\">__proto__</span> = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">obj.<span class=\"property\">__proto__</span>.<span class=\"property\">__proto__</span>.<span class=\"property\">__proto__</span> = &#123;</span><br><span class=\"line\">  <span class=\"attr\">address</span>: <span class=\"string\">&quot;北京市&quot;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">address</span>)</span><br></pre></td></tr></table></figure>\n\n\n\n<p><img src=\"/images/%E5%A4%A7%E7%99%BD%E8%AF%9D%E7%B3%BB%E5%88%97%E4%B9%8BJavaScript%E5%8E%9F%E5%9E%8B%E5%8F%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.assets/image-20240906164844964.png\" alt=\"image-20240906164844964\"></p>\n<h3 id=\"Object的原型\"><a href=\"#Object的原型\" class=\"headerlink\" title=\"Object的原型\"></a>Object的原型</h3><p>按照上面的案例，第三个proto的proto就是Object对象了</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">__proto__</span>.<span class=\"property\">__proto__</span>.<span class=\"property\">__proto__</span>.<span class=\"property\">__proto__</span>) <span class=\"comment\">// [Object: null prototype] &#123;&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>看一下默认的对象原型都是啥</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123; <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span> &#125;</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">__proto__</span>) <span class=\"comment\">// [Object: null prototype] &#123;&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Object</span>()</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj1.<span class=\"property\">__proto__</span>) <span class=\"comment\">// [Object: null prototype] &#123;&#125;</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Object</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>) <span class=\"comment\">// [Object: null prototype] &#123;&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj.<span class=\"property\">__proto__</span> === <span class=\"title class_\">Object</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>) <span class=\"comment\">// true</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj1.<span class=\"property\">__proto__</span> === <span class=\"title class_\">Object</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>) <span class=\"comment\">// true</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p>我们可以知道，从Object直接创建出来的对象的原型都是 <code>[Object: null prototype] &#123;&#125;</code>。</p>\n<p>那么我们可能会问题： <code>[Object: null prototype] &#123;&#125;</code> 原型有什么特殊吗？</p>\n<ul>\n<li>特殊一：该对象不再继续有原型属性了，也就是已经是顶层原型了；</li>\n<li>特殊二：该对象上有很多默认的属性和方法；</li>\n</ul>\n<p><img src=\"/images/%E5%A4%A7%E7%99%BD%E8%AF%9D%E7%B3%BB%E5%88%97%E4%B9%8BJavaScript%E5%8E%9F%E5%9E%8B%E5%8F%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.assets/image-20240906165201726.png\" alt=\"image-20240906165201726\"></p>\n<h3 id=\"继承\"><a href=\"#继承\" class=\"headerlink\" title=\"继承\"></a>继承</h3><h2 id=\"ES6下Class语法糖\"><a href=\"#ES6下Class语法糖\" class=\"headerlink\" title=\"ES6下Class语法糖\"></a>ES6下Class语法糖</h2><blockquote>\n<p>拯救以上你一下子学不会，写啊写不明白的原型继承，虽然底层依旧是我上面讲的。</p>\n</blockquote>\n<p>那么，如何使用class来定义一个类呢？</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 类的声明</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 类的表达式</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> <span class=\"title class_\">Student</span> = <span class=\"keyword\">class</span> &#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<p>接着我们就可以使用new操作符调用类：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> p2 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1, p2)</span><br></pre></td></tr></table></figure>\n\n\n\n<p><strong>这个写法创造的变量，其实和我们刚刚new 函数干出来的其实是一样的</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> p = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Person</span>) <span class=\"comment\">// [class Person]</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>) <span class=\"comment\">// &#123;&#125;</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>.<span class=\"property\">constructor</span>) <span class=\"comment\">// [class Person]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p.<span class=\"property\">__proto__</span> === <span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>) <span class=\"comment\">// true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"keyword\">typeof</span> <span class=\"title class_\">Person</span>) <span class=\"comment\">// function</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"类的构造方法（从这开始就和你其他oop学到的差不多了）\"><a href=\"#类的构造方法（从这开始就和你其他oop学到的差不多了）\" class=\"headerlink\" title=\"类的构造方法（从这开始就和你其他oop学到的差不多了）\"></a>类的构造方法（从这开始就和你其他oop学到的差不多了）</h3><p>如果我们希望在创建对象的时候给类传递一些参数，这个时候应该如何做呢？</p>\n<ul>\n<li>每个类都可以有一个自己的构造函数（方法），这个方法的名称是固定的constructor；</li>\n<li>当我们通过new操作符，操作一个类的时候会调用这个类的构造函数constructor；</li>\n<li>每个类只能有一个构造函数，如果包含多个构造函数，那么会抛出异常；</li>\n</ul>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name, age, height</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">name</span> = name</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">age</span> = age</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">height</span> = height</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>(<span class=\"string\">&quot;xiaoyu&quot;</span>, <span class=\"number\">18</span>, <span class=\"number\">1.88</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1)</span><br></pre></td></tr></table></figure>\n\n<p>通过new关键字操作的时候..其实和上文学习的内容是一样的</p>\n<p>当我们通过new关键字操作类的时候，会调用这个constructor函数，并且执行如下操作：</p>\n<ul>\n<li>1.在内存中创建一个新的对象（空对象）；</li>\n<li>2.这个对象内部的[[prototype]]属性会被赋值为该类的prototype属性；</li>\n<li>3.构造函数内部的this，会指向创建出来的新对象；</li>\n<li>4.执行构造函数的内部代码（函数体代码）；</li>\n<li>5.如果构造函数没有返回非空对象，则返回创建出来的新对象；</li>\n</ul>\n<p><strong>相比较于之前直接写this复制那一套，语法糖果然名副其实</strong></p>\n<h3 id=\"类的方法定义\"><a href=\"#类的方法定义\" class=\"headerlink\" title=\"类的方法定义\"></a>类的方法定义</h3><p>在上面我们定义的属性都是直接放到了this上，也就意味着它是放到了创建出来的新对象中：</p>\n<ul>\n<li>在前面我们说过对于实例的方法，我们是希望放到原型上的，这样可以被多个实例来共享；</li>\n<li>这个时候我们可以直接在类中定义；（其实不要觉得怪异，这在oop思想中本就是应该的）</li>\n</ul>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name, age, height</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">name</span> = name</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">age</span> = age</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">height</span> = height</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">running</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot; running~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">eating</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot; eating~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> p1 = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>(<span class=\"string\">&quot;xiaoyu&quot;</span>, <span class=\"number\">18</span>, <span class=\"number\">1.88</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p1)</span><br><span class=\"line\"></span><br><span class=\"line\">p1.<span class=\"title function_\">running</span>()</span><br><span class=\"line\">p1.<span class=\"title function_\">eating</span>()</span><br><span class=\"line\"><span class=\"comment\">// [ &#x27;constructor&#x27;, &#x27;running&#x27;, &#x27;eating&#x27; ]</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Object</span>.<span class=\"title function_\">getOwnPropertyNames</span>(<span class=\"title class_\">Person</span>.<span class=\"property\"><span class=\"keyword\">prototype</span></span>))</span><br></pre></td></tr></table></figure>\n\n<p>这样子就可以在各个对象中进行使用了，因为是放在原型上的。</p>\n<p>我们也可以查看它们的属性描述符：</p>\n<ul>\n<li>会发现它们的enumerable都是为false的；</li>\n</ul>\n<h3 id=\"访问器方法\"><a href=\"#访问器方法\" class=\"headerlink\" title=\"访问器方法\"></a>访问器方法</h3><p>我们之前讲对象的属性描述符有时可以添加setter和getter函数的，那么类也是可以的：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">_name</span> = name</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">set</span> <span class=\"title function_\">name</span>(<span class=\"params\">newName</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">&quot;调用了name的setter方法&quot;</span>)</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">_name</span> = newName</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">get</span> <span class=\"title function_\">name</span>() &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">&quot;调用了name的getter方法&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"variable language_\">this</span>.<span class=\"property\">_name</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> p = <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>(<span class=\"string\">&quot;张三&quot;</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p.<span class=\"property\">name</span>)</span><br><span class=\"line\"><span class=\"comment\">// 这样子写以后，我们可以在打印p.name的时候发现调用了setter方法</span></span><br><span class=\"line\">p.<span class=\"property\">name</span> = <span class=\"string\">&quot;李四&quot;</span> <span class=\"comment\">// 对p.name进行更改，会触发setter</span></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(p.<span class=\"property\">name</span>)</span><br></pre></td></tr></table></figure>\n\n<p>ok 就差不多就是这个写法吧。</p>\n<p>但是和直接在对象中定义不同的是，类中的setter和getter是放在对象的</p>\n<p>proto上面的，不是和对象中定义一样放在对象中。</p>\n<p><img src=\"/images/%E5%A4%A7%E7%99%BD%E8%AF%9D%E7%B3%BB%E5%88%97%E4%B9%8BJavaScript%E5%8E%9F%E5%9E%8B%E5%8F%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.assets/image-20240908184527958.png\" alt=\"image-20240908184527958\"></p>\n<p>我们可以发现确实是放在原型上的哦~</p>\n<p>ps:<strong>我们如果直接在node环境下进行打印prototype是不能显示的，console.log会有显示上限的噢</strong></p>\n<p>所以我们可以用getOwnPropertyDescriptors如下方法进行打印</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Object</span>.<span class=\"title function_\">getOwnPropertyDescriptors</span>(p.<span class=\"property\">__proto__</span>))</span><br></pre></td></tr></table></figure>\n\n<p><code>getOwnPropertyDescriptors</code> 方法返回一个对象，其中包含指定对象的所有自身属性（即直接属性）的描述符。每个属性的描述符包括 <code>value</code>, <code>writable</code>, <code>enumerable</code>, 和 <code>configurable</code> 等属性。</p>\n<h3 id=\"静态方法\"><a href=\"#静态方法\" class=\"headerlink\" title=\"静态方法\"></a>静态方法</h3><p>静态方法就和你在别的语言里面所了解的到的一样，比如PHP和Java都有静态方法。</p>\n<p>也就是可以直接用类去调用方法。</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">age</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">age</span> = age</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">static</span> <span class=\"title function_\">create</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Person</span>(<span class=\"title class_\">Math</span>.<span class=\"title function_\">floor</span>(<span class=\"title class_\">Math</span>.<span class=\"title function_\">random</span>() * <span class=\"number\">100</span>))</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++) &#123;</span><br><span class=\"line\">  <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"title class_\">Person</span>.<span class=\"title function_\">create</span>())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"ES6类继承\"><a href=\"#ES6类继承\" class=\"headerlink\" title=\"ES6类继承\"></a>ES6类继承</h3><p>没错就是extends,ES5的继承太抽象了，要这么繁琐，所以ES6直接一手extends</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span>&#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Student</span> <span class=\"keyword\">extends</span> <span class=\"title class_ inherited__\">Person</span>&#123;</span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>我们知道继承可以让我们复用父类的一些代码结构，比如继承属性和方法：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name, age</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">name</span> = name</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">age</span> = age</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">running</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot; running~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">eating</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot; eating~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Student</span> <span class=\"keyword\">extends</span> <span class=\"title class_ inherited__\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name, age, sno</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">super</span>(name, age)</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">sno</span> = sno</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">studying</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot; studying~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> stu = <span class=\"keyword\">new</span> <span class=\"title class_\">Student</span>(<span class=\"string\">&quot;xiaoyu&quot;</span>, <span class=\"number\">18</span>, <span class=\"number\">111</span>)</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"super关键字\"><a href=\"#super关键字\" class=\"headerlink\" title=\"super关键字\"></a>super关键字</h3><p>如果在子类的构造函数中使用this或者返回默认对象之前，必须调用super调用父类的构造方法。</p>\n<p>这一点PHP的面向对象里面如果要调用父类函数有一个parent::写法，或者直接$this起手，如果子类没有就会去找父类而没有super这个函数。</p>\n<p>super的使用位置有三个：</p>\n<ol>\n<li>子类的构造函数</li>\n<li>实例方法</li>\n<li>静态方法；</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 调用 父对象/父类 的构造函数</span></span><br><span class=\"line\"><span class=\"variable language_\">super</span>([<span class=\"variable language_\">arguments</span>]);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 调用 父对象/父类 上的方法</span></span><br><span class=\"line\"><span class=\"variable language_\">super</span>.<span class=\"title function_\">functionOnParent</span>([<span class=\"variable language_\">arguments</span>]);</span><br></pre></td></tr></table></figure>\n\n<p>下面的代码会报错，因为我们没有调用super：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Student</span> <span class=\"keyword\">extends</span> <span class=\"title class_ inherited__\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">sno</span>) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// ReferenceError: Must call super constructor in derived class before accessing &#x27;this&#x27; or returning from derived constructor</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> stu = <span class=\"keyword\">new</span> <span class=\"title class_\">Student</span>()</span><br></pre></td></tr></table></figure>\n\n<p>我们可以在子类的方法中调用父类的方法：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name, age</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">name</span> = name</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">age</span> = age</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">running</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;  running~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">eating</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;  eating~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">static</span> <span class=\"title function_\">create</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">&quot;hello world&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Student</span> <span class=\"keyword\">extends</span> <span class=\"title class_ inherited__\">Person</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">constructor</span>(<span class=\"params\">name, age, sno</span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">super</span>(name, age)</span><br><span class=\"line\">    <span class=\"variable language_\">this</span>.<span class=\"property\">sno</span> = sno</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"title function_\">studying</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"variable language_\">this</span>.<span class=\"property\">name</span> + <span class=\"string\">&quot;  studying~&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"title function_\">running</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">super</span>.<span class=\"title function_\">running</span>()</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">&quot;this is student reload running~&quot;</span>, <span class=\"variable language_\">this</span>.<span class=\"property\">name</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">static</span> <span class=\"title function_\">create</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"variable language_\">super</span>.<span class=\"title function_\">create</span>()</span><br><span class=\"line\">    <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">&quot;aaaaaaa&quot;</span>)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> stu = <span class=\"keyword\">new</span> <span class=\"title class_\">Student</span>(<span class=\"string\">&quot;xiaoyu&quot;</span>, <span class=\"number\">18</span>, <span class=\"number\">111</span>)</span><br><span class=\"line\">stu.<span class=\"title function_\">running</span>()</span><br><span class=\"line\"><span class=\"title class_\">Student</span>.<span class=\"title function_\">create</span>()</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"继承内置类\"><a href=\"#继承内置类\" class=\"headerlink\" title=\"继承内置类\"></a>继承内置类</h3><p>emm 这个概念怎么说呢，如果你想要对Array类做出一些改变加个方法什么的也不是不行，这样子你就可以用到内置类。</p>\n<p>比如Array</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">xArray</span> <span class=\"keyword\">extends</span> <span class=\"title class_ inherited__\">Array</span>&#123;</span><br><span class=\"line\">  <span class=\"title function_\">lastItem</span>(<span class=\"params\"></span>)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"variable language_\">this</span>[<span class=\"variable language_\">this</span>.<span class=\"property\">length</span>-<span class=\"number\">1</span>]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> array = <span class=\"keyword\">new</span> <span class=\"title function_\">xArray</span>(<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(array.<span class=\"title function_\">lastItem</span>())</span><br><span class=\"line\"></span><br><span class=\"line\">array.<span class=\"title function_\">filter</span>(<span class=\"function\"><span class=\"params\">item</span> =&gt;</span> &#123;</span><br><span class=\"line\">  <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(item)</span><br><span class=\"line\">&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>但是目前这种继承所返回的数据，或者数据类型既是xArray又是Array我们可以做个改动</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">xArray</span> <span class=\"keyword\">extends</span> <span class=\"title class_ inherited__\">Array</span> &#123;</span><br><span class=\"line\">  <span class=\"title function_\">lastItem</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"variable language_\">this</span>[<span class=\"variable language_\">this</span>.<span class=\"property\">length</span> - <span class=\"number\">1</span>]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"keyword\">static</span> get [<span class=\"title class_\">Symbol</span>.<span class=\"property\">species</span>]()&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"title class_\">Array</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> array = <span class=\"keyword\">new</span> <span class=\"title function_\">xArray</span>(<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(array.<span class=\"title function_\">lastItem</span>())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> demo = array.<span class=\"title function_\">filter</span>(<span class=\"function\"><span class=\"params\">item</span> =&gt;</span> &#123;</span><br><span class=\"line\">  <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(item)</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(demo <span class=\"keyword\">instanceof</span> xArray)</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(demo <span class=\"keyword\">instanceof</span> <span class=\"title class_\">Array</span>)</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"ES6对象增强\"><a href=\"#ES6对象增强\" class=\"headerlink\" title=\"ES6对象增强\"></a>ES6对象增强</h2><p>ES6中对对象字面量进行了增强</p>\n<h3 id=\"属性简写\"><a href=\"#属性简写\" class=\"headerlink\" title=\"属性简写\"></a>属性简写</h3><p>就对象属性赋值的时候，如果变量名和属性名一样就可以简略些</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">&quot;xiaoyu&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> age = <span class=\"number\">18</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// ES5的写法</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj1 = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: name,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: age</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// ES6的增强写法</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj2 = &#123;</span><br><span class=\"line\">  name,</span><br><span class=\"line\">  age</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"方法简写\"><a href=\"#方法简写\" class=\"headerlink\" title=\"方法简写\"></a>方法简写</h3><p>另一个就可以方法简写，其实在不知不觉中我自己已经有混用发现了…..</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ES5的方法写法</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> info1 = &#123;</span><br><span class=\"line\">  <span class=\"attr\">foo</span>: <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"attr\">bar</span>: <span class=\"keyword\">function</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// ES6的增强写法</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> info2 = &#123;</span><br><span class=\"line\">  <span class=\"title function_\">foo</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"title function_\">bar</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"计算属性名\"><a href=\"#计算属性名\" class=\"headerlink\" title=\"计算属性名\"></a>计算属性名</h3><p>相信你一定有遇到属性名是需要动态构成的情况，比如我一个属性名得是一个变量名对吧~以前es5只能字面量赋值</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">&quot;three&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;</span><br><span class=\"line\">  <span class=\"attr\">one</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">  <span class=\"attr\">two</span>: <span class=\"number\">2</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">obj[name] = <span class=\"number\">3</span></span><br></pre></td></tr></table></figure>\n\n<p>ES6可以</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> name = <span class=\"string\">&quot;three&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;</span><br><span class=\"line\">  <span class=\"attr\">one</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">  <span class=\"attr\">two</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">  [name]: <span class=\"number\">3</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(obj)</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"解构Destructuring\"><a href=\"#解构Destructuring\" class=\"headerlink\" title=\"解构Destructuring\"></a>解构Destructuring</h2><p>ES6加了一个结构的方法，咋说呢，要不是去学习我以为就是天然支持的哈哈哈，毕竟是别的</p>\n<p>语言过来的，很多东西都是相通的。</p>\n<h3 id=\"数组结构\"><a href=\"#数组结构\" class=\"headerlink\" title=\"数组结构\"></a>数组结构</h3><figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> names = [<span class=\"string\">&quot;abc&quot;</span>, <span class=\"string\">&quot;cba&quot;</span>, <span class=\"string\">&quot;nba&quot;</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> [name1, name2, name3] = names</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(name1, name2, name3)</span><br></pre></td></tr></table></figure>\n\n<p>但是结构数组必须得按照顺序来，如果你只要第二个和第三个</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> [, nameb, namec] = names</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(nameb, namec)</span><br></pre></td></tr></table></figure>\n\n<p>隔壁GO是_来占位，js直接空着就完事了</p>\n<p>如果我们希望解构出来一个元素，其他元素继续放到另外一个数组中：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> [namea, ...newNames] = names</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(namea, newNames)</span><br></pre></td></tr></table></figure>\n\n<p>剩下两个就丢进了newNames中了</p>\n<p>如果我们解构的数据数量大于数组中原本的数据数量，那么会返回undefined：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> [namex, namey, namez, namem] = names</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(namem) <span class=\"comment\">// undefined</span></span><br></pre></td></tr></table></figure>\n\n<p>我们可以在解构出来的数据为undefined的时候给它一个默认值</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> [namex, namey, namez, namem = <span class=\"string\">&quot;aaa&quot;</span>] = names</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(namem) <span class=\"comment\">// aaa</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"对象的解构\"><a href=\"#对象的解构\" class=\"headerlink\" title=\"对象的解构\"></a>对象的解构</h3><p>对象的解构和数组的解构是相似的，不同之处在于：</p>\n<ul>\n<li>数组中的元素是按照顺序排列的，并且我们只能根据顺序来确定需要获取的数据；</li>\n<li>对象中的数据由key和value组成，我们可以通过key来获取想要的value；</li>\n</ul>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> obj = &#123;</span><br><span class=\"line\">  <span class=\"attr\">name</span>: <span class=\"string\">&quot;xiaoyu&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">age</span>: <span class=\"number\">18</span>,</span><br><span class=\"line\">  <span class=\"attr\">height</span>: <span class=\"number\">1.88</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> &#123; name, age, height &#125; = obj</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(name, age, height)</span><br></pre></td></tr></table></figure>\n\n<p><strong>因为对象是可以通过key来解构的，所以它对顺序、个数都没有要求：</strong></p>\n<p>如果我们对变量的名称不是很满意，那么我们可以重新命名：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> &#123; <span class=\"attr\">name</span>: whyName, <span class=\"attr\">age</span>: whyAge &#125; = obj</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(whyName, whyAge)</span><br></pre></td></tr></table></figure>\n\n<p>我们也可以给变量一个默认值：</p>\n<figure class=\"highlight js\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> &#123; name, address = <span class=\"string\">&quot;广州市&quot;</span> &#125; = obj</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(name, address)</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n\n","tags":["JavaScript"]},{"title":"Hello World","url":"/forward/4a17b156.html","content":"<h2 id=\"失語時代下的喃喃自語\"><a href=\"#失語時代下的喃喃自語\" class=\"headerlink\" title=\"失語時代下的喃喃自語\"></a>失語時代下的喃喃自語</h2><p>纪念2017年愚人节，reddit网站发起一项为期三天的社会实验（2017年4月1日-4月3日），号召所有注册用户在一块100万像素的画布上作画（1000*1000），用户有16种像素颜色选择，生成一次后需要等待20分钟到5分钟之后才可以进行下一次编辑。凭借大家的协作创造出得一幅伟大的作品并载入互联网史册。</p>\n<p>在混乱中建立秩序，文明也在一次次破坏重建中焕发了新的面貌，当资源有限的情况下，一个群体想要生存势必要蚕食别的群体，生存还是毁灭的问题在短短的72小时内在一块小小的帆布画版上不断上演。虽然这个活动在几年前就已经结束了，但现实中比Reddit这场社会实验残酷百倍的故事却从未停歇。<br><del>国家之间的冲突，族群之间的恶意。在更大纬度的战场，渗透于各个领域的对垒，甚至已经关乎到十几亿几十亿人们的幸福生活。</del></p>\n<p>活动地址参见：<a href=\"https://www.reddit.com/r/place/\">reddit/r/place</a><br>活动详情参见：<a href=\"https://en.wikipedia.org/wiki/Place_(Reddit)\">维基百科</a><br>画板元素详解：<a href=\"https://draemm.li/various/place-atlas/\">The /r/place Atlas</a><br>变化过程参见：<a href=\"https://www.bilibili.com/video/BV1WW41197qY\">bilibil</a></p>\n<p>活动结束时最终快照[高清]：<br><img src=\"/images/img--1.png\" alt=\"reddit-place-2017\"></p>\n","tags":["place"]},{"title":"iterm2常用快捷键","url":"/forward/10883bf2.html","content":"<h1 id=\"Iterm2-常用快捷键\"><a href=\"#Iterm2-常用快捷键\" class=\"headerlink\" title=\"Iterm2 常用快捷键\"></a>Iterm2 常用快捷键</h1><p><img src=\"/images/iterm2%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE.assets/image-20240429133734551.png\" alt=\"image-20240429133734551\"></p>\n<h2 id=\"标签控制\"><a href=\"#标签控制\" class=\"headerlink\" title=\"标签控制\"></a>标签控制</h2><figure class=\"highlight text\"><table><tr><td class=\"code\"><pre><span class=\"line\">新建标签：command + t</span><br><span class=\"line\"></span><br><span class=\"line\">关闭标签：command + w</span><br><span class=\"line\"></span><br><span class=\"line\">切换标签：command + 数字 command + 左右方向键</span><br><span class=\"line\"></span><br><span class=\"line\">切换全屏：command + enter</span><br><span class=\"line\"></span><br><span class=\"line\">查找：command + f</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"分屏控制\"><a href=\"#分屏控制\" class=\"headerlink\" title=\"分屏控制\"></a>分屏控制</h2><figure class=\"highlight text\"><table><tr><td class=\"code\"><pre><span class=\"line\">垂直分屏：command + d</span><br><span class=\"line\"></span><br><span class=\"line\">水平分屏：command + shift + d</span><br><span class=\"line\"></span><br><span class=\"line\">切换屏幕：command + option + 方向键 command + [ 或 command + ]</span><br><span class=\"line\"></span><br><span class=\"line\">查看历史命令：command + ;</span><br><span class=\"line\"></span><br><span class=\"line\">查看剪贴板历史：command + shift + h</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"光标操作（常用）\"><a href=\"#光标操作（常用）\" class=\"headerlink\" title=\"光标操作（常用）\"></a>光标操作（常用）</h2><figure class=\"highlight text\"><table><tr><td class=\"code\"><pre><span class=\"line\">清除当前行（实际上是光标前全部内容）：ctrl + u</span><br><span class=\"line\"></span><br><span class=\"line\">删除前一个字符|删除后一个字符：ctrl + h | ctrl + h</span><br><span class=\"line\"></span><br><span class=\"line\">按单词往前删除（推荐记忆）：ctrl + w</span><br><span class=\"line\"></span><br><span class=\"line\">删除光标后所有内容：ctrl + k</span><br><span class=\"line\"></span><br><span class=\"line\">到行首（尾）：ctrl + a/e</span><br><span class=\"line\"></span><br><span class=\"line\">光标前进后退：-&gt; ctrl + f | &lt;- ctrl + b</span><br><span class=\"line\"></span><br><span class=\"line\">上一条命令|下一条命令：ctrl + p/n</span><br><span class=\"line\"></span><br><span class=\"line\">可以搜索的历史命令：ctrl + r</span><br><span class=\"line\"></span><br><span class=\"line\">清屏：command + r | ctrl + l | 我自己一般手动clear</span><br></pre></td></tr></table></figure>\n\n\n\n<p>上面就是我整理的一些快捷键。</p>\n<p>下面就是大整合：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">新建标签：<span class=\"built_in\">command</span> + t</span><br><span class=\"line\"></span><br><span class=\"line\">关闭标签：<span class=\"built_in\">command</span> + w</span><br><span class=\"line\"></span><br><span class=\"line\">切换标签：<span class=\"built_in\">command</span> + 数字 <span class=\"built_in\">command</span> + 左右方向键</span><br><span class=\"line\"></span><br><span class=\"line\">切换全屏：<span class=\"built_in\">command</span> + enter</span><br><span class=\"line\"></span><br><span class=\"line\">查找：<span class=\"built_in\">command</span> + f</span><br><span class=\"line\"></span><br><span class=\"line\">垂直分屏：<span class=\"built_in\">command</span> + d</span><br><span class=\"line\"></span><br><span class=\"line\">水平分屏：<span class=\"built_in\">command</span> + <span class=\"built_in\">shift</span> + d</span><br><span class=\"line\"></span><br><span class=\"line\">切换屏幕：<span class=\"built_in\">command</span> + option + 方向键 <span class=\"built_in\">command</span> + [ 或 <span class=\"built_in\">command</span> + ]</span><br><span class=\"line\"></span><br><span class=\"line\">查看历史命令：<span class=\"built_in\">command</span> + ;</span><br><span class=\"line\"></span><br><span class=\"line\">查看剪贴板历史：<span class=\"built_in\">command</span> + <span class=\"built_in\">shift</span> + h</span><br><span class=\"line\"></span><br><span class=\"line\">清除当前行：ctrl + u</span><br><span class=\"line\"></span><br><span class=\"line\">到行首：ctrl + a</span><br><span class=\"line\"></span><br><span class=\"line\">到行尾：ctrl + e</span><br><span class=\"line\"></span><br><span class=\"line\">前进后退：ctrl + f/b (相当于左右方向键)</span><br><span class=\"line\"></span><br><span class=\"line\">上一条命令：ctrl + p</span><br><span class=\"line\"></span><br><span class=\"line\">搜索命令历史：ctrl + r</span><br><span class=\"line\"></span><br><span class=\"line\">删除当前光标的字符：ctrl + d</span><br><span class=\"line\"></span><br><span class=\"line\">删除光标之前的字符：ctrl + h</span><br><span class=\"line\"></span><br><span class=\"line\">删除光标之前的单词：ctrl + w</span><br><span class=\"line\"></span><br><span class=\"line\">删除到文本末尾：ctrl + k</span><br><span class=\"line\"></span><br><span class=\"line\">交换光标处文本：ctrl + t</span><br><span class=\"line\"></span><br><span class=\"line\">清屏1：<span class=\"built_in\">command</span> + r</span><br><span class=\"line\"></span><br><span class=\"line\">清屏2：ctrl + l</span><br><span class=\"line\"></span><br><span class=\"line\">自带有哪些很实用的功能/快捷键</span><br><span class=\"line\"></span><br><span class=\"line\">⌘ + 数字在各 tab 标签直接来回切换</span><br><span class=\"line\"></span><br><span class=\"line\">选择即复制 + 鼠标中键粘贴，这个很实用</span><br><span class=\"line\"></span><br><span class=\"line\">⌘ + f 所查找的内容会被自动复制</span><br><span class=\"line\"></span><br><span class=\"line\">⌘ + d 横着分屏 / ⌘ + <span class=\"built_in\">shift</span> + d 竖着分屏</span><br><span class=\"line\"></span><br><span class=\"line\">⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏</span><br><span class=\"line\"></span><br><span class=\"line\">ctrl + u 清空当前行，无论光标在什么位置</span><br><span class=\"line\"></span><br><span class=\"line\">输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令</span><br><span class=\"line\"></span><br><span class=\"line\">⌘ + <span class=\"built_in\">shift</span> + h 会列出剪切板历史</span><br><span class=\"line\"></span><br><span class=\"line\">可以在 Preferences &gt; keys 设置全局快捷键调出 iterm，这个也可以用过 Alfred 实现</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n","categories":["折腾"],"tags":["MacOS终端"]},{"title":"计算机硬件基础-cache-校验码","url":"/forward/20906a71.html","content":"<h1 id=\"计算机基础硬件-cache-校验码\"><a href=\"#计算机基础硬件-cache-校验码\" class=\"headerlink\" title=\"计算机基础硬件-cache + 校验码\"></a>计算机基础硬件-cache + 校验码</h1><h2 id=\"cache\"><a href=\"#cache\" class=\"headerlink\" title=\"cache\"></a>cache</h2><p>功能:提高cpu数据输入输出的速率，突破冯诺依曼瓶颈</p>\n<p>速度：在计算机存储体系中，cache是访问速度较快的层次</p>\n<p>原理: 在使用cache改善系统性能的一居室程序的局部性原理。</p>\n<p>组成：cache由控制部分和存储部分组成</p>\n<p><img src=\"/images/pasted-2.png\" alt=\"upload successful\"></p>\n<p><img src=\"/images/pasted-3.png\" alt=\"upload successful\"></p>\n<h2 id=\"输入输出\"><a href=\"#输入输出\" class=\"headerlink\" title=\"输入输出\"></a>输入输出</h2><p><img src=\"/images/pasted-4.png\" alt=\"upload successful\"></p>\n<h2 id=\"校验码-奇偶校验码-，CRC-海明校验码\"><a href=\"#校验码-奇偶校验码-，CRC-海明校验码\" class=\"headerlink\" title=\"校验码-奇偶校验码 ，CRC,海明校验码\"></a>校验码-奇偶校验码 ，CRC,海明校验码</h2><p><img src=\"/images/pasted-5.png\" alt=\"upload successful\"></p>\n<p>奇偶校验码 - 只能检错，可检验1（奇数）位错</p>\n<p>CRC - 只能检错，可检多位</p>\n<p>海明码：可以检错纠错，和1位多位</p>\n<p><img src=\"/images/pasted-6.png\" alt=\"upload successful\"><br>奇偶校验很简单比如：</p>\n<p><span style=\"color:red\">1</span>|00  0 这样子这个就有一个奇数校验</p>\n<p><span style=\"color:red\">0</span>|01      1</p>\n<p><span style=\"color:red\">0</span>|10      2</p>\n<p><span style=\"color:red\">1</span>|11      3</p>\n<p>假如出现一个 <span style=\"color:red\">0</span>|11 这种就在奇数校验下非法了</p>\n<p>CRC 就是k个数据位+r个校验位没啥好说的</p>\n<p>海明码假设由48个数据位</p>\n<p>那么由公式 2^k &gt;= 48 + k     得出k = 6 6个校验位</p>\n<p><img src=\"/images/pasted-7.png\" alt=\"upload successful\"></p>\n","categories":["日记"],"tags":["信息系统管理工程师"]},{"title":"操作系统杂项考点习题-软考版","url":"/forward/cff67e5b.html","content":"<h1 id=\"操作系统\"><a href=\"#操作系统\" class=\"headerlink\" title=\"操作系统\"></a>操作系统</h1><h2 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h2><p>通过资源管理，提高计算机系统效率。</p>\n<p>改善人机界面，向用户提供友好的工作环境。</p>\n<h2 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h2><ul>\n<li>并发性</li>\n<li>共享性</li>\n<li>异步性</li>\n</ul>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240429123939629.png\" alt=\"image-20240429123939629\"></p>\n<h2 id=\"进程管理\"><a href=\"#进程管理\" class=\"headerlink\" title=\"进程管理\"></a>进程管理</h2><h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><p>进程：</p>\n<ol>\n<li>进程是程序的一次执行</li>\n<li>进程是一个程序及其数据在处理机上顺序执行时发生的活动</li>\n<li>进程是具有独立功能的程序在一个数据集合上运行的过程，是系统进行资源分配和调度的独立单位</li>\n<li>也可以这么记，进程是进程实体的一次运行，是系统进行资源分配和调度的一个独立单位</li>\n</ol>\n<p>程序：</p>\n<p>​    程序是一组有序指令的合集并存在某种介质上，本身不具有活动含义。</p>\n<p>线程:</p>\n<p>​    线程是进程中的一个实体，是被系统独立调用的基本单位。 线程的资源用的是进程里面的。</p>\n<p>简单的流程图（我的灵魂手绘图）：</p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240504112732155.png\" alt=\"image-20240504112732155\"></p>\n<h3 id=\"进程控制\"><a href=\"#进程控制\" class=\"headerlink\" title=\"进程控制\"></a>进程控制</h3><p>原语：控制程序的指令段，要么不执行，要么都执行，不可分割的。</p>\n<p>同步：直接制约，是有顺序的。</p>\n<p>互斥：异步制约，双方都可制约。</p>\n<p>灵界资源：一次只能供一个进程使用的资源</p>\n<p>临界区：使用临界资源的代码片段。</p>\n<h3 id=\"信号量机制\"><a href=\"#信号量机制\" class=\"headerlink\" title=\"信号量机制\"></a>信号量机制</h3><p>信号量：</p>\n<ul>\n<li>一个整数</li>\n<li>S&gt;=0 表示资源的可用数</li>\n<li>S&lt;0 S的绝对值就是等待队列或是阻塞队列的任务书</li>\n</ul>\n<p>PV操作：</p>\n<p>P操作就是占用一个资源，S -= 1</p>\n<p>S操作就是任务结束了，释放一个资源S+=1</p>\n<h4 id=\"PV互斥模型\"><a href=\"#PV互斥模型\" class=\"headerlink\" title=\"PV互斥模型\"></a>PV互斥模型</h4><p>在一个程序段里，pv操作应该同时出现。</p>\n<p>P(S):</p>\n<p>使用XXX</p>\n<p>V(S):</p>\n<p>后续代码</p>\n<p>互斥信号量s的初始值为1</p>\n<h4 id=\"PV同步模型\"><a href=\"#PV同步模型\" class=\"headerlink\" title=\"PV同步模型\"></a>PV同步模型</h4><p>如单缓冲区的生产消费问题，其实也就是同一个信号量在不同的模型中进行控制</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\">smophore mutex = <span class=\"number\">1</span> empty = n full = <span class=\"number\">0</span></span><br><span class=\"line\">producer()&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        p(empty);</span><br><span class=\"line\">        p(mutex);</span><br><span class=\"line\">        produce;</span><br><span class=\"line\">       \tv(mutex);</span><br><span class=\"line\">        v(full);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">consumer()&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(<span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">        p(full);</span><br><span class=\"line\">        p(mutex);</span><br><span class=\"line\">        consume ;</span><br><span class=\"line\">       \tv(mutex);</span><br><span class=\"line\">        v(empty);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<p>一张PPT的图：<br><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240430003954753.png\" alt=\"image-20240430003954753\"></p>\n<h2 id=\"存储管理\"><a href=\"#存储管理\" class=\"headerlink\" title=\"存储管理\"></a>存储管理</h2><h3 id=\"页式存储\"><a href=\"#页式存储\" class=\"headerlink\" title=\"页式存储\"></a>页式存储</h3><p>优点： 利用率高，碎片小，分配及管理简单</p>\n<p>缺点：增加了系统开销，可能产生抖动现象</p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240430005646138.png\" alt=\"image-20240430005646138\"></p>\n<h3 id=\"段式存储\"><a href=\"#段式存储\" class=\"headerlink\" title=\"段式存储\"></a>段式存储</h3><p>段式存储主要是，程序段是完整的，不会和页式一样一个程序段被切成多块。</p>\n<p>优点：多道程序共享内存，各段程序修改互不影响。</p>\n<p>缺点：内存利用率低，内存碎片浪费大。</p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240503232221396.png\" alt=\"image-20240503232221396\"></p>\n<h3 id=\"段页式存储\"><a href=\"#段页式存储\" class=\"headerlink\" title=\"段页式存储\"></a>段页式存储</h3><p>优点：空间浪费小，存储共享容易，存储保护容易，可以动态链接。</p>\n<p>缺点：由于管理软件的增加，复杂性和开销也增加，性能有所下降</p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240503235441587.png\" alt=\"image-20240503235441587\"></p>\n<h2 id=\"虚拟存储器\"><a href=\"#虚拟存储器\" class=\"headerlink\" title=\"虚拟存储器\"></a>虚拟存储器</h2><p>其实实现使用也就是上文的存储管理。</p>\n<p><strong>好像考试也不怎么考这些</strong></p>\n<h3 id=\"页面置换算法\"><a href=\"#页面置换算法\" class=\"headerlink\" title=\"页面置换算法\"></a>页面置换算法</h3><ul>\n<li>先进先出FIFO</li>\n<li>最佳置换optimal</li>\n<li>最近最久未使用LRU</li>\n<li>最少使用LFU</li>\n</ul>\n<h3 id=\"文件组织结构\"><a href=\"#文件组织结构\" class=\"headerlink\" title=\"文件组织结构\"></a>文件组织结构</h3><p>逻辑结构：流式文件，记录式文件。</p>\n<p>物理结构：顺序结构，链接结构，索引结构。</p>\n<p><strong>好像考试也不怎么考这些</strong></p>\n<h3 id=\"虚设备与SPOOLING技术\"><a href=\"#虚设备与SPOOLING技术\" class=\"headerlink\" title=\"虚设备与SPOOLING技术\"></a>虚设备与SPOOLING技术</h3><p>当只有一个物理设备的情况下，有多个用户需要进行使用，所以就需要一个作业井（其实也就理解为一个任务队列）</p>\n<p><strong>随便贴图一张基本上不会考的样子。</strong></p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240504112544771.png\" alt=\"image-20240504112544771\"></p>\n<h2 id=\"习题\"><a href=\"#习题\" class=\"headerlink\" title=\"习题\"></a>习题</h2><p>送分题：<br><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240429124040399.png\" alt=\"image-20240429124040399\"></p>\n<p><img src=\"%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240430004454017.png\" alt=\"image-20240430004454017\"></p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240504000120592.png\" alt=\"image-20240504000120592\"></p>\n<p>这个题的思路就是，先判断在不在内存里，然后判断有没有访问过，最后判断有没有被修改过。</p>\n<p>实际上就是判断：去掉0访问，去掉0修改。</p>\n<p><img src=\"/images/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%BD%AF%E8%80%83%E4%B8%93%E9%A2%98.assets/image-20240504012327600.png\" alt=\"image-20240504012327600\"></p>\n<p>这个地方如果是字，那就是根据cpu的字长来32就是除32.</p>\n<p>如果是字节，那就是除8</p>\n","categories":["日记"],"tags":["信息系统管理工程师"]},{"title":"计算机组成原理指令存储-软考版","url":"/forward/8f372709.html","content":"<h1 id=\"指令-存储软考版本\"><a href=\"#指令-存储软考版本\" class=\"headerlink\" title=\"指令+存储软考版本\"></a>指令+存储软考版本</h1><h2 id=\"指令\"><a href=\"#指令\" class=\"headerlink\" title=\"指令\"></a>指令</h2><p><strong>一条指令就是机器语言的一个语句，是一组有意义的二进制代码</strong></p>\n<p>一条指令其实包含如下内容：”操作码字段” ，”地址码字段”</p>\n<ul>\n<li>操作码字段 - 指出计算机要执行什么性质的操作。</li>\n<li>地址码字段 - 包含各操作数的地址与结果存放地址。</li>\n</ul>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240417225856055.png\" alt=\"image-20240417225856055\"></p>\n<p>如果没有A1 A2 A3只有OP就是0地址指令符</p>\n<h2 id=\"寻址方式\"><a href=\"#寻址方式\" class=\"headerlink\" title=\"寻址方式\"></a>寻址方式</h2><ul>\n<li><p>立即寻址：地址码部分存放的就是操作数</p>\n</li>\n<li><p>直接寻址：地址码存放的是操作数的地址</p>\n</li>\n<li><p>间接寻址：地址码存放的是记录操作数地址的地址。</p>\n</li>\n<li><p>寄存器寻址：地址码部分告诉我们数据存在哪一个寄存器</p>\n</li>\n<li><p>寄存器间接寻址：数据存在哪一个寄存器的地址</p>\n</li>\n<li><p>———————–上面软考常考</p>\n</li>\n<li><p>下面这三个基本上就是加偏移量进行寻址</p>\n</li>\n<li><p>相对寻址-一般个电脑就这个</p>\n</li>\n<li><p>基址寻址</p>\n</li>\n<li><p>变址寻址</p>\n</li>\n</ul>\n<h2 id=\"计算机体系结构分类\"><a href=\"#计算机体系结构分类\" class=\"headerlink\" title=\"计算机体系结构分类\"></a>计算机体系结构分类</h2><table>\n<thead>\n<tr>\n<th>体系结构类型</th>\n<th>结构</th>\n<th>关键特性</th>\n<th>代表</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>单指令流，单数据流，<strong>SISD</strong></td>\n<td>控制部分：1<br />处理部件：1</td>\n<td></td>\n<td>单处理器系统</td>\n</tr>\n<tr>\n<td>单指令流，多数据流 <strong>SIMD</strong></td>\n<td>控制部分：1<br />处理部件：多个</td>\n<td>以同步的形式执行同一条指令</td>\n<td>阵列处理机，超级向量处理机</td>\n</tr>\n<tr>\n<td>多指令流，单数据流 <strong>MISD</strong></td>\n<td>控制部分：多个<br />处理部分：1</td>\n<td>不可能且不实际</td>\n<td>目前没有，有点像流水线之类的<br /></td>\n</tr>\n<tr>\n<td>多指令流，多数据流<br /><strong>MSMD</strong></td>\n<td>控制部分：多个<br />处理部分：多个</td>\n<td>能够实现作业任务，指令等各级全面执行</td>\n<td>多处理机系统，多计算机</td>\n</tr>\n</tbody></table>\n<p>阵列处理机：就是多台处理机组成，每台处理机处理相同任务，并行计算。</p>\n<p>多处理机系统：多台处理机设备组成的系统，每台处理机有属于自己的控制部件，可以执行独立的程序，共享一个主存储和所有外部设备。</p>\n<p><img src=\".//images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240418203026838.png\" alt=\"image-20240418203026838\"></p>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240424011317032.png\" alt=\"image-20240424011317032\"></p>\n<h2 id=\"CISC-与-RISC\"><a href=\"#CISC-与-RISC\" class=\"headerlink\" title=\"CISC 与 RISC\"></a>CISC 与 RISC</h2><table>\n<thead>\n<tr>\n<th>–</th>\n<th>CISC（复杂）</th>\n<th>RISC(精简)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>指令</td>\n<td>数量多，使用频率差别大，可变长格式</td>\n<td>数量少<br />使用频率接近<br />定长格式<br />大部分为单周期指令<br />操作寄存器<br />只有Load/Store操作内存</td>\n</tr>\n<tr>\n<td>寻址方式</td>\n<td>支持多种</td>\n<td>支持方式少</td>\n</tr>\n<tr>\n<td>实现方式</td>\n<td>微程序控制技术</td>\n<td>增加了通用寄存器<br />硬布线逻辑控制为主<br />采用流水线<br /></td>\n</tr>\n<tr>\n<td>其他</td>\n<td></td>\n<td>优化编译，有效支持高级语言</td>\n</tr>\n</tbody></table>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240424011820711.png\" alt=\"image-20240424011820711\"></p>\n<h2 id=\"流水线\"><a href=\"#流水线\" class=\"headerlink\" title=\"流水线\"></a>流水线</h2><p>流水线：多条指令重叠进行操作的一种准并行处理实现技术。</p>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240424011930035.png\" alt=\"image-20240424011930035\"></p>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240424011938087.png\" alt=\"image-20240424011938087\"></p>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240424012012622.png\" alt=\"image-20240424012012622\"></p>\n<p>上面这个图是不是一下子看不懂？</p>\n<p>根据列题来说，流水线周期其实就是，三部分执行时间中最长的一部分，在如题中也就是2ns。</p>\n<p>那么流水线计算公式呢？</p>\n<p><em><em>单条指令所需时间+（n-1）</em> 流水线周期</em>*</p>\n<p>那么如题就是</p>\n<p>（2+2+1）+ 99 * 2 = 203</p>\n<h2 id=\"多级存储器结构\"><a href=\"#多级存储器结构\" class=\"headerlink\" title=\"多级存储器结构\"></a>多级存储器结构</h2><p>没啥好说的，看图即可，金字塔上面 贵和快和小。下面就是便宜慢和大</p>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240418223757692.png\" alt=\"image-20240418223757692\"></p>\n<h2 id=\"存储器分类\"><a href=\"#存储器分类\" class=\"headerlink\" title=\"存储器分类\"></a>存储器分类</h2><p>一般就纠结一些</p>\n<p><img src=\"/images/%E6%8C%87%E4%BB%A4+%E5%AD%98%E5%82%A8-%E8%BD%AF%E8%80%83%E7%89%88.assets/image-20240418223824672.png\" alt=\"image-20240418223824672\"></p>\n","categories":["日记"],"tags":["信息系统管理工程师"]},{"title":"计算机组成原理部分（基础词汇扫盲+基本组成）-软考版","url":"/forward/624a8c21.html","content":"<h1 id=\"计算机基本组成\"><a href=\"#计算机基本组成\" class=\"headerlink\" title=\"计算机基本组成\"></a>计算机基本组成</h1><p><img src=\"/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.assets/image-20240415190659207.png\" alt=\"image-20240415190659207\"></p>\n<h2 id=\"计算机基组成\"><a href=\"#计算机基组成\" class=\"headerlink\" title=\"计算机基组成\"></a>计算机基组成</h2><ol>\n<li>输入设备</li>\n<li>运算器 控制器 ==》 CPU （其实在这个阶段还有CPU+主存储器被称为主机）还有说法就是CPU其实应该分为（运算器，寄存器组，控制器，内部总线）</li>\n<li>存储器</li>\n<li>输出设备</li>\n</ol>\n<p>其中比较值得记忆的就是<code>运算器</code>和<code>控制器</code></p>\n<h3 id=\"运算器\"><a href=\"#运算器\" class=\"headerlink\" title=\"运算器\"></a>运算器</h3><table>\n<thead>\n<tr>\n<th>模块</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>算数逻辑单元ALU</td>\n<td>进行算式计算和逻辑运算</td>\n</tr>\n<tr>\n<td>累加寄存器（有的设备没有累加寄存器直接用<code>数据缓冲寄存器替代</code>）</td>\n<td>存放数据运算的一个操作数或者结果如31+1=32中的32.也有可能是其中的31。因为它只能存一个。</td>\n</tr>\n<tr>\n<td>数据缓冲寄存器</td>\n<td>保存cpu的运算数和运算结果。<code>这个存的多一些</code></td>\n</tr>\n<tr>\n<td>状态条件寄存器</td>\n<td>在计算机中，它主要用来保存运算过程中的状态信息，比如运算结果、运算过程中的逻辑状态等。当运算出现异区状态时，它能够及时标识出来，帮助计算机更好地进行下一步的运算。</td>\n</tr>\n</tbody></table>\n<h3 id=\"控制器\"><a href=\"#控制器\" class=\"headerlink\" title=\"控制器\"></a>控制器</h3><table>\n<thead>\n<tr>\n<th>模块</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>程序计数器PC</td>\n<td>用于记录下一个需要运行的指令。</td>\n</tr>\n<tr>\n<td>指令寄存器IR</td>\n<td>存放当前运行的任务指令</td>\n</tr>\n<tr>\n<td>指令译码器</td>\n<td>将指令译码为计算机能执行内容</td>\n</tr>\n<tr>\n<td>时序部件</td>\n<td>实际上就是控制cpu 频率的</td>\n</tr>\n</tbody></table>\n<p><img src=\"/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.assets/image-20240415191622335.png\" alt=\"image-20240415191622335\"></p>\n<h2 id=\"并发并行\"><a href=\"#并发并行\" class=\"headerlink\" title=\"并发并行\"></a>并发并行</h2><h3 id=\"并发性\"><a href=\"#并发性\" class=\"headerlink\" title=\"并发性\"></a>并发性</h3><p>并发就是一时间段内运行的任务。</p>\n<h3 id=\"同时性\"><a href=\"#同时性\" class=\"headerlink\" title=\"同时性\"></a>同时性</h3><p>就是同一时刻。</p>\n<h2 id=\"词汇扫盲\"><a href=\"#词汇扫盲\" class=\"headerlink\" title=\"词汇扫盲\"></a>词汇扫盲</h2><p><img src=\"/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.assets/image-20240415191807006.png\" alt=\"image-20240415191807006\"></p>\n<h3 id=\"CPU的性能指标\"><a href=\"#CPU的性能指标\" class=\"headerlink\" title=\"CPU的性能指标\"></a>CPU的性能指标</h3><p>主频就是2.4GHZ这个，</p>\n<p>字长就是一次性能处理的2进制数据长度，如2^64    2^32这样子</p>\n<p>CPU缓存就是L1 L2高速缓存。</p>\n<h3 id=\"总线分类\"><a href=\"#总线分类\" class=\"headerlink\" title=\"总线分类\"></a>总线分类</h3><ul>\n<li>数据总线：顾名思义数据走向的总线。</li>\n<li>控制总线：控制指令总线</li>\n<li>地址总线：内存编址范围。（一般XP系统内存是4G，因为xp的操作系统内存编址是32位 2^32 = 2^2 * 2^30  然后 2^30是一个G，所以算下来就是4G）总之就是管理操作系统运行内存大小</li>\n</ul>\n<p>总线性能：带宽（这个就是是带宽），位宽（一般就是和CPU字长一样，32位就是32位），工作频率（时序频率）</p>\n<p>设备间连接方式：串行连接，和并行连接。 串行线只有一根但是可以很长，并行线可以有多根但是不能很长。前者速度慢但是距离长，后者速度快距离短。</p>\n","categories":["日记"],"tags":["信息系统管理工程师"]}]