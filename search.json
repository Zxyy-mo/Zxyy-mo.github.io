[{"title":"LLama2大模型量化部署","url":"/forward/1f77414f.html","content":"<h1 id=\"Llama模型量化模型cpp部署\"><a href=\"#Llama模型量化模型cpp部署\" class=\"headerlink\" title=\"Llama模型量化模型cpp部署\"></a>Llama模型量化模型cpp部署</h1><h2 id=\"部署步骤\"><a href=\"#部署步骤\" class=\"headerlink\" title=\"部署步骤\"></a>部署步骤</h2><p>wsl下部署没啥装个Ubuntu22.04先。</p>\n<p>然后git clone两个项目。</p>\n<p>首先是llama的git项目</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/facebookresearch/llama.git</span><br></pre></td></tr></table></figure>\n\n<p>然后是cpp</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/ggerganov/llama.cpp.git</span><br></pre></td></tr></table></figure>\n\n<p>然后进入llama的项目</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> llama</span><br></pre></td></tr></table></figure>\n\n<p>然后去官网<a href=\"https://ai.meta.com/resources/models-and-libraries/llama-downloads/\">https://ai.meta.com/resources/models-and-libraries/llama-downloads/</a></p>\n<p>申请下载到邮箱</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">./download.sh</span><br></pre></td></tr></table></figure>\n\n<p>然后就是这样子</p>\n<p><img src=\"/images/pasted-1.png\" alt=\"upload successful\"></p>\n<p>等待模型下载完毕以后，进入llama.cpp</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> llama.cpp</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>先安装gcc环境</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo apt install build-essential</span><br></pre></td></tr></table></figure>\n\n<p>编译等待编译完成</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n\n<p>安装python依赖</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3 -m pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\n\n<p>转换模型，当然还有其他参数我们可以直接打开convert.py去查看</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">python3 convert.py <span class=\"string\">&#x27;模型地址&#x27;</span></span><br><span class=\"line\">python3 convert.py --outfile <span class=\"string\">&#x27;输出地址&#x27;</span> <span class=\"string\">&#x27;模型地址&#x27;</span></span><br><span class=\"line\">python3 convert.py --outfile ./models/llama-<span class=\"number\">2</span>-7b-chat ../llama/llama-<span class=\"number\">2</span>-7b-chat/</span><br></pre></td></tr></table></figure>\n\n<p>那么如果遇到以下问题</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">```bash</span><br><span class=\"line\">python3 haConvert.py --outfile ./models/llama-2-7b-chat ../llama/llama-2-7b-chat/</span><br><span class=\"line\">```</span><br><span class=\"line\">```error</span><br><span class=\"line\">Writing models/llama-2-7b-chat, format 1</span><br><span class=\"line\">Traceback (most recent call last):</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 1210, <span class=\"keyword\">in</span> &lt;module&gt;</span><br><span class=\"line\">    main()</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 1205, <span class=\"keyword\">in</span> main</span><br><span class=\"line\">    OutputFile.write_all(outfile, ftype, params, model, vocab, special_vocab, concurrency = args.concurrency, endianess=endianess)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 909, <span class=\"keyword\">in</span> write_all</span><br><span class=\"line\">    check_vocab_size(params, vocab)</span><br><span class=\"line\">  File <span class=\"string\">&quot;/home/xiaoyu/llama.cpp/haConvert.py&quot;</span>, line 796, <span class=\"keyword\">in</span> check_vocab_size</span><br><span class=\"line\">    raise Exception(msg)</span><br><span class=\"line\">Exception: Vocab size mismatch (model has -1, but ../llama/tokenizer.model has 32000).</span><br><span class=\"line\">```</span><br></pre></td></tr></table></figure>\n\n<p>不要去相信网上的added_tokens.json</p>\n<p>实际上在llama-2-7b-chat文件夹中，应该有一个.json文件（可能是params.json）。打开这个json文件，将”vocab_size”从-1改为32000。</p>\n<p><img src=\"/images/pasted-2.png\" alt=\"upload successful\"></p>\n<h2 id=\"注意\"><a href=\"#注意\" class=\"headerlink\" title=\"注意\"></a>注意</h2><p>实际上最后输出的是一个.bin文件，所以我们上面的命令是有瑕疵的。</p>\n<p>所以当我们转换成功以后。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> models</span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> 7B</span><br><span class=\"line\"><span class=\"built_in\">mv</span> llama-2-7b-chat 7B/ggml-model-f16.bin</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"量化\"><a href=\"#量化\" class=\"headerlink\" title=\"量化\"></a>量化</h2><p>我们上面改为了bin这里也变成bin，我们执行的是4bit量化, 输出到./models/7B/目录下面</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">./quantize ./models/7B/ggml-model-f16.bin ./models/7B/ggml-model-q4_0.gguf q4_0</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">./main -m ./models/7B/ggml-model-q4_0.gguf -n 256 --repeat_penalty 1.0 --color -i -r <span class=\"string\">&quot;User:&quot;</span> -f prompts/chat-with-bob.txt</span><br></pre></td></tr></table></figure>"},{"title":"Hello World","url":"/forward/4a17b156.html","content":"<h2 id=\"失語時代下的喃喃自語\"><a href=\"#失語時代下的喃喃自語\" class=\"headerlink\" title=\"失語時代下的喃喃自語\"></a>失語時代下的喃喃自語</h2><p>纪念2017年愚人节，reddit网站发起一项为期三天的社会实验（2017年4月1日-4月3日），号召所有注册用户在一块100万像素的画布上作画（1000*1000），用户有16种像素颜色选择，生成一次后需要等待20分钟到5分钟之后才可以进行下一次编辑。凭借大家的协作创造出得一幅伟大的作品并载入互联网史册。</p>\n<p>在混乱中建立秩序，文明也在一次次破坏重建中焕发了新的面貌，当资源有限的情况下，一个群体想要生存势必要蚕食别的群体，生存还是毁灭的问题在短短的72小时内在一块小小的帆布画版上不断上演。虽然这个活动在几年前就已经结束了，但现实中比Reddit这场社会实验残酷百倍的故事却从未停歇。<br><del>国家之间的冲突，族群之间的恶意。在更大纬度的战场，渗透于各个领域的对垒，甚至已经关乎到十几亿几十亿人们的幸福生活。</del></p>\n<p>活动地址参见：<a href=\"https://www.reddit.com/r/place/\">reddit/r/place</a><br>活动详情参见：<a href=\"https://en.wikipedia.org/wiki/Place_(Reddit)\">维基百科</a><br>画板元素详解：<a href=\"https://draemm.li/various/place-atlas/\">The /r/place Atlas</a><br>变化过程参见：<a href=\"https://www.bilibili.com/video/BV1WW41197qY\">bilibil</a></p>\n<p>活动结束时最终快照[高清]：<br><img src=\"/images/img--1.png\" alt=\"reddit-place-2017\"></p>\n","tags":["place"]}]